0	"Misuse" has a generally less severe connotation than "abuse." Abuse would usually be something that someone does intentionally or without regard for consequences, while misuse is more likely to be unintentional. The meaning is the same in the humanities, sociology, legal studies, and all other fields.
1	The two can be used synonymously, but there is generally a difference at least of degree between them, and often of intended meaning. To "misuse" is "to use incorrectly". For example, if you take a screwdriver and try to use it to paint a picture, you are misusing it; the screwdriver is not designed for painting, and will not do a good job when pressed into that service, but neither the paint, the picture, nor the screwdriver will be damaged as a result of your action. To "abuse" is "to use excessively or damagingly". For example, if you take a screwdriver and try to use it to pry up a manhole cover, you are abusing it; although a screwdriver can often be used to pry up small objects, a manhole cover is much too large for an average screwdriver and you are likely to end up with a bent, damaged screwdriver and an unmoved manhole by the time you give up. In terms of sociology, as @Daniel has also said, the usage is essentially the same, although I'd say you are much less likely to encounter the word "misuse" in this context (or if you do, it is entirely synonymous with "abuse"). If an employer makes his workers engage in a dangerous action without taking appropriate safety precautions, he is abusing the workers ("using them in a way likely to cause damage"), even if they don't actually get injured.
2	The two words are NOT synonyms of each other in general conversations, as you have suggested. The examples you give actually illustrate the differences mentioned by the others who have replied. Misuse is far less serious than abuse. Misuse may be a mistake, but could be intentional. Abuse is almost certainly intentional and may have serious consequences. In your examples: Drug misuse is when you use a drug for the wrong purpose, either by mistake or intentionally. Drug abuse involves misusing a drug to such an extent that it becomes addiction and "willful habit". Then it is abuse. Hence, as in other general usage, abuse is more serious than misuse. You're correct that misuse is not generally used in talking about relationships, because you don't usually talk about misusing a person. But abusing a person is serious. I repeat, your examples of usage of the words in connection with drugs and relationships are merely illustrating - or extensions of - the more general differences, albeit that they have generally accepted fairly specific meanings in those fields.
3	Prepositions are confusing, but this particular use has its logic. You are thinking of the King speaking to the photographer; but this English idiom is driven by the quality of what is said. When you ask for a favour or a gift or make a demand or a request you are asking the other person to give you something, and the idiom employs a preposition which expresses not the direction of the communication but the direction of the giving which is to follow, from the person requested back to the person making the request. The preposition might have been from, but in English the prepositions of and from have a great deal of overlap, and had even more overlap in the past. Note, for instance, that titles and identifiers which express a person's place of origin use of rather than from: the Duke of York, Auld Wat of Harden, and so forth. Very far back in history we held an election between of and from in this context, and of won. So in English we do not say made a request to; we say made a request of.
4	Mercenary as an adjective or noun could provide a suitable description for such a person. mercenary adjective 1. primarily concerned with making money at the expense of ethics noun 1.1 A person primarily concerned with material reward at the expense of ethics Source: ODO Definition of “mercenary”
5	He's a sell out (sense 3). He can do anything for money.
6	Nouns: Grafter. 1, 2 (def. 2 in both cases). Someone who engages in and benefits from graft, which is the abuse of one's position of (often political) power or authority for the purpose of gaining money by illegal or immoral means. It would not be appropriate to call a filing clerk who copied and sold classified papers a grafter. Money-grubber. 1, 2. Someone who's solely or overly interested in money and will take almost any opportunity to acquire more. The term focuses more on the desire for money than the willingness to do anything to get it, though someone money grubbing would be willing to do many things (but not necessarily anything) others aren't in order to get paid. I do know of a word that fits exactly what you're after, but it's extremely rude and vulgar. See below if you're interested. Whore. Typically this means prostitute, but modern and informal usage has expanded it to refer to someone who will do anything, especially immoral or degrading acts, for money or gain. Synonyms (prostitute, hooker, etc.) don't carry this expanded meaning. Adjectives: Venal. The right meaning, but wrong type of word. The noun form, venality, is the quality of being venal, not a person who is venal. For sale. Informal, meaning venal or able to be bought or bribed. "I can't believe Judge Watkins is presiding over the mob trial; everyone knows he's for sale." "His access to the credit card database is for sale to the highest bidder."
7	According to a dictionary: character: - a letter, sign, mark or symbol used in wirting, printing or computers -e.g) Chinese characters / a line of 30 characters long letter: - a written or printed sign representing a sound in speech -e.g,) 'B' is the second letter of the alphabet. Write your name in capital letters. So we can conclude that a letter is a kind of character that represents a sound in speech.
8	In general, a "character" is any mark or symbol that can appear in writing. A "letter" is a character that is part of an alphabet. Basically, a character that represents a sound in the language and that can be combined with other characters to form words. So in English, the letters are A-Z, in both capital and small versions. Characters include the letters, and also punctuation marks like a period or comma, and other symbols included in writing, like a dollar sign. Note that in the computer world, "character" has a somewhat more specific technical meaning: it's a value from the "character set" represented by a code and that can be stored in a character or string variable. The old ASCII character set includes a number of "non-printable characters", control codes that were sent between devices. The idea of "non-printable characters" doesn't make much sense in conventional writing and printing.
9	You've asked for an "elaborate" explanation, so I'll elaborate. A character is a typographical symbol. For example, any of these could be classified as characters: $ A m ; * 3 + A letter is a symbol corresponding to a letter in an alphabet, such as M or G. One dictionary defines it as: letter (noun) a character representing one or more of the sounds used in speech; any of the symbols of an alphabet (from NOAD) Now, for some fun facts: The English language has twenty-six letters, which are represented using fifty-two characters (each letter has an upper-case and lower-case character version). The same letter can be represented by different-looking symbols (also known as fonts). What might be a letter in some languages could be considered a symbol in others. For example, µ is a Greek letter, but an English symbol. Also, ñ is a letter in Spanish, but, in English, one might describe that as "the letter n with a tilde over it." The two are not mutually exclusive – a letter can function as a symbol. For example, the c in cat functions as a letter, but the c in E = mc2 functions as a symbol for a constant (the speed of light). In summary, all letters can be symbols, but not all symbols can function as letters. Fun exercise for the learner From Wikipedia, under its entry for Angstrom: The ångström or angstrom is a unit of length equal to 10−10 m (one ten-billionth of a metre) or 0.1 nm. Its symbol is Å, a letter in the Scandinavian alphabets. (emphasis added) So, is Å a letter, or a symbol?
10	The problem is that grammar is somewhat tied to meaning here. The position of an adjective in a sentence depends on its role. When used attributively (to describe a noun), as stated in other comments and answers, the adjective comes before the noun: All navigable rivers are being patrolled. If you say: All rivers that are navigable are being patrolled. (Others are not) This can become: All rivers navigable are being patrolled. At first glance this doesn't really seem to change the meaning since: rivers that are navigable = navigable rivers Edit: But... When an adjective comes after the noun it describes (like in the 3rd example), it functions as a postpositive modifier. Changing the position of the adjective (relative to the noun it describes) may bring a slight difference in the meaning of the sentence (the meaning of the word itself does not change!). When used postpositively an adjective connotes an ephemeral quality, one that is present at the moment, but doesn't always have to be. On the other hand, the adjectives used attributively may express either an ephemeral or a permanent characteristic, depending on the context. The difference between attributive and postpositive use of an adjective is explained in more detail in (the middle of) this post and in the comments. Only some adjectives can be used both attributively and postpositively (while retaining the same word meaning), and these are the ones ending in -able and -ible (such as navigable). (But not even all of those - see later: responsible). To cover another aspect (this is where grammar kicks in again): if an adjective is used predicatively (in a pattern: subject + verb + object + complement (here an adjective)) it would be in a sentence like this: Signalisation on the banks made rivers navigable. (Or something like that, I'm not really an expert on rivers). The upcoming event made people excited. The meaning of some adjectives (when used as modifiers) changes depending on whether they are used attributively or postpositively. Some examples are: concerned, responsible, present etc. Neither navigable nor excited are among those. Here the meaning of the word itself changes and the difference can be determined by checking the dictionary definitions.
11	Here are the common prepositions we use with born, as listed in a definition given by the Macmillan Dictionary: born [adjective] [never before noun] when a baby is born, it comes out of its mother’s body and starts its life. The time when you are born is your birth, and a mother gives birth to a baby Her grandfather died before she was born. born in: I was born in Tokyo. born on: The twins were born on August 29, 1962. born into: Meg was born into a large family. born to: More children are now born to older women. In short, we use born in a place, born on a date, born into a family, born to a mother (or parents, as in your example). According to an answer to a related question, this part gives us a good reason why we don't use born by anymore: When we speak today of a child being born, there is no longer a sense that this was an action performed upon the child by the mother; it is, rather, an event. We no longer say that John Smith was born on April 1, 1950 by Mary Jones Smith; we say at most that John Smith was born on April 1, 1950 to Mary Jones Smith.
12	The correct sentence would be : Does anyone have a black pen? I would recommend not trying to follow rules blindly (might I add, like a robot) and give your intuition a voice too.
13	Anyone, in this instance, is not plural. So, just substitute a name, "Does John ____ a black pen?" The answer is "have." However, the point is moot when one considers the more acceptable form (picture a classroom setting), "Who here has a black pen?" Mary might answer, "Jane has one." Jane might answer, "I have one." While to the original form, "Does anyone have a black pen" the literal answer could be "Yes, of course."
14	When using auxillary or helping verbs, the first verb is conjugated according to subject, but the second part of it is fixed. Take present progressive tense, for an example: I am going to the park. He is going to the park. We are going to the park. The basic construction here is {to be} + {-ing form of verb}. The {to be} is conjugated according to subject, but not its helping verb - it'll always be "going" in this example. This is the same with {to do} + {plain form of verb}, which is the emphatic form of a verb, and often used for negative and interrogative expressions. I do go to the park from time to time. He does go to the park from time to time. Do you go to the park from time to time? Does he go to the park from time to time? Does anyone go to the park from time to time? Anyone is singular, so the first verb is conjugated accordingly, but not any subsequent helping verb.
15	No, they mean different things. "Keeping well" means "keeping healthy". So "I hope you're keeping well" is a slightly old fashioned greeting. It might be addressed to an older person (for whom being "well" might be in some doubt). I can't imagine a child using it with their friends. To "keep doing well" is not an idiom. "Well" is the adverb related to "good". The speaker is hoping that the other person continues to do something in a good manner Eg. -- I've got over 90% in all my maths tests this year. -- That's great. I hope you keep doing well.
16	The attribute inheres in the created not in the act of creating. You can take are created as a quasi-copula complemented by a predicate adjective that applies to that which is created. We don't say born freely do we? Created equal is perfectly grammatical.
17	Equal, the adjective, is correct here. Created equally, with the adverb, implies that some things are more and some are less "created"—which would presumably mean (it's not idiomatic English) that they owe their origins to a greater or lesser degree to some sort of act of creation, as opposed to having arising spontaneously. Equal is not an adverb but a "subject-oriented predicate complement", a term which describes the subject and is attributed to it as a result of the action of the verb. Compare, for instance: Coffee was served black. Coffee was served in large mugs. Black and in large mugs are subject-oriented predicate complements. All men are created equal thus means that all men (and women, too!) were created as equal—the creative act caused them to be equal.
18	"Created equal" means "created such that they are equal". A homosexual man might say, "Your God created me gay!". This is the same grammar: gay is an adjective, complement to the verb created. (And note, by the way, it cannot be: "... created me gaily!") "Created equally" is an awkward application of an adverb to a verb. A speaker who uses this might be making a mistake, having intended to say "created equal", or might be trying to say "created according to the same procedure, to the same level of completion". "Equally" is usually a helping adverb in an adverbial phrase as in "equally well", "equally far" and so on. By itself, it usually refers to something being done such that there are even proportions: "The food rations were divided equally among the stranded passengers." "Daniel treated his three children equally when it came to love or discipline." To say, "created to the same level of completion, by the same procedure", we normally say "created in the same way". Equally doesn't function very effectively as a synonym for in the same way; at least not in all the circumstances in which we can use in the same way.
19	In this specific sentence the use of who is correct. As a rule of thumb: Think whether you would use he or him if the sentence was written differently. In this case you would say "The man proved to be a swindler. I thought HE was thoroughly honest." If you wanted to say "I thought of HIM as thoroughly honest.", whom would be the way to go
20	OYou can use either who or whom; both are correct grammatically. It's common to use "who" in place of the object pronoun "whom". The use of the whom is formal or less common in speech and writing. Furthermore, the who/whom is a relative object pronoun in the relative defining clause "who/whom I thought was thoroughly honest". You can drop the who/whom. Besides, you can also use the structure think + someone + adjective. So you can also drop "was" in the clause. The sentence can be rephrased or reduced as follows: The man (who/whom) I thought thoroughly honest proved to be a swindler.
21	"By market" would mean "by means of a market" or "using the device of a market" and would not, ordinarily make sense. Even if it sounds logical, there is no context I can think of in which "I used a market to buy this" would feel idiomatically correct. You can use "buy by X" to describe the method or measure of how something is normally bought: Gasoline is normally bought by volume, not by weight. Large orders of beef can be bought by grade. However, even with this it would be more common to say "sold by" or "priced by" and not "bought by". Gasoline/petrol is sold by volume Meat is priced by grade. If you want to say that a market is normally where or how to buy something, you would say something like: You can buy it at the market. You have to buy it at the market price, which changes daily. Shares in publicly traded companies are bought on the (stock) market. Or, in some cases, you could say: (Some special item) can only be bought through the (some special) market. Side note: "from market" is not idiomatic in American English. We almost always say "from the market". However, this is idiomatic, not grammatical, since we do say "from school", "from church", "from class", "from home" and various others.
22	Babel is the Hebrew name in biblical myth; since "Tower of Babel" is taken from scripture the Hebrew name is used. If I interpret the Wikipedia entry correctly is a sort of pun with an Hebrew word for confusion: In the Bible, the name appears as Babel (Hebrew: בָּבֶל‎‎, Bavel, Tib. בָּבֶל, Bāvel; Syriac: ܒܒܠ‎, Bāwēl), interpreted in the Hebrew Scriptures' Book of Genesis to mean "confusion",[13] from the verb bilbél (בלבל, "to confuse") In contrast "Babylon" is (the transliteration of) the places name (as per Wikipedia, "Greek Babylṓn (Βαβυλών), [is] a transliteration of the Akkadian Babili]") , so that is used when talking about geography instead of mythical stories.
23	Babel and Babylon have different origins and may actually reflect different words. The city known as Babylon was founded circa 2334 BCE, around or before the reign of Sargon of Akkad. Akkadian was the native language of the Mesopotamian nations at that time. The city became the largest in the world and the center of power under Hammurabi (1792-1750 BCE). The complete history of the place name is disputed. Hammurabi called his realm Babylonia (a transliteration of what is represented as Bab-ili, Babilli, or Babilla, from Akkadian (or perhaps Old Babylonian, which was the language of king Hammurabi). The English Babylon comes from Greek Babylṓn (Βαβυλών), from that transliteration. Bāb-ili ("Gate of God" or "Gateway of the God") also corresponds with the Aramaic Bab for Gate and El for God, hence Babel. In the Bible, the place name appears as Babel (Hebrew: בָּבֶל‎‎). The Mesopotamians built many monumental towers as temples. Archaeologists have discovered nineteen of these buildings in sixteen cities; the existence of another ten is known from literary sources. The ancient Babylonians called these brick mountains a ziqqurratu or ziggurat, which can be translated as "rising building" (Akkadian zaqâru, "to rise high"). Babylon, itself, contained a number of these. The Etemenanki was among the largest (92 x 92 x 92 meters). It was the most important (its Sumerian name E-temen-an-ki means "House of the foundation of heaven on earth"). This temple tower was erected at what was thought to be the center of the world, the axis of the universe, where a straight line connected earth and heaven. This aspect of Babylonian cosmology is echoed in the Biblical story, where the builders say "let us build a tower whose top may reach unto heaven" (apparently heaven is at 92 meters). This is the tower known as the Tower of Babel. Construction of the tower took over a century. The tower must have looked unfinished for a long time, and this may explain how the Biblical story came into being. The name "Tower of Babel" came from the biblical story about the tower, it was not the actual name of the tower (Etemenanki). Babel is a transliteration of the Hebrew. It could mean the Hebrew equivalent of the "Tower of Babylon". Or as Eike Pierstorff writes, it may have been a play on words. It could tie into the Biblical story because Babel is similar to Balal (בלל), the Hebrew word for confusion, and the verb bilbél (בלבל), "to confuse". *Sources: https://en.wikipedia.org/wiki/Babylon, http://www.ancient.eu/babylon/, http://www.livius.org/articles/place/etemenanki/, https://en.wikipedia.org/wiki/Akkadian Addendum: Incidentally, there is no connection between "Babel" and "babble", even though it might seem like the obvious origin. From Online Etymology Dictionary: babble (v.) mid-13c., babeln "to prattle, utter words indistinctly, talk like a baby," akin to other Western European words for stammering and prattling (Swedish babbla, Old French babillier, etc.) attested from the same era (some of which probably were borrowed from others), all probably ultimately imitative of baby-talk (compare Latin babulus "babbler," Greek barbaros "non-Greek-speaking"). "No direct connexion with Babel can be traced; though association with that may have affected the senses" [OED]. Meaning "to talk excessively" is attested from c. 1500. babble (n.) c. 1500, "idle talk," from babble (v.). In 16c., commonly in reduplicated form bibble-babble. Meaning "inarticulate speech" is from 1660s. Other nouns meaning "idle talk" included babblery (1530s), babblement (1640s).
24	First off, the use of the infinitive after the verb mind is ungrammatical (this source may be helpful). As for requests starting with the phrase "Do you mind"/"Would you mind", they may be used: 1.When you are asking for the permission to do something yourself – then it is followed either by "if" + "I do something" or (rarer) "my doing something". 2.When you are asking someone to do something – then it is followed by the gerund. Examples: Would you mind/Do you mind if I finish off the cake? Would you mind/Do you mind my sleeping here? Would you mind / Do you mind opening the window? The answer may be "Of course not!" which means "I don't/wouldn't mind if you do it", or "Of course I do (mind)!" which means the reverse. Also, to agree, you may answer "Go ahead!" or "Please, do!" or to disagree, "Please, don't!" (Then it would be polite to explain the reason for your disagreement) .
25	First, I must address what you said here: Because he didn’t mention any doctor before saying “the doctor”. You can read in another ELL answer that there are in fact other uses for the definite article besides "alluding to things that were previously mentioned." As this Wordnik page shows, the word the has several meanings and usages. Your example is a tricky one, though. Strictly following rules of grammar, one might think that "a doctor" might be more grammatically correct than "the doctor", but I think the latter is more idiomatic. Personally, I might use any of these: I"m going to see a doctor. I'm going to see the doctor. I'm going to see my doctor. I'd be most likely to use the first one when I'm on my way to a clinic or emergency room where I've never been before. And I'm most likely to use the last one when I have a scheduled appointment with my primary physician. I might use the one in the middle when neither one of those is true. Perhaps I'm going in as a walk-in patient where my regular doctor usually works, but I don't even know if he'll be there today. As I searched for a definition that might fit his context, I found this one in NOAD: the (article) informal used instead of a possessive to refer to someone with whom the speaker or person addressed is associated : I'm meeting the boss I think that one captures the "I'm going to the doctor" usage rather well. It may not be a personal relationship, but the physician-patient relationship as a whole is understood well enough that the usage of "the" sounds both normal and idiomatic.
26	A) I am going to see a doctor. B) I am going to see the doctor. C) I am going to the doctor. D) I am going to the doctor's office. E) I am going to the doctor's. F) I am going to see my doctor. G) I am going to see a new doctor. Choice A does not mean a random doctor. It simply does not say (in this sentence) what doctor. Usually the speaker is talking about the disease or problem, and is not interested in talking about "which doctor I will use". Choice B,C,D,E do not mean "my regular doctor". The phrase "the doctor's" is a standard idiom, which can mean any doctor's office. Many people use clinics, where they do not know what doctor they will see. They still say they are going to "the doctor". Only choices F and G tell us if the doctor you are visiting is your regular doctor, or a stranger. Neither H nor J says anything about what doctor you are visiting: H) Sorry, I can't talk right now. I am at a doctor's office.➡️doesn't use the idiom "the doctor's" so you need office J) Sorry, I can't talk right now. I am at the doctor's ➡️. uses the idiom
27	Yes! "Either" takes a singular verb. Either has seen that creature. ("Either have seen that creature" is incorrect.)
28	Introspective means a person who likes to look inward, look inside him- or herself and think. Anyone can be introspective at times in their life. introverted (noun, introvert) is a personality type, someone who is quiet and does not show much outward emotion. Introverts can be difficult people in terms of communicating with others.
29	Though they mean the same, they are not always interchangeable. You need to study the context before using those words as synonyms to each other. Say, for example, if there is a group of scientists and they are trying to do an experiment that has been previously attempted by someone else, they try to replicate the results. The word 'duplicate' doesn't go there! If I'm a good painter, I can replicate the Mona Lisa, I cannot 'duplicate' it! So, to answer this question, check twice before interchanging these words. Likewise, when you lose your original driving license or any other document, you apply for a duplicate copy. There, 'replica' does not work!
30	When you replicate something, you get a copy that's almost the same as the original, but not quite the same. There is usually some sort of difference between the original and the replicate. The original and its copy can have different sizes, for example. But the most important difference between the two is their identity—the original and its copy are not going to be the same thing at least in terms of their identity! An example that illustrates this best would be a replica of a famous painting. A professional painter can make an exact replica of the Mona Lisa. Even though the two paintings look exactly the same, we all agree that there is still a big difference between the two paintings! The original costs millions of dollars because it's the original work of Leonardo da Vinci and the replica is just a mere copy of it. So, the idea behind replication is that the replicate is always slightly different from the original at least in terms of its identity. As for the other term, the result of the process of duplication is a duplicate which is an identical copy of the original in all of its aspects. If you make a duplicate of the keys to your house, the duplicate is going to be absolutely identical to the original keys in all respects. This means that a duplicate of something is as good as the original and can be used to replace it completely while this is usually not true for replicates.
31	In addition to the answers above, I would add that a duplicate mostly apply to objects, like an ID card duplicate in case of loss or damage, a line in a source code, a photocopy of a document... The noun replicate was already stated by previous answers, but now, let's consider the verb to replicate Consider a crime scene witnessed by someone. When asked from the police, the witness may for example replicate the gestures of the murderer to describe how the scene went. In this context, it is more like mimics, trying to be as close as possible to the original action. Now, consider software engineering. The tester tells the programmer that there is a bug on the X module. The programmer tests the module but is unable to find out what manipulations the tester did in order to the bug to occur. He then calls the tester to show him what he did step by step. The tester then replicates his actions and the bug is occuring again. So, the verb to replicate may still infer copying something, but it could also be re-doing something, as the verb to duplicate is mostly making a copy of something.
32	In addition to the answers above, I get the impression that "duplication" generally refers to one duplicate copy (as opposed to triplicate), and sometimes a few (eg "I cut four duplicate keys from the original, and I still have the duplicate keys with me"), and the focus is more on the object being duplicated. So you may have a duplicate that you used a different process to produce, as long as they are identical in all ways that matter. A duplicate is also normally 1:1 scale to the original. Whereas "replicate" seems to be more focused on the process and the result is the same or close to the same because you performed the same process, or at least you say you did (if its something you are selling to tourists). A replica may be scaled up or down from the original and still be called a replica (eg "He replicated his winning sales strategy from a small business beginning all the way up to a multi-million dollar company"). For instance You replicate old ships, not duplicate them: https://en.wikipedia.org/wiki/Ship_replica (though they seem to like calling significant scale changes "models" not replicas) Anyway, my 5c worth, based on my understanding of usage in Australia, sailing and computer science.
33	Duplication is making an exact copy of an existing ojbect (you duplicate the key of your house). Replication is making many object from the same model, for example industry mass produtions, you replicate the same car model.
34	It should be noted that replication and duplication technically refer to processes, not any result or object that results from such processes. Previous answers refer to the end result to determine which process has been followed (replication or duplication); ie that a duplicate is normally an exact copy of an original (such as a photocopy of a paper) whereas a replica is not necessarily to the exact specifications or dimensions. However if is important to note that while the processes of duplication and replication may be different, the end result from both can still be identical. For example: A computer programmer codes some software that produces a result. Another programmer is asked to replicate that software. The second programmer may use an entirely different method to achieve the same result. However, in an entirely different example: if it is found that two people are performing the exact same task and the repetition of work is unnecessary, this is referred to as a duplication of work irregardless of whether the two are strictly following the same process, so there are clearly exceptions. Finally, although the correct English terms for the results of duplication and replication would be duplicate and replica, it is not uncommon in colloquial speech to hear them referred to by their processes. Incorrect, but nevertheless sometimes used.
35	The style of headline involved here tends to omit small words that a native reader finds easy to restore. Something like Man Found Alive would be understood to mean A man was found alive. This restored sentence is cast in the passive voice. An active voice equivalent is easier to examine: Someone found a man alive. The term "linking verb" is reserved for those verbs which directly license subject complements. The adjective "alive" is a complement in the active voice statement above, but it is not a subject complement there. It's an object complement. There does exist a label which covers this situation. The verb to find is a complex transitive verb. Your observation is correct. Even in the passive voice, to find still licenses an optional complement. When the clause is in the passive voice, that complement is an attribute of the subject. It seems entirely reasonable to consider the "alive" of "a man was found alive" to be a subject complement. It is not quite as reasonable to consider to find as a linking verb. On its own, that verb does not license subject complements. Instead, it is the complete passive-voice construction "was found" that offers this license. Within this construction, that license is provided by the "was", which by itself is a linking verb. To be is a linking verb. To find is a transitive verb, and optionally a complex transitive verb. Together, they create the passive construction "was found", which promotes the target of its complement to its subject. The headline in question has a linking construction that's missing its essential linking verb.
36	This whole concept is surely the wrong way round. The world, from which the sample has been taken, is how it is, without regard to any models that you might have chosen to use through which to view the world. So models are not applied, but are tested. You are not testing the sample, you are testing your models. So " we tested our model with these data and..."
37	I truly hate the vocabulary used with participles. In English, participles are formed from verbs. Each verb has a progressive participle and a perfect participle. The principle purpose of participles is in verbal phrases for the purpose of indicating the aspect of the lexically significant verb. However, participles can also be used as adjectives or as nouns. When they are used as nouns, they are called gerunds. The children were running the business on their own by then. The participle "running" is used here as the lexically significant part of a verbal phrase that is in the past progressive tense. They bought a thriving business. The participle "thriving" is used here as an adjective. Swimming is good though tedious exercise. The participle "swimming" is used here as a noun and so is called a gerund. It would be easier for students if we said that a "gerund" is one way that progressive pariciples are used in English. There is no difference in form between a participle and a gerund.
38	The preposition phrase "next to the bar" is modifying "the supermarket" since it is tightly following "the supermarket". If the preposition phrase is modifying "the bank," it'd be written like this: The bank is opposite the supermarket and next to the bar.
39	Great discussion! So I was the phrase ‘When’s the last time you got lucky?’ on a billboard. This sparked my curiosity because I thought it was incorrect to use the contraction for when was, and based on the definition for when’s you have to use When is the last time you got lucky, not when was the last time you got lucky. Therefore, both should be allowed in speech or either you can’t use the contraction and we know it to be used this way quite often… Funny thing about grammar- it seems to be ignored ignored more often when speaking than when writing…
40	It reminds me of a slogan-like sentence: "make it possible". If we paraphrase that in a passive voice, we get this: "it is made possible". I think this follows the same structure or grammar as "all are created equal".
41	As this article explains, The basic manoeuvre is a sucking of air through the teeth from behind pursed lips – or as academics describe it, a "velaric ingressive airstream involving closure at two points in the mouth". But thereafter there is nuance. There is the short, sharp kiss from the front teeth on either side. Usually this denotes minor irritation or mild disapproval. It may be deployed with a shake of the head and perhaps the glimmer of a smile, recognising the absurdity of what has transpired. Moving up the scale, there is the sucking from further back in the mouth. Longer in duration and louder, this responds to episodes occasioning deeper incredulity. This video is a somewhat tongue-in-cheek explanation, but it also shows it well: http://www.youtube.com/watch?v=JSBMqGCdw84
42	I found an explanation of "kissing teeth" in a blog post by Azizi Powell on Pancocojams, a blog which (in its own words) showcases the customs of people of Black descent throughout the world. In this post, she explains something about the history of the term and the various different words which can be used for it in different parts of the Caribbean: The phrase "suck your teeth" is documented as early as 1915 in Jamaica and is also found in Barbados, Belize, and Guyana, Trinidad, and the United States (particularly among African Americans). In Tobago, kiss teeth is called "hiss teeth" and in the Cayman Islands it is called "sucking your mouth". Source: http://privatewww.essex.ac.uk/~patrickp/papers/KSTpapwww.pdf The Meaning Of Kiss Teeth [...] In the Caribbean kiss teeth is represented by the initials "KST" (kiss teeth) and "KMT" (kiss my teeth). Among people from the Caribbean, kiss teeth can be represented in writing using the words "Cho!", "Chups", "Tchuipe, "Chupes", "Stchuup”, and similarly spelled words. These words are both nouns and verbs. [...] A well deserved ode to the tjoerie. The what?!? The tjoerie, which is the Surinamese word for what is known in the French West Indies as 'le tchip' and in the English speaking part of the Caribbean as 'kiss-teeth'. When something or someone becomes too annoying, one always has an effective weapon at their disposal: a long, cricket-like sound of which the effect combined with rolling eyes is deadly insulting. There is no one that does not respect a good tjoerie. She also includes a video in her blog post to demonstrate the "tjoerie" in action: https://youtu.be/ha9-RAJK65g
43	Kissing teeth, or the "velaric ingressive airstream involving closure at two points in the mouth" may be considered disrespectful and a culpable expression of contempt. It is banned in many French schools and at one time was liable to result in arrest in Britain if done by someone being questioned by police. French schools ban teeth-sucking
44	Option 1: I'm Back! For an IF game, probably the easiest way to allow character death is to allow some kind of backup, or a chance to be restored to life. Examples include: Cloning Technology - Your character has been cloned (or can be), and when the original dies, a clone takes his place. This method is used in the classic SF/humor RPG Paranoia, specifically to let characters be killed off constantly. Time Travel - In a time-travel story, sometimes the time-travel technology lets you "come in from the future" and make another attempt if "things go wrong." Beat Death - Some RPGs solve the death problem by making it simply an extra challenge: dying just takes you to a different level, which you must beat, and then you can return and continue with the game. So you could have a "Hell" level or a "Deal with the Devil" challenge or some such, allowing you to return to life once you beat the extra level. (I remember the Neverwinter Nights module Witch's Wake did this.) There's also the brilliant use of story-as-a-flashback in Zarf's Spider and Web (HIGHLY recommended!). Obviously you don't want to copy such a unique structure wholesale, but the unusual approach may give you ideas for similarly oddball structures that might work for you. Option 2: I'm Still Here! This seems to be more what you had in mind - ways to exert influence despite having, shall we say, shed the mortal coil. Do bear in mind, though, that creating a whole new mode of play can be quite a chore for an interactive-fiction game! If you like any of these ideas, you might consider basing the entire game around the concept, rather than adding the extra mode in as an odd extension. Some ideas: Ghostly Haunting - Your own suggestion, and quite effective for your purposes. A ghost has limited interaction with the world - how limited is up to you. A ghost can certainly continue to wander around; maybe it's more limited in what it can touch and manipulate; maybe it can't speak easily to others. Maybe it also has new powers - like walking through walls, or possessing NPCs. A particular variation could set the player as the incorporeal sidekick of an "independent" NPC. Kind of the reverse of what Jeremy Freese did with Violet. Reincarnation - A more mystical/fantastical approach to having a backup character would be reincarnating as someone or something else. Guidance From Beyond - Set up some way to give advice to some sidekick character - dreams and visions; flashback memories; a will; a prophecy. You can set this up so the "advice" is retroactively assumed to have already been provided. Hope this helps. If I have any other ideas, I'll add them on later.
45	Any reflection written in an European context is based on a philosophical idea of reasoning. It means the issue is deepened and put in perspective. Each development brings a new nuance. This however, has nothing to do with "not picking a side" (as this has to do with writing a report or a argumentative essay). Any reflection written in an American context does indeed pick a side and will support a definite conclusion. This explains why more complex issues often have to be simplified or considered in a narrower focus. When it comes to writing mechanics, the rules also change. As a general rule, the American conventions are stricter and more rigid. Quality of reflection is usually prized above all in European standards.
46	One easy, cheap and workable approach to writing without worldbuilding is when the world is known. Your story takes place at the White House, your protagonist is President Trump. Everyone knows all the rest. Just sketch out the events. Another, harder - is to write apart from the setting. The events and conflicts are universal, essentially per Alexander's answer. What you're trying to do though, is very hard to do right - and very easy to get wrong. When the world is just a minimal sketch of weirdness surrounding the characters, but definitely interacts with them, you're at constant risk of introducing Deus Ex Machina - a very bad tool, a total rock bottom when it comes to quality of prose. Your deus ex machina may come as immediate solution, contrivance or problem that was not foreshadowed, is not understandable to the reader, serves no other purpose than to advance the plot, and in effect your story becomes either a pulp of cheapest kind or a starts resembling milder forms of Schizophasia. It takes a very skilled writer to pull it off - have the world with unexplainable mysteries, but still compelling, the sudden revelations spicing the story up instead of watering it down. Considering you're even asking this question, I'd suggest you take a more conservative approach. Just knowing that it can be done doesn't put you much closer to knowing how to do it right.
47	Well. I'm learning as I go and I haven't seen the series. But here's what that sounds like to me. You've identified rhythm and meter. Maybe these can be imagined as dialog that varies in its staccato or legato elements. Here are a few more ideas. 1. There are different genres of music. (and different types of dialog can work.) One type of music is the blues. Here are some lyrics from Muddy Waters: Baby please don't go. Baby please don't go. Baby please don't go, down to New Orleans. You know I love you so. The pattern in the blues is repeat, repeat, change. In a lot of other styles of songs (and maybe blues too), there is a pattern of verse, verse, bridge, verse. So, music, even music that is geared to adults, has elements of both repetition and novelty woven into it. Dialog can do this sometimes too. The repetition can have the effect of reinforcing certain ideas. The repeats can be spaced or immediate. 'What are you doing?' 'What am I doing? I'm leaving.' 'Leaving? (etc)' This ain't a great example, but I think the idea of repetition is worthwhile. 2. Music has chords, multiple notes, multiple instruments, and also high notes and low notes. Put that complexity into dialog. Pairing characters with opposing values in dialog can move a story. Or simply be interesting. Imagine a mother who wants to protect and raise her child safely, and a child who just wants to go out and see the world. What is their dialog? Or an angry boss and a meek employee. Or a single character arcing from patience to frustration during a conversation. The dialog can reflect these 'opposing' pairs, as 'high and low' notes. 3. Music has harmony and balance. Dialog should, too. If you have two characters arguing a point, they will not each state their case in completion and then listen to the other case in its completion. Instead they will go back and forth, and the amount of this from either character should balance out. 4. Chopsticks is hard to listen to. So is dialog that repeats a sound again and again. 'Stop shaking the salt shaker.' is hard to read. 'Will you stop that? You have plenty of salt.' is easier. 5. Playing by ear. I think Sorkin's right? It seems like a person picks it up with time. I don't know if it can be taught or not but I think it can be learned.
48	Obviously you have to read, but you don't have to read a LOT. The lessons for writing are distilled into non-fiction books on writing, usually by authors of multiple best-sellers. It is actually a little difficult to extract rules of plotting and characterization from reading books, the plot and characterization are better taught, not by example, but by explicitly tutoring the distilled version of how to do it. Another approach is to not read fiction for entertainment, but to open it up and scan for particular things similar to what you want to do. If you have a lot of dialogue to put across, find a passage in a book, written by a multiple best-selling author, and analyze how they accomplished that feat without boring the reader. The same goes for a lengthy description of a setting; look for something with very little dialogue and a lot of exposition. The same goes for writing a battle, or a sex scene. Of course both of those have their own non-fiction books on how to write them, or examples of them. Google for them. We don't teach medical students surgery by just telling them to watch a few dozen surgeries and then jump in with a scalpel. We don't teach engineers to build bridges by looking at a lot of bridges. We teach them the theory of biology and surgery, or the theory of building bridges, long before we have them look at actual surgery or actual bridges. The same can go for writing. Read on the theory of forming a story, what is important to that. Read on the theory of writing. If you love to write, learning the theory should should be engaging to you; you have immediate application for it. Then follow the examples and try to apply what you've done in writing. You won't avoid reading best selling fiction altogether, but IMO it is bad advice to just tell people read a hundred books and then write one, just as bad as telling an engineer to go look at 100 bridges by themselves, try to figure out what is important by themselves, and then design an original bridge by themselves. The result would be either a patchwork of plagiarisms from existing bridges, or a disaster, or both. Theory first, examples of "what worked" are only useful once you can generalize them back to the theory, because it is the generalized theory you need to apply to your own specific work; not just plagiarizing somebody else's application of the theory.
49	Yes. Something like this has been done before. At any given moment, there might be 9,728 planes in the air carrying 1,270,406 people around the world. Every crew on each of these planes depends on having accurate, readable, flight manuals on their aircraft. The Aviation industry has addressed the issue of how best to encode and decode information by establishing the S1000D standard for creating documentation. This standard uses a controlled vocabulary or language called Simplified Technical English. You could study these and see if they embody concepts that could be applied to your idea.
50	Not many. The Romans borrowed plenty of Greek words, but mostly in technical senses; in Antiquity, many Greek words that were used in Latin were also considered a bit fancy and special, for better or worse. There were also some Greek words that were borrowed by the Romans so early in Roman history that they were probably no longer intuitively (or at all) felt to be Greek during the Empire; but the very large majority of Latin words were not from Greek. In Christian times, some more Greek words were adopted from the New Testament and from ecclesiastical traditions; Christianity emerged in the eastern part of the Roman Empire, where literate people spoke Greek, not Latin (many people were bilingual, though, just as in the western part). But the number of Greek words was still fairly limited; for comparison, the proportion of French or Latin words in modern English is many, many times greater than was that of Greek words in Latin. Latin is from the Italic branch of languages, along with Oscan and a few more long-dead languages. Greek is from the Greek/Hellenic branch of languages. Both branches are part of the larger Indo-European language family, along with the Germanic branch (English etc.), the Slavic branch (Russian etc.), and several other branches. While it is true that Latin was influenced by Greek in ways other than vocabulary—such as grammar—, most similarities between Greek words and Latin words you observe are probably due to their common ancestor, the hypothetical Proto-Indo-European language, in which the Indo-European family of languages originated. All Indo-European languages retain much of their Proto-Indo-European heritage. It is also true that some Indo-European branches are more closely related than others; but I believe the Italic branch was more closely related to the Celtic branch than to the Greek branch. It may be that Italic and Greek are more closely related to each other than to Germanic and Slavic, but they're still not very close.
51	OK, the fact of the matter is that everybody learns their own languages, in their own ways, in their own times, places, and circumstances. It is normal for kids to have several languages at home, and to pick up others as needed, by playing with other kids. Those languages either flourish through use, or wither and get forgotten by disuse, like any human skill. Plus, people vary not only in their unique language experience, but in their skill at apprehending and using it. Also like any human skill. That's a vast amount of individual variation. By contrast, labels like Native language, First language, Mother tongue L1 L2 .. etc. are invented by people who need abbreviations for commonly-referenced groups of characteristics, usually characteristics that are common only in monolingual places like the USA, where almost everybody speaks only English, and often finds multilingualism threatening. They are not terms defined in the Qur'an or the APA Style Manual; they are just abbreviations, which may be useful in certain contexts among certain kinds of professional. That's all, really. These terms, and others, may or may not be applicable to the situations you mention. Or to others one can easily imagine. I repeat, they're just nonce forms, with localized definition and localized utility. They are Not Ready For Prime Time, in other words, so you shouldn't take them too seriously. And they certainly don't cover every possibility.
52	I wrote a blog post about this very topic last week, on the International Mother Language Day. http://multilingualparenting.com/2014/02/21/mother-tongue/ There is unfortunately no clear-cut answer if you speak more than one language. The different terms are used in different contexts and for varying purposes. For me 'mother tongue' and 'native language' are more or less interchangeable. The term 'first language' is as far as I understand not the chronologically first language, but the one a speaker is fluent in and feels most comfortable to speak. This means your 'first language' can change depending on where you live and which language you speak the most. Your first question is intriguing and I also wrote about the scenario in my blog. If you no longer speak the language(s) you learnt as a child, based on the monolingual research terminology, you would be "mother-tongue-less" - however you would have a L1. If you have become fluent in a language later in life, you have a 'native level fluency'. It's difficult to draw the line with regards to accents - different "native" speakers have vastly varying accents as well, so why would an accent from an other area prevent you from being called fluent? If you have learnt a language as a child and you are fluent in it, it is one of your 'native languages' - the notion that there could only be one 'mother tongue' or 'native language' comes from a monolingual perspective and doesn't apply to bilingual people.
53	This is a very good question because it highlights the multiple terms used to describe what appears to be similar if not the same phenomena; However, as it has been pointed out above, there are contextual differences in the terms. As far as a clarification for the terms: First language and L1 are the same. L1 is the abbreviated form of first language. And mother tongue and Native language are interchangeable. Essentially, these two terms are socio-cultural constructs. Meaning, the terms native and/or mother language are a way to conjure a transportation of a language from one culture and geography into another geography/culture. Their use trigger the counterpart, foreign. Thus, in addition to declaring the order of language acquisition, these two terms also reveal an immigration component to the language. In contrast, the term L1/First language are clinical terms to describe language acquisition in individuals who have acquired one or more languages. As far as the scenarios listed in the original post: I would describe this scenario as a non dominant L1 individual, i.e. underscoring language acquisition and subsequent language shift. L2 adquisition post Critical period. This scenario needs to be further qualified because the critical period may include for some a wide time frame. For example, I would call an individual acquiring a second language up to age 4 or 5 a sequential L2, and/or maybe depending on the input exposure opportunity in both languages, a simultaneous bilingual, known as 2L1.
54	Just take myself for an example. It might be subjective though. I'm a Cantonese living in Canton(or Guangzhou), China. Cantonese is my mother tongue and first language. It's a local language in Guangzhou and Hong Kong SAR. Mandarin is my native language. It's the official language of China. So almost all kindergartens and primary schools in mainland China will teach Mandarin as compulsory. Accents and dialects appear in all different parts of the nation but Mandarin is the only one that used nationwide freely. English is my 2nd language then.
55	I was wondering how many of Latin (both Classical and Medieval varieties) words have Greek roots. As a fraction of words in the dictionary, relatively few, but as a fraction of words in formal texts, not insignificant, depending on the topic and context. Similar to words of Greek origin in English, which are largely via Romance. Examples would be problem, church, oil, democracy... Notably, the names of the academic or encyclopædic topics themselves are disproportionately Greek - geology, architecture, economics, politics... As are the words academic, encyclopædic and topic. But plenty more were just coined in other languages in recent centuries and then only borrowed back into modern Greek - photography, anarchism, Anglicanism... Is Greek the common root of most IE languages? No, no living language or subfamily is, they are branches of a tree.
56	Unless you have a crazy good reason for wanting to speak only said language, such as, for example, speaking anything else on that particular planet will summon Cthulhu itself, no, there's no justification. Here's the long and short of it: people will rebel. Oh, you might get your way for a while, but only under a demonstrated, and actively enforced threat of punishment. Consider that in order to know when people are disobeying you will have to monitor them constantly. Regardless of the morality of this action, implementing that level of surveillance is going to be challenging. I also doubt too many people will enjoy having some AI-like entity listening to every word they say, even in their most private moments, or in their sleep.
57	Easy You catch the dragon using disposable peasants, steel nets and whatnot. You drag the dragon to the public square (or a clearing or whatever, if a square is inconvenient with all the dragonfire and stuff). You use your death row convicts to deal the death blow. If the death row convict refuses to kill the dragon, he/she is tortured for days before being put to death. You then hang the death row convict dragonslayer (optionally, use the convict for more than one slaying).
58	1. Irregular geological / tectonic plate activity - Perhaps at some point mantle became unstable resulting in frequent earthquakes. These earthquakes were small scale but unnaturally damaging to the human settlements. Imagine deep fissures opening up randomly in the heart of cities, small lava eruptions that open and close without a warning, EM flares coming from ground frying electronics, disrupting human brain/hearts and what not. But all large water bodies are completely free of it because water absorbs it all so humans gradually moved to seas/rivers. As for animals, they suffered from losses as well but eventually adjusted and thrived with humans gone. This satisfies your requirements of people living on water and not going inland for very long durations. 2. Post-apocalyptic world - Let's say human population keeps increasing eventually to the point that water bodies become viable real estate. It becomes commonplace for people to live on boats and large cruise boats type of structures are common as apartment complexes. Now, cause an apocalypse on land that makes the water settlements far safer than land. Perhaps it was a super-bacteria/virus that thrives in concrete/asphalt but not on lighter plastics/woods used to create the houses on water. So, humans didn't "migrate" to water, they were already living there and then something happened on land that resulted in only the water settlements surviving. 3. Zombies - Zombies can't swim. Humanity can't beat the zombies and must start living offshore. 4. Predators - Let's imagine the movie "Jurassic world" as what its name suggested instead of being a working Jurassic park. Dinos have either fully integrated in the society (Dino pets, Dino powered lawnmovers, Dino egg benedicts) or thriving in relative secret in jungles and something causes them to become the apex predators (human partial extinction due to plagues, wars etc). Sounds outlandish but dinosaurs can be enhanced or replaced with anything else as long as it can't survive in water and doesn't exterminate all other flora and fauna. It could even be as simple as triffids or Alzheimer's like symptoms inducing plant/microbes. 5. The last ship - In this scenario, an apocalypse has happened and only the ships out very far away in the oceans have survived. The land is not livable except by plants and small animals, so they restart the human civilization on water.
59	Your biggest adversary is human nature. The best of us are selfish brutes, motivated by base vices and greed, and we won't go into what the worst of us are like. Our current society rewards actions taken for others. Why does a farmer grow food he's not going to eat? He does it so that he can get other things he wants. There are, as I see it, four ways forward. First, foment an insurrection/revolution in a nation. This is bloody, expensive, dangerous, and very hard to control. Forget about the idea espoused by Marx that the masses will by nature turn to your new collectivist system. They are sheep which need lead. Assume that a useful society will require 51% of the people to buy in. That means you have to eliminate, coerce, or convince at least that many people to see things forward. China did something like that in its Great Leap forward. It wasn't pretty. Two, take the long view. Create a secret society with these goals. The society infiltrates all schools and universities. They press for state-control of child-rearing so the older ideas are not taught by the backward parents. They influence language so that old-thought is impossible to articulate (it's hard to talk about snow if you don't have a word for it.) They set about to make small, incremental changes to major social institutions that will make the transition easier. Eventually, the society will be ripe, and the society will stage a revollution, take power, and force the remaining changes. This plan will take two or three generations at a minimum. During this time, it would be hard to keep the society from splintering into factions. Third, a group of like-minded individuals could pool resources and buy some land somewhere remote. They could then set about building the society, populating it, initially at least, with clones trained to think cooperatively/collectively. If the society is as successful as you think they will be, they will become an economic powerhouse that would then grow. I think, however, the ugly specter of human nature will rear its ugly head, and you'll be plagued by listless, lazy people, punctuated by a few charismatic, ambitious folks who will exploit any flaws in the system for personal gain. I think it would be hard to avoid Tragedy of the commons. Lastly, a cabal of elites works to create a massive AI with the goals you outlined secretly embedded in its core programming. This they install in, say, the Pentagon. Over time, the AI gains control over more and more functions. At some point, the AI will have enough control to start making small, incremental changes to accomplish its secret programming. See Person of Interest TV Series for speculation of such an AI's abilities. Edit added the AI option.
60	Well, pretty clear the biggest hurdle is that there is no way for the carrier to transmit its genetic traits to the offspring. The way you describe it, it can pretty much be a vascularized nest, nothing more. Reproduction is basically an answer to the need of DNA molecules to not decay. You need to find a way that 3 entities have to contribute with their genetic material to the offspring.
61	Don't forgot you're going back in time... then coming back to the present If my understanding of the question is correct, the aim is to be able to have/afford a house in present day but only pay $15,000 for it, or at least pay as little as possible, and you have access to a time machine of some sort that can take you back 50 years, I'm not sure if that's only 50 years or it can do more or less as well. but I digress, if that is the case Although Gold is worth a lot less dollars 50 years ago, due to inflation of the Dollar not value of Gold. it is still the most hassle free way to transport wealth back in time. It's how you use it that counts So Today Gold is roughly 1200 Dollars an ounce, and back in 1968 it was roughly 290 Dollars an ounce, so if you were to buy 12,000 Dollars worth of Gold today, you'd have roughly 2900 Dollars in 1968, not great but... as others have suggested, you can get old money now, you might have to pay twice as much for it, but if nothing else you know Gold is going to be worth 4x what it was worth then, so spend as much money now to get the old bills, go back and spend all that money on Gold then bring it back and sell it... Alternately... Why buy a house? Buy Shares!!! In theory, you could buy $10,000 worth of gold today go back in time and then sell that and place the money into stocks that you know full well will mature well over time. you may only be able to but a few different stocks but buy a few here and there and as they mature they split doubling your amount, then have dividends placed into a couple savings accounts. this is important as account that don't get accessed every few years get flagged for checking, and if they don't get used after this then they can be closed, the money would still be owed to you but the interest rates would no longer pay out, so simply having some letters put in with a lawyer, which they will send every couple of years to transfer some money between the accounts should see you fine right up until about 2001, when banks security changed and you would have to go in to do things like this, (be aware that some small town banks still to this day will make transactions by letter) The dividends are paid on say (Very low estimate) 10 cents a share and that is usually paid 4 times a year (this changes with certain companies and requires them to always make a profit, but lets assume you did your research and knew this would happen) so 40 cents a year, for 50 years is 2000 cents, 20 dollars! yay... OK so not that much, but that's only for one share, so owning say 200 shares in company X would net you, $4,000 not bad return so far, but still not made your money back until you sell the shares. but!!! as a company matures over time they often split their shares, Microsoft for example has split their shares 9 times since 1986 to maintain a reasonable trading range So if that were the case then those 200 shares would be if split however many times your chosen company splits (it's all in the research before you go) No Split: 200 Shares = $4,000 1 split: 400 Shares = $8,000 2 Split: 800 Shares = $16,000 3 split: 1600 Shares = $32,000 4 Split: 3200 Shares = $64,000 etc, you see how this is going, there's no point buying the house back then when you can buy a much bigger house in the present, and that's not even taking compound interest into account, and this is only the dividend money, not the value of the shares themselves One very simple way of getting round this is if you can go back more than once, $10,000 worth of stocks in 1968, and that would net a huge amount over time in dividend payouts, Go back in 1984, and invest in Red Bull, this would increase the divided payouts even more... then go back in 2000, take those divided payouts and invest in Apple or Microsoft, then come back to the present, you wouldn't have changed much in terms of human history (let's just ignore chaos theory for this) and yet, if you take inflation, and even some very low estimates the dividend payouts alone would make you a multi millionaire
62	Immediate effects The earth would cool down within hours to way below freezing temperatures. (the sun would not provide any heat any more) First days If the atmosphere is transported with the earth it would take a little longer to cool down still within days. In that same time span most life would cease to exist and maybe a few humans survive by burning fuels or using stored electricity or by getting to bunkers in time. In a couple of weeks surface temperatures would near - 100 to -170°C and slowly near absolute zero. First years Wait a little longer and the core of earth would cool down to a pint where tectonic activity would cease to exist. (no active volcanoes no earthquakes no earth crust movements) This would already take years to take effect. So everything beyond this point doesn't belong in this answer if I understood the question right.
63	There are many examples of technological stagnation through out history. Many uncontacted aboriginal groups in Brazilian forest have never advanced into the iron age. They remained in a primitive state for various reasons. Some of the most advanced native American cultures never advanced, in many ways, much past the early bronze age. When the Tokogawa Shogunate came to power, they closed their doors to the world. When they reemerged 250 years later, they found a world that advance well beyond them, while they made very little advancement.
64	Chitin is heavy, not good for armour. There might be some potential in keratin (horn) if you can get a lot of it. Wood is your best bet for barriers like shield and pavise. Gambesons were very common, and were always worn under plate and mail. On top of these you want to use tough skins, like hardened leather or raw hide. There were some armours made of boar tusks found in the East. Japanese used armours made of wood, bamboo and leather. You can look into that as well. One more thing to note is that you don't need that much protection from the weapons. Since metal is unusable your whole warfare moved back to the stone age, making the weapons less effective. Things like aztec "swords", clubs, bow and arrow, slings, stone tipped spears, etc. (Unless bronze remains as an option because it's hard to corrode it entirely.) Most siege weapons don't need any metal parts, if you have good craftsmen. Even mechanical parts can be just wood, but they would have to be replaced often to make them reliable but I'm no expert so don't take my word on that Another thing to think about is that most of these materials are flammable, expect a lot of burning oil and stuff like that being used.
65	A light adhesive ball. Preferably because the ball has a metamaterial surface rather than an adhesive glue-like substance. On earth the balls have a certain resistance with the ground that slows them down upon contact. With an adhesive surface your balls would stick to the surface of the ground as long as you dont throw them downwards too hard and then roll to a stop. By manipulating how adhesive and elastic the balls are you can change the chance they'll bounce off and how much resistance they generate on the surface before rolling to a stop.
66	1)Religions in the past were not widely accepted as today and often faced prosecution or even public mobbing. In such a case a religion may adopt to means similar to warfare whereby a coded language is created in order to keep secrecy and uphold security measures. If continued for a long time by a particular sect this can evolve and become a language of its own. It should be noted though that an entirely new language cannot be formed by people who already speak a certain language. This is mainly attributed to the need for translations and psychological factors. Therefore the language will be based on known languages but can gradually evolve to separate itself. 2)The second scenarios is based on George Orwell’s novel ‘Nineteen Eighty-Four’. He writes of a government that manipulates the english language to limit human thinking. This is done by removing certain words and expressions that may cause a rebellion against the government. Religion’s are highly conservative and have only recently come to terms with the free world, nevertheless restrictions of clothings,tattoos and similar lifestyles are received negatively. Language too is somehow regulated in religious institutions with words related to sexual activity, atheism...etc are in a way banned in public. In OP’s situation, it can be said the monks try to create a language to control such factors and prevent the human mind from thinking any thoughts that revolt or oppose religious thoughts. This although would be an extreme case of regulation by the monks but people go to extreme lengths for their faith and beliefs. The monks may not necessarily to govern a set of people but may try to limit their own thoughts in attempt to purify themselves. Some may argue that the above is impossible but artificial languages have been created before and been used by a set of people. One example is the language of the minions which is claimed to be created by Chris Renaud and Pierre Coffin. It is a limited language with an aim of being humorous but I doubt any monks would create a language for humor. 3) Another possible reason is the need for the monks to differentiate themselves from similar religions or other similar factors(Who knows when monks start facing competition from a restaurant dressing their staff similar to the monks-JK). This would still be an extreme measure but it would serve the purpose of separating their identity from the so called competition. 4) The monks can be on a higher level of authority in the religion and might want to signify the importance and level of dedication required to achieve the level of authority. In christianity it can be compared to that of the pope(The pope does not speak a different language). The sam situation can work in a reverse situaion wher trainees in the monk religion are taught a different language to show dedication to the religion. All the above situations would be almost impossible and unnecessary making the likeliness of such a language existing impossible. If anything like this happens it would give a new insight in th field of linguistics.
67	Since the cooker is on the chest, let's assume we're pumping heat from both the back and the chest Average adult human body surface: 1.8 m2 Average waste heat of an average adult human: 18.4 BTU/hr/0.09m2 (Source) The chest and back equal 27% or .486m2 (Source) That's 99.36 BTU/hr that could be used to heat food For the sake of argument, we'll assume perfect transference of heat from the skin surface to the food. This is certainly NOT true, but the result is a best-case measurement of what this technology could do. So, what can we do with 99.36 BTU/hr? 1 Btu = amount of heat required to increase temperature of 1 pound (1 pint) of water by 1 DEGREE F The average adult human needs four pounds of food each day. (Source) Let's assume only 2 pounds of food must be cooked. It must be raised to 350℉. For convenience we'll assume we don't need to hold it there. Cooking food during the heat-raising time is not as efficient as pre-heating the cooking apparatus and has the potential of causing botulism, so it's not the best solution, but it's a simplification that's useful for this exercise. How many BTUs are needed to heat 2 pounds of food from room temperature (75℉) to 350℉? (350 - 75) * 2 = 550 BTU, which would be generated in about 5.5 hours. Conclusion: Believable Considerations The above analysis is assuming the human is resting. If the human is working, they'll generate more waste heat, but they'll also need more food. I can't prove it, but my spidey senses suggest food will be needed at a greater rate than heat will be generated. The inefficiencies ignored in this analysis would lengthen the time needed to cook food. 10 hours to cook 2 pounds of food would be more believable. The ambient conditions were completely ignored by this analysis and it's important that they be considered. In high summer, "room temperature" would be higher but heat pumps work much less efficiently. In deep winter "room temperature" would be quite a bit lower, but the heat pump would work more efficiently. Consequently, cooking during the summer might be hard-to-impossible (but, then, you could cook eggs on surrounding rocks, n'est pas?) However, adding to the improved efficiency of heat pumps in the winter is the benefit to having all the apparatus under insulating clothing — Except the homeless are usually a bit short of insulating clothing and the loss of waste heat might compromise their ability to stay warm at all during the winter. Therefore, while I conclude this is believable, I wouldn't focus too much on it. I wouldn't be surprised that a rigorous review of physics would demonstrate this solution would barely work, at best, and be so susceptible to botulism that it wouldn't be worth the effort.
68	As an experienced GM, I generally ignore the wealth by level chart for all purposes except as a quick and convenient guide to equipping custom NPCs. The documented goal of the Wealth By Level sidebar and table is to tell you what default level of value of gear might keep an average party of the average number of PCs of some average build hitting the default expcted CR/ELs at the standard level of difficulty in an average campaign. An even slightly careful reading of that previous sentence illustrates the vast number of assumptions required to make it useful. I'm not sure when I've ever had an average group of PCs. I don't always allow every gp to be bought/sold into custom gearing, so sometimes an expensive piece of gear doesn't contribute to "kill factor." I am not a big fan of level setting everything to the "right" CR. As an actual living Dungeon Master, not a computer AI or someone bound by Organized Play rules, there are six or so variables in balancing my campaign that I tune at my discretion to make the game run smoothly. If you're not tuning encounter difficulty to your actual PCs in their specific situation every time based on their builds, their gearing, and many other situational factors, you are probably not doing a great job as a GM. Putting lots of work into making all those factors 'standard' will get you a very generic game and blindly relying on those tables for balance will actually inhibit you from understanding how to balance things yourself based on all the factors in game and not just the couple they've sidebarred for you.. WBL, along with CR/EL, is one of those "let's be helpful and give new DMs some guidance" parts of the DMG that have been misinterpreted as black letter law by too many legalistic gamers. My groups don't pay them any mind except when we want to eyeball the guideline to know how much we're violating it. Worrying about the "default guidance" and other GMing advice the book provides you with is great your first couple times DMing - then after that the world and story should come above the rules. It's picky minutiae to feel constrained by it. Those tables (CR, WBL) didn't exist for many versions of D&D and it all worked out OK. I've never in my last 13 years of active gaming played with a 3e/3.5e/Pathfinder group that bothered with WBL and we're all still alive and have had consistently good games. WBL Pitfall 1 First, if you feel constrained to follow WBL, you're likely to break simulation to do so. You can see this in the related question about WBL and sandboxes - so if the party goes and kills wild boars, you need to have the right amount of money drop into their laps? In the pirate campaign I run, if the PCs want money they have to go out and do something to get it - the idea that there's a certain entitled amount you just get as you run through the world like a passive spectator removes much of the drive from adventuring. And usually in sandbox campaigns, PCs can run across "inappropriate CRs" easily so the whole concept of slavish balance isn't in scope anyway. WBL Pitfall 2 Second, and related, it constrains what stories you can tell. Right now I'm a player in a group running through the Jade Regent Adventure Path. We're power players on the path to be the next emperors of fantasy-Japan, and we have access to lots and lots of wealth - last time I checked at level 12 I was carrying something in excess of $150k of stuff. But because of the story, lots of that is "ancestral weapons" you don't just hock at the nearest magic shop, and lots of it is stuff we end up giving away to allies - "You nine ronin helped us? Here's 9 +1 katanas we just got off the bad guys! Go forth and kick ass in our names!" Adherence to WBL would limit the scope of stories available to the game. People over Process over Tools Does this require "consensus at the table" beyond what the RAW gives you? Totally. All games require and benefit from consensus at the table on many points. The hard and fast rules about CR, WBL, etc. are mainly useful when you lack a meaningful social contract otherwise (e.g. Organized Play at cons). But I'm not sure why someone would play in a normal home game without that kind of understanding.
69	Since Gary Gygax was the original "designer" let's look at what inspired his version and hence D&D's version of the Paladin. This is from a Collection of "Sources for D&D" that was compiled by Aardy R. DeVarque, who draws his source directly from the original 1st edition Dungeon Masters Guide. Paladin Class Based largely on the character of Holger Carlson from Poul Anderson's Three Hearts and Three Lions, as well as Anderson's original sources, Charlemagne's paladins in the medieval French chansons de geste ("songs of deeds"), particularly The Song of Roland and Ariosto's Orlando Furioso. The paladin's tie to a special war-horse is also from Three Hearts and Three Lions. I do not mean a saint, but a warrior whom God gave more than common gifts and then put under a more than common burden. —Martinus, Three Hearts and Three Lions So a lot of what the Paladin class is, seems to come from Three Hearts and Three Lions. The main protagonist of the novel plays a crucial role in an epic struggle between Law and Chaos (this is also where the D&D alignment system came from). In the book, law and order are represented by Christianity, which was also considered a beacon of hope. This is, I think, the basis for the Lawful Good requirement and code of conduct that Gygax attached to the paladin class.
70	In 2E (and maybe 1E - not sure, I don't have the books handy at the moment), the Paladin is specifically a specialist Fighter, much like how the Druid was an "example" of a specialist Cleric. The paladin is also less defined by his religion (not just a holy warrior) and his alignment, and more defined by his required code of conduct. Alignment is a guideline - any other Lawful Good character can bend the rules from time to time, but the paladin's code of conduct is a hard and fast rule - he breaks it, he's no longer a paladin. The design decision was less "hey lets make a holy warrior, and only the good guys would have those" and more of a "lets create a class based on this example of the knight in shining armor, with an uncompromising dedication to the ideals of good".
71	From a gaming perspective, I see two points in favor of the initial alignment restriction : consistency with existing stereotypes : assassins are evil, paladins are ultimately good, and so on. So that was not shocking for players Paladins was the most powerfull class available. Alignment restriction was a good way to prevent abuses and make is also somewhat not easy to play. Playing an overtly evil is less restrictive and may have cause trouble all the time, in my opinion.
72	I dont think there is much issues with this, unless your group disagrees. It is true that fire is the most commonly resisted element, and is easy to find defenses against. However, cold immunity is not all too much more rare (think all the undead). The breath weapon is not all that overpowered anyways, so I dont think it should be a problem. Unless you are actively abusing this or have a group that finds that unfair/unacceptable, I see no real reason to ban it, but it's "talk to your DM" thing.
73	Yes, you're understanding it correctly. You roll your attack roll for the bow with proficiency and Dex modifier (PHB p. 194), and damage with just Dex (PHB p. 196).
74	Yes, you are precisely right. Attack rolls are 1d20 (+ proficiency bonus, if you are proficient) + modifiers (Dex for ranged attacks and finesse weapons; Str for most other melee weapons). The Damage rolls are whatever the weapon damage dice is, plus the modifier (again, Dex for ranged and finesse weapons; Str for melee weapons and throwm weapons.) You may be confused, but you are certainly plugging in the right numbers where they belong.
75	You are correct. A Weapon Attack Roll is 1d20 + Ability Modifier + Proficiency Bonus (if proficient in the weapon) + Other Modifiers. A Damage Roll is XdX + Ability Modifier. Do not add the Proficiency Bonus to Damage Rolls. The same Ability Modifier applies to both rolls. Use STR for melee weapons (when holding them and when throwing them), DEX for ranged weapons, and either STR or DEX (your choice) for weapons with the Finesse tag.
76	Yes. Any action you take in D&D 5e that requires a roll follows the same template. Actions that require rolls tend to be interesting situations like attacks. First, roll a d20 to determine if you succeed at the action. You almost always add an attribute bonus to this roll: in your case, Dex for firing a bow. You add your proficiency bonus if you have some feature that gives you proficiency in the roll; in your case, you have proficiency with the weapon. Occasionally, the attacker doesn't roll; the defender rolls to see if they avoid the action. This is called a saving throw. Next, determine the result of the action. In this case, you deal the damage of the weapon and (according to PHB 196, "Damage Rolls") you add the ability modifier used for the attack. Following this sequence, you've got the rolls correct.
77	RPG text has several cross purposes, most notably instruction and reference. The game designers chose to emphasize what makes the game unique early, both for reference and perhaps to initially entice a first reader to continue, over explaining the core mechanics.
78	The only ways for a wizard to gain shield proficiency are either multiclassing, or the Moderately Armored feat. Since Moderately Armored requires you to be proficient in light armor, most wizards will need either a multiclass or another feat (Lightly Armored). Note that you can use a shield without proficiency - you just won't be able to cast spells, and you'll have disadvantage on any attack roll, saving throw, or ability check that involves Strength or Dexterity.
79	Yes, there is a difference. For reference: 3.0 SRD text file on Special Abilities and 3.5 hypertext SRD for Improved Grab The first paragraph of the 3.0 ability reads: If the creature hits with a melee weapon (usually a claw or bite attack), it deals normal damage and attempts to start a grapple as a free action without provoking an attack of opportunity. No initial touch attack is required, and Tiny and Small creatures do not suffer a special size penalty. This text is removed in the 3.5 version of the ability. However, the Mouther is Medium, so that is irrelevant in your case. Both versions include this size-related text: Unless otherwise stated, improved grab works only against opponents at least one size category smaller than the creature. As a Medium monster, the Mouther can only use its Improved Grab on small creatures, even in 3.0. The -20 functionality is identical across versions - the creature can take a -20 penalty to use only one body part and avoid suffering the consequences of a grapple, or deal with the loss of mobility and DEX to AC.
80	No In the Monk Unarmored Defense section it is specified that Beginning at 1st level, while you are wearing no armor and not wielding a shield... and in the Barbarian Unarmored Defense While you are not wearing any armor, your Armor Class equals 10 + your Dexterity modifier + your Constitution modifier. You can use a shield and still gain this benefit. Which indicates armour and shields are considered separate. Ultimately, due to some very unclear descriptions of armor and shields the most definitive verdict is from Jeremy Crawford, who tweeted: Q: Does wielding a shield count as wearing armor [for the defense fighting style]? A: No. Which I think is a strong confirmation that unless specifically called out, shields do not count as armor in game terms, and were referred to as armor in a more plain English sense, mistakenly.
81	No, wearing a shield does not count as Armor Shields are in the Equipment section (Chapter 5) of the PHB, but are not classified under the Armor section when determining Light, Medium, or Heavy Armor. The posted Sage Advice also contains some details differentiating Shields from Armor: These methods—along with any others that give you a formula for calculating your AC—are mutually exclusive; you can benefit from only one at a time. … What about a shield? A shield increases your AC by 2 while you use it…[k]eep in mind that some AC calculations, such as a monk’s Unarmored Defense, prohibit the use of a shield. This was further clarified via Twitter by Jeremy Crawford Does wielding a shield count as wearing armor [for Defense fighting style]? Jeremy Crawford: No. There is another complimentary Tweet from Jeremy Crawford that states the same: The Defense fighting style is intended to work with a suit of armor you wear, not with a shield alone Confusion is understandable! If you look at Character Class options and review the listed Proficiencies, you'll notice something at odds with all of the above in my answer. As an example, let's look at the Fighter (PHB, 71). Armor: All armor, shields This does make it look like Shields are a subset of armor and would be permissible under the current written rules of the Defense Fighting Style. And, as @Goodguy5 answer states, it's not likely a huge issue for someone who invests in a 2 level dip to get the +1 AC who wields a shield without wearing armor. *Big Thanks to @Christopher for their answer here in help supplying the content of this answer.
82	Shields aren't armor, but the GM could house-rule otherwise It's possible to make a call in your game (or request the GM to make a different call) based on what you're going for. Personally (as a house rule), I'd update the phrasing to resemble something like: "While you are wearing armor or wielding a shield, you gain a +1 bonus to AC". I can't think of a realistic scenario where I (as a GM) would be upset with the +1 ac you get. The obvious concerns are "Unarmored Defense" or "Mage Armor" or some such. But, if a character wants to take a one or two level dip to snag +1AC, so be it.
83	No, wielding a shield does not count as wearing armor Rules As Intended Jeremy Crawford has clarified: Q: Does wielding a shield count as wearing armor [for the defense fighting style]? A: No. and again here: The Defense fighting style is intended to work with a suit of armor you wear, not with a shield alone. Rules as Written - Shields and armor are different Considering that shields are not listed in the armor section in the PHB, but are instead listed in the equipment section, I'd say that it is clear that shields are not intended to be armor in the rules. There is supporting evidence also in the description for a monk's unarmored defense ability: Beginning at 1st level, while you are wearing no armor and not wielding a shield... This ability makes clear that armor and shields are considered separate and distinct. The Sage Advice Compendium confirms and elaborates a bit about this: Shields are grouped with armor in the equipment rules in the Player’s Handbook, but various game features distinguish between the armor you wear and a shield you wield. Take a look at the monk’s Unarmored Defense feature and compare it to the barbarian’s version. In the monk’s version, you must both forgo wearing armor and forgo wielding a shield if you want to benefit from the feature, whereas a barbarian must only forgo wearing armor. (Sage Advice Compendium p.16) Taken together I seems clear that the interpretation above is pretty well supported by RAW as well even if it is not as explicit as it could/should be.
84	Bards can't use an Arcane Focus In the Bard class features there is a "Spellcasting Focus" section stating: You can use a musical instrument (see the Tools section) as a spellcasting focus for your bard spells. Further, the description of an Arcane Focus states: A sorcerer, warlock, or wizard can use such an item as a spellcasting focus. Since the bard is not included in the list of classes in the Arcane Focus description and the Spellcasting Focus section only mentions musical instruments, bards can't use a normal Arcane Focus. As pointed out by David Coffron, this is also true for Arcane Tricksters and Eldritch Knights despite them using Arcane magic because they do not have an entry for using a spellcasting focus in their description (and Arcane Focus does not mention them)
85	Bards cannot use an arcane focus The description of the Arcane Focus which explicitly defines which classes are allowed to use it as a focus: A sorcerer, warlock, or wizard can use such an item as a spellcasting focus. No bards are allowed it seems. Foci are determined by class, not spellcasting type It seems that the type of focus allowed to be used is defined by the class and not by what type of caster they are. The Bard class says: You can use a musical instrument [...] as a spellcasting focus for your bard spells. The wizard class says: You can use an arcane focus [...] as a spellcasting focus for your wizard spells. Both are "arcane" classes. But the class specifies what can be used. If an arcane focus was allowed to be used by all arcane casters, then the wizard wouldn't specify it as their only option. For what it is worth, Arcane Tricksters and Eldritch Knights also cannot use an arcane focus despite also being arcane casters for the same reasons. (Thanks @DavidCoffron) Jeremy Crawford also indirectly supports this in an unofficial tweet: Every spellcaster—including bards—can use a component pouch for spellcasting. Some classes also know how to use certain objects as a spellcasting focus. Bards, for example, can use musical instruments in this way, but they aren't required to. It just goes to show that arcane foci are very, very classy.
86	All of the information presented below is gathered and derived from the stated rules found in Chapter 9: Combat, of the Player's Handbook for 5th Edition D&D, starting with page 189. Any additional rules (or effects, like from spells) cite their origin. Attack Bonus There are four parts that get added together: Your Ability Modifier For most Melee weapons, this is Strength; for most Ranged weapons, this is Dexterity; for attack-roll spells, this is your Spellcasting Ability (typically Intelligence, Wisdom, or Charisma) The notable exception to this rule is the Finesse property, which when found on a weapon explicitly allows you to choose between Dexterity or Strength when you choose to make the attack, and use the same modifier for the Damage roll as well. In the core game, this property only appears on Melee Weapons. Also, thrown weapons typically count as melee weapons, even if they may be used at range; check the weapon's statblock for possible exceptions to this rule. Another notable exception is special class features or spells that allow alternative ability modifiers. For example, a Druid casting Shillelagh [Player's Handbook, 275] gains the ability to use Wisdom for both their attack and damage, instead of Strength or Dexterity, but only on certain weapons. Similarly, a Hexblade Warlock [Xanathar's Guide to Everything, 55] uses Charisma instead of Strength or Dexterity for their weapon attack and damage rolls, provided the weapon they're using matches the requirements of their Patron. Your Proficiency Bonus This applies if you have proficiency in the weapon. Simple as that. For Martial classes like Fighters, Barbarians, or Paladins, they gain proficiency in every single weapon in the game, meaning they always get their Proficiency Bonus. For other classes, you need to check the proficiencies their class grants. There are also, theoretically, "Exotic Weapons" which no class gains proficiency in by default, and for which a character would not receive their proficiency bonus unless they gain proficiency in it through some means; the core game does not contain any such weapons though. For spells, you nearly always have proficiency in spellcasting, and therefore gain this bonus. There may be a few edge cases where this might not be true, but they are rare and only worth mentioning as a curiosity. Special modifiers on the weapon itself Some magic weapons confer bonuses to the Attack Roll, Damage Roll, or Both. A +1 Weapon [DMG, 213], for example, confers a +1 bonus to both rolls. Buffs/Other Effects The spell Bless [PHB, 219], for example, adds a d4 roll to any attack roll the target makes. So for example, a level 5 Fighter wielding a +1 Rapier (has the Finesse property), with a Strength Score of 16 and a Dexterity of 18, would have the following bonus for their Attack Roll: Ability Modifier: +3 if they use Strength, or +4 if they use Dexterity Proficiency: Fighters gain proficiency in Rapiers, so +3 for a Level 5 character Magic Weapon: Weapon is a +1 Rapier, so +1. Total: +7 with Strength; +8 with Dexterity Damage Bonus Your Ability Modifier Same as above: Strength for melee, Dexterity for Ranged, Strength or Dexterity for weapons that have the Finesse property (though it must be the same ability that was used to make the attack roll), Intelligence/Wisdom/Charisma for features that allow this modifier to be replaced by a different stat. Spells do NOT gain this damage bonus unless the character has a specific feature that allows their spells to benefit, like the Evocation Wizard [PHB, 117] or the Agonizing Blast Warlock feature [PHB, 110]; or if the spell specifically says so, like with Green Flame Blade [Sword Coast Adventurer's Guide, 143] specifically saying that you are allowed to add your spellcasting modifier to the damage produced by the spell. NOT your Proficiency Bonus You never add your Proficiency Bonus to your damage rolls, even if you have proficiency in the weapon or spell. The only exception is if you have a class feature, or a feature obtained from some other source, that says so. For example, Necromancy Wizards have a class feature, Undead Thralls [PHB, 118] that allows their summons (specifically those created by necromancy magic) to add the wizard's proficiency bonus to their damage rolls. Special Modifiers Some magic weapons confer bonuses to the Damage Roll, Attack Roll, or Both. A +1 Weapon [DMG, 213], for example, confers a +1 bonus to both rolls. Buffs/Other Effects For example, the spell Divine Favor [PHB, 234] allows the target to add 1d4 Radiant Damage to all their Damage Rolls produced by Weapon Attacks. So using the Fighter example from above, assuming they took the Dueling Fighting Style (which confers a +2 bonus to Damage rolls when a character is not wielding more than one weapon and only wields that weapon in one hand), their Damage Bonus would be: Ability Modifier: +3 if they use Strength, or +4 if they use Dexterity Magic Weapon: +1 Buffs/Other Effects: The Dueling Fighting Style adds +2 to damage rolls for one-handed weapons if the character is not wielding another weapon, so +2 Total: +6 for Strength; +7 for Dexterity Note that for damage, Proficiency was explicitly not added. Proficiency is generally not added to damage rolls unless some feature expressly says it should. Additionally, it is important to remember that with Finesse weapons, the fighter has the choice of which modifier to use, but they have to use the same modifier for both attack and defense. So they could not, for example, choose to use Strength for the Attack roll and Dexterity for the Damage roll. A few other Examples Level 5 Wizard casting Fire Bolt, Intelligence 18 Attack Roll: 1d20 + 4 (Intelligence) + 3 (Proficiency) == 1d20 + 7 Damage Roll: 2d10 (Firebolt) Level 10 Evocation Wizard casting Fire Bolt, Intelligence 20 Attack Roll: 1d20 + 5 (Intelligence) + 4 (Proficiency) == 1d20 + 9 Damage Roll: 2d10 (Firebolt) + 5 (Intelligence, Empowered Evocation [PHB, 117]) Level 13 Rogue wielding a Longsword, Dexterity 20, Strength 10 Attack Roll: 1d20 + 0 (Strength) + 0 (Non-Proficiency) == 1d20 Damage Roll: 1d8 (or 1d10 if wielding with two hands) + 0 (Strength) == 1d8 or 1d10 Level 13 Rogue wielding a Rapier, Dexterity 20, Strength 10 Attack Roll: 1d20 + 5 (Dexterity) + 5 (Proficiency) == 1d20 + 10 Damage Roll: 1d8 + 5 (Dexterity) + 7d6 (Sneak Attack for Finesse Weapon and having an adjacent ally) == 1d8 + 5 + 7d6
87	Short answer: they didn't originally have to be Lawful Good The original Paladin as published in Greyhawk was aligned as Lawful. Full Stop. (This is a very minor frame challenge). The alignment matrix in Men and Magic (TSR, 1974, Gygax Arneson, p. 9) showed three: Lawful, Neutral, Chaotic. That's it. The two-axis system was first shown in a Strategic Review article (SR #6, Feb 1976) then in the Holmes "Basic D&D" before AD&D hit the streets but after the original Paladin was published. Greyhawk (TSR, 1974, Gygax/Kuntz, p. 8) says this about Paladins: Charisma scores of 17 or greater by fighters indicate the possibility of paladin status IF THEY ARE LAWFUL from the commencement of play for that character. If such fighters elect to they can then become paladins, always doing lawful deeds, for any chaotic act will immediately revoke the status of paladin, and it can never be regained. The paladin has a number of very powerful aids in his continual seeking for good: He can "lay on his hands" to cure wounds or diseases in others (two points of damage for every level the paladin has attained, one disease per five levels, either function performable but one per day). Paladins are not themselves subject to disease. They have a 10% higher saving throw against all forms of attack (excluding melee). Paladins of 8th level and above dispel evil (spells, undead, evil enchanted monsters, and the like) simply by ordering it hence, and they detect all evil at a range of 6". Paladins with any form of "Holy Sword" are virtually immune to all magic (see MONSTERS & TREASURE, MAGIC & TREASURE, Swords) I bolded the "lawful deeds" and "any chaotic act" but the rest is original emphasis by the author. In Play: we were a typical adventurer party in a large group in the late 1970's, and had a paladin who was lawful, and who in play was pretty much an example of the lawful good you'd see in AD&D 1e requirements by his own choice to play the knight in shining armor. We ran into paladin NPCs led by a Lawful cleric (but in our eyes, not quite particularly pleasant and for sure not good from our PoV) who came to our town and laid the law down on us, the adventurers. My druid in particular was cited as being an undesirable, since I was a heretical Neutral nature cleric. Our Paladin was criticized for associating with us. (We have a few thieves and a few multiclass X-thiff characters). Lawful was the overriding consideration: that alignment restriction (which carried over into the Lawful Good later) was a cost for the benefits of the class. You could not just choose to be a Paladin: you had to qualify for it, and you had restrictions (also mentioned in Greyhawk) (1) on treasure and (2) the number of followers you could attract and of course (3) you can't change alignment. Lawful Good happened originally in Advanced Dungeons and Dragons, 1e Note that it says, in the original version of the class, that the paladin "is seeking for good." That germ of an idea that Lawful and Good would be married up came to fruition in the AD&D 1e PHB. The stat requirements also increased: Strength 12, Wisdom 13, Constitution 9, Intelligence 9: these were minimums along with a 17 Charisma (rolled up) or you could not qualify for this Lawful Good Paladin sub class of Fighting Man/Fighter. While the citation of Three Hearts and Three Lions from the accepted answer shows some valid sourcing (no real disagreement) there were additional inspirations that can be seen in the selected entries for the AD&D 1e Gods, Demigods, and Heroes section covering the Arthurian Legends. Galahad and Lancelot figure prominently. If you look at the original Paladin from Greyhawk: the Paladin's laying on of hands can be traced in mythology and literature to be a reflection of Mallory's Morte d'Artur scene where Lancelot revives a knight he has slain. This makes a vivid impression on Queen Guinevere. Other literary inspiration for the knights in shining armor trope can be found in OD&D and AD&D 1e inspirational reading lists offered by the author. There is a nice summary here in an interview with Mike Mearls where he discusses the roots of D&D in terms of short stories, novels, Moorcock's conception of Law vs Chaos, and more. One of the more interesting tidbits one gleans from the interview with Dave Arneson is that his favorite class to play, in terms of challenge, was the Paladin, but how much input he had in that class, and its final form, may be lost to the ages.
88	If you select hobgoblin as your race you start with proficiency in light armor and may take the moderately armored feat giving you a proficiency with both medium armor and shields allowing for an ac of up to 19 (24 with the shield spell)
89	A very literal reading of http://www.d20srd.org/srd/environment.htm would tell us that exposure to fire only deals damage if a character's "clothes or hair" catches fire. That damage is not explicitly described as fire damage. However it's possible the character might be at risk of heatstroke, depending on whether their fire resistance counted as "a way to get cooled off". In practice, every DM I have played with would rule that lying in a fire deals at least 1d6 fire damage per round. Tieflings only have fire resistance 5, so they would take damage roughly once per 36 seconds. A DM might rule that a sufficiently small fire might only deal 1d4 fire damage, in which case a bald naked tiefling would be immune. Even in this case, there are no rules about what sort of distraction a character can or cannot sleep through. You'd have to ask your DM.
90	They can probably indefinitely endure a very small fire, but not necessarily sleep in it There's no general rule in the core about exactly how much damage various sizes of fire can do, but we know that being personally on fire deals 1d6 damage per round, so we can imagine that being exposed to a very small fire (such as that of a single torch) probably deals less damage than that - say 1d4 or 1d3. Tieflings have Fire Resistance 5, so as long as a source of fire damage can only do 5 or less damage to them in a single instance, they are functionally immune to that fire - it cannot do them any damage. You could imagine that a naked tiefling could hold a torch to themselves without fear of suffering any damage or catching fire. However, Fire Resistance is not Fire Immunity, and Fire Resistance 5 is not very much resistance. Even a very small source of fire is potentially only a couple of points of damage shy of being able to physically harm the Tiefling, and the heat of that would still be painful and distracting even if it's not quite sufficient to cause hit point damage, so I wouldn't imagine that it's realistic to sleep in those circumstances. If the fire is sufficiently large that it can completely surround the Tiefling, that's clearly at least equivalent to being personally on fire and should deal at least 1d6 damage per round, meaning that it will sometimes overcome the Tiefling's Fire Resistance and they would (albeit perhaps slowly) take damage. The rules don't seem to support a Tiefling sleeping comfortably in a bed of fire unless they've got some other source of Fire Resistance that's much more significant. What might be a more plausible could be a Tiefling sleeping in the embers of a small campfire, which would still be far too hot for a creature without Fire Resistance of some kind but should be much less damaging than an actual fire.
91	No. (At least not by default.) The 3.5 Tiefling was printed in Races Of Destiny, and does not include any fire resistance. If Little Lucy the tiefling curls up in a campfire, she will need to make reflex saves to avoid catching on fire (1d6 damage), then another reflex save each round to put the fire out and not take another 1d6 damage. I am not able to find general rules for sleeping, but would expect that to wake Lucy up. If you are using the earlier Forgotten Realms Tiefling (which is 3.0 content, reprinted in the 3.5 Monster Manual but then overridden by Races Of Destiny), Lucy has fire resistance 5. Even with this, the fire still deals 1 point of damage every time the d6 result is “6”. As such, Lucy is awakened (on average) once every 36 seconds. Of course, if it’s important to you that your character can curl up in a campfire, that’s doable. You probably only need fire resistance 6 to make that work, so you can do something goofy like taking two flaws and the feats fiendish heritage, fiendish resistance, and fiendish power (all from complete mage) at first level. That yields fire resistance 6 (plus a bunch of other minor benefits).
92	I am not a lawyer, and I am certainly not your lawyer. I have worked on publications that leveraged the Open Game License, but I was in no way involved in OGL compliance, and in any event none of those publications attempted to do what you are discussing in this question. I offer this as an interested layman’s understanding, and strongly urge you to speak with a lawyer before you publish anything, particularly for sale. Anyway, from the Open Game License, §7: Use of Product Identity: You agree not to Use any Product Identity, including as an indication as to compatibility, except as expressly licensed in another, independent Agreement with the owner of each element of that Product Identity. You agree not to indicate compatibility or co-adaptability with any Trademark or Registered Trademark in conjunction with a work containing Open Game Content except as expressly licensed in another, independent Agreement with the owner of such Trademark or Registered Trademark. The first sentence says that anything published under the OGL cannot “Use any Product identity,” with a capital U in “Use.” That references §1 part g, "Use", "Used" or "Using" means to use, Distribute, copy, edit, format, modify, translate and otherwise create Derivative Material of Open Game Content. Referring to something by name is known, as I understand things, as “nominative use,” which probably falls under the definition of “Use” meaning “to use.” (Ridiculous, I know.) I believe that “nominative use” does not fall under creating “Derivative Material,” but I’m not 100% sure of that either. Anyway, normally nominative use is a thing you can do, but the OGL is saying that you agree not to. Thus, as I have understood things, part of the deal with the OGL is that you can use stuff you otherwise couldn’t, but there is a trade-off where you agree not to do things you otherwise could—which includes this kind of nominative use. So my understanding is that no, you cannot do this under the OGL.
93	Besides the options listed above, the only other way I am aware of for a Wizard to use a shield is the Tenser's Transformation spell from Xanathar's Guide to Everything. Among other things, the spell gives you: You have proficiency with all armor, shields, simple weapons, and martial weapons. The spell does prevent you from performing any spellcasting while the spell is in effect, but otherwise, it does allow a Wizard to use a shield as requested.
94	To get Shield proficiency without multiclassing you could use the Mountain Dwarf, Hobgoblin, or Githyanki races, all of which provide you with light armor proficiency. If your DM allows the Supernatural Gift from Mythic Odysseys of Theros with feats, you could also get the Moderately Armored feat right off the bat at 1st level. Choose to get money for equipment instead of the standard equipment. Then you can buy scale mail plus a shield, for a base AC of 16 +2 Dex max = 18 AC. When you can, buy a Half Plate Armor for AC of 17 +2 Dex max = 19 AC.
95	Blitz games will have 1-5 minutes per side. Most tournaments will have 1-3 hours per side. A popular setup is 1-2 hours per side for the first 40 moves, plus an additional ½-1 hours each after the 40th move. They may also allow Bronstein/Fischer time, if the clock supports it. The official FIDE time settings are 90 minutes for the first 40 moves + 30 minutes after move 40 + 30 seconds for every move. The 2010 world championship was "120 minutes, with 60 minutes added after move 40, 15 minutes added after move 60, and 30 additional seconds per move starting from move 61." I've heard of World Championships going up to 8-hours per side, though.
96	Fast time controls are more current these days. You can find a lot of 30/30 (each player has 30 moves to make in 30 minutes) and G/30 (each player has 30 minutes to make all of his moves) in over the board tournaments. Slow time controls are still out there, but with the rise of Internet chess, even over the board tournaments are going with quicker time controls. On the Internet clubs you can find blitz chess (usually something between 3 and 15 minutes for each player to make all of his moves) and bullet chess (under 3 minutes for each player to make all of his moves); although the Internet allows for slow chess too, it may take a while of waiting, and good deal of patience, to get a game.
97	You are referencing the wrong part of the MTR for you question the relevant part is a few paragraphs above that. Players are allowed to share prizes they have not yet received in the current tournament as they wish and may agree as such before or during their match, as long as any such sharing does not occur in exchange for any game or match result or the dropping of a player from the tournament. As an exception, players in the announced last round of the single-elimination portion of a tournament may agree to divide tournament prizes as they wish. In that case, one of the players at each table must agree to drop from the tournament. Players are then awarded prizes according to their resulting ranking. [MTR 5.2] So what they are allowed to do is combine their prizes (4 + 1 in this case) and split them anyway they choose to, from 5-0 to 0-5 or anything in between. Then one of the 2 players drops from the tournament and they get their prizes and split them up as previously agreed. The portion you quote is intended more for when you are in single elimination brackets, but you haven't gotten to the final 2 yet. For example at an FNM after 4 rounds of Swiss and a cut to Top 8, it is 1am and everyone wants to go home to sleep, as long as all the players and the TO agree they can stop the tournament there and split all of the prizes that would go to the Top 8 spots evenly between all of them. The rules do not state what happens if the prize payout in this case is not evenly divisible by the number of players.
98	These rules have 2 and 3 person variant rules. So yes you can play with 2 or 3 people as well. Here's the relevant rule changes: Two-Player Mah Jong This is good practice for beginners although not quite such a good game as the more typical version with 4 players. One player plays East, the other West. The preliminaries are conducted in the same way as for the 4 player game, 4 walls are built and the game starts with East's discard. The game continues as with the standard game but with the following differences: No chows are allowed and therefore before either player can go Mah Jong, the player must gather four doubles or be entitled to the limit or half-limit score. When scoring, East Wind neither pays nor receives double. When scoring, the player going Mah Jong has a lower score than the player's opponent, the player with the Mah Jong receives the normal total score plus the difference between the scores. Three-Player Mah Jong There are two main ways to play three-player Mah Jong. One common way to play is with four walls but to have the North wind position as a 'dummy'. The alternative is to play with 3 walls in a triangle. The 'dummy' method results in a satisfactory game but there are a number of special rules that are required and Masters Traditional Games believes that the triangular game for three players is simpler and more elegant and so that is our recommendation. In South East Asia, Triangular Mah Jong is so popular that there are companies who make special triangular Mah Jong tables. Triangular Mah Jong for 3 players eliminates the North position completely and the 4 North wind tiles are removed from the set before starting so that a set of 132 tiles are used. The walls therefore consist of 22 stacks (44 tiles) in a triangle shape and there are 3 hands in each round and 3 or 4 rounds as agreed. Other than that, the game is played in the same way as for 4 player Mah Jong. If flowers and seasons are included, one season and one flower is removed, usually Winter and Bamboo tiles so that 138 tiles are used and each wall consists of 23 stacks (46 tiles).
99	Equipment will fall off, and Auras most likely will as well. Equipment can only be attached to creatures. If it finds itself attached to a non-creature permanent, like when the Ojutai Monument turns back into a plain old non-creature artifact, that's illegal, and it'll be detached. 301.5. Some artifacts have the subtype “Equipment.” An Equipment can be attached to a creature. It can’t legally be attached to an object that isn’t a creature. 704.5p If an Equipment or Fortification is attached to an illegal permanent, it becomes unattached from that permanent. It remains on the battlefield. If an Aura says "Enchant Creature" on it, that means it can only be attached to creatures. So if it finds itself attached to a non-creature artifact instead, that's illegal, and it's put into its owner's graveyard. If on the other hand the enchantment said "Enchant permanent" (e.g. Take Possession) it'd be able to stay attached. 702.5a Enchant is a static ability, written “Enchant [object or player].” The enchant ability restricts what an Aura spell can target and what an Aura can enchant. 704.5n If an Aura is attached to an illegal object or player, or is not attached to an object or player, that Aura is put into its owner’s graveyard.
100	Bullet: one minute per player for all moves Blitz: 5 minutes per player for all moves Quickplay: 20, 30 or 40 minutes per player for all moves Quick tournament: 1 hour 30 mins to reach move 35, then 30 mins to finish (per player) FIDE tournament: 1 hour 30 minutes to reach move 40, then 30 mins to finish, plus 30 seconds per move (per player) Slow tournament: 2 hours to reach move 40, then one extra hour to reach move 60, then 40 mins to finish (per player) Lightning: 10 seconds per move Hourglass: 1 to 2 mins each to start with. the time you lose is added to the opponent's clock, and vice versa Fischer delay: 5 seconds (usually, can be less) are added to your clock after every move
101	Forcing players to trade is not part of the game. You can try to make her an offer. But she has the right to refuse it. If a player has one of each color, they have a strong trade point because they can stop the formation of all combinations. I advise you to make her an offer she will benefit from. So to guarantee her at least one full set she can use to increase her wealth. But maybe she likes your company and goes for the slow game.
102	We have a mahjong set and regularly play with only three people but using the same rules as the four-player game. The only difference is that it is often slightly easier for someone to win with three players. That said, we still goulash every so often. The two player game is also possible using different rules, usually with making all pairs in a hand, however I find this method a bit boring so we still play normal rules with two players. That way someone always wins a hand, just more quickly. One piece of advice I have is to treat the game as fun! I have met many people who are so serious about what is or isnt 'allowed' in playing mahjong that it can be a bit off putting. Why not try the usual play with fewer people--it's just as much fun even if you aren't changing the rules to suit fewer than four...
103	In the series Smallville, Superman is weak to any form of magic, or at least doesn't have any kind of protection against it. Just as with anyone who is heavily protected, a chink in the armor can prove fatal. There's an excelent article about this very topic as well on How Stuff Works. Basically, it pits Superman vs Harry Potter and Gandalf, to which they suppose he would lose both battles.
104	In Superman/Shazam!: The Return of Black Adam, it is revealed that Superman is susceptible to Black Adam's magical powers. Outside, the battle rages on between Superman and Black Adam. Superman is barely able to hold his own against the magical based powers of his foe. Superman is again subdued by his adversary and is rendered unconscious.
105	From Wookieepedia: Due to the weightlessness of plasma and the strong gyroscopic effect generated by it, lightsabers required a great deal of strength and dexterity to wield, and it was extremely difficult—and dangerous—for the untrained to attempt using. However, in the hands of an expert of the Force, the lightsaber was a weapon to be greatly respected and feared. Basically, the Jedi order is an order of discipline, and a demonstration of that discipline is the use of their chosen weapon. To the general public the light saber would be nearly anachronistic by the time of the events of the original movies. Pointed to by Obi-Wan saying that it "This is the weapon of a Jedi Knight. Not as clumsy or random as a blaster; an elegant weapon for a more civilized age." 'Normal' people don't use them because they are too difficult, and too obsolete in most people's hands. While it is true that non-force attuned people physically CAN use light sabers, they generally avoid it because they are dangerous and not worth it in the end. Add to that the fact that all of the really cool things about light sabers (deflecting blaster bolts etc) generally come from force-influenced reflexes and so at its best in a normal persons hands its a glowing sword in a world filled with guns.
106	The answer is obviously yes, if only because Grievous wasn't a Jedi or Sith and he was successful at handling 4 lightsabers simultaneously (and if I remember correctly, even managed to defeat several Jedi before facing Obi Wan). An extremely skilled one, according to Wookieepedia: After being made Supreme Commander, Grievous proceeded to wreak havoc on the Republic for the three-year–span of the Clone Wars. The general was trained in the art of lightsaber combat by Dooku himself, who was also a Sith Lord. Grievous was a quick study and eventually came to be recognized as one of the most skilled duelists in the galaxy.
107	There have been records of non-Force-sensitive people using lightsabers, but because the blades don't have any weight, they are rather awkward to use. Force-sensitive people can wield them the way they do because of the extra sense and reflexes the Force gives them.
108	While it might be difficult for a non-force user to wield and fight with a lightsaber, it has been known to happen: From Ask A Jedi: Han Solo did it, but didn’t fight with it. In a non-canon story Boba Fett did however. In Episode III, the Clone Wars miniseries, and Star Wars: The Clone Wars General Grevious does too. In Star Wars: The Clone Wars season 2 Pre Viszla does it as well as one of the thieves who stole Ahsoka’s. In season 3 of the same show we know Cad Bane jumps on the bandwagon as well. Finally we have Anja Gallandro, who appeared in Star Wars: Young Jedi Knights in the novel Return to Ord Mantell by Kevin J Anderson and Rebecca Moestra. So we have G, T, and C canon examples of it happening.
109	In Kingdom Come when Wonder Woman and Superman are in space, Superman cuts himself on her sword. Wonder Woman warns him to be careful as he is weak to magic and the sword was forged by the gods. Since KC Superman was identical to normal universe superman until the divergence point, then the answer is clearly yes. This is further expanded on in World War 3 when Black Adam goes crazy, and Superman states he isn't a match for him. Those are the most prominent examples that comes to mind.
110	No. Superman is no more vulnerable to magic than any other person in the DC Universe. But given his range of powers and normal ranges of invulnerability, this is counted as a great weakness relatively speaking. While magic-users do not abound in the DC Universe, there are a number of magical phenomenon which can make confrontations against those forces a surprise for the Man of Steel. Superman is indeed vulnerable to only a tiny slice of phenomenon in the DC Universe, and each iteration was slightly different in their representation of those weaknesses. We will use the Golden Age Superman, Pre-Crisis Superman and Post Crisis Superman as the definitive canon models as reference. DCnU Superman's limits are still being defined, but it is likely they will not deviate too far from the norm. All canon Supermen: Derived their powers from the yellow or higher energy wavelength stars. Orange or red stars do not completely trigger the genetic capabilities that give him his powers. Under orange stars, his powers are half of their strength and under red stars he has no access to his superhuman abilities. While this has never been effectively explained, Kryptonite appears to possess the ability to prevent him from accessing the solar energy somehow stored within his cells. In addition to denying him access to his solar powers, prolonged exposure is both dangerous and ultimately toxic to him. Upon the removal of Kryptonite, depending on the exposure, his access to his powers will return relatively shortly. Only a near-death encounter will leave him drained of power. possess a weakness to specific wavelengths of radiation. Advanced species who knew of Kryptonians (such as the denizens of the Fourth World, i.e. Darkseid, Highfather and other New Gods, as well as extraterrestrials, particularly during the period of Pre-Crisis Superman who spent a considerable amount of his time in space) used weapons capable of producing radion energy. Such weapons were rare but were capable of affecting Superman. Pre-Crisis Superman was also vulnerable to exotic radiations such as Q-radiation and weapons from advanced civilizations that either harnessed red sun wavelengths, or with sufficient energy could overcome his invulnerability making him vulnerable to their effects. Green Lanterns (and presumably the Guardians) can also use their rings to emulate the wavelengths of Kryptonite radiation. have less of a weakness and simply an inability to effectively counter magical energies. The true magic of the DCU has always been considered an effect of Chaos and derived from the Lords of Chaos. Such effects of Chaos render a being whose powers are derived from Order less than effective. Superman is not an agent of Order, only that his powers are created from a technological process that is Ordered. have a vulnerability to magic that is no greater than any ordinary human's and Superman has been able to fight magical foes, granted with more difficulty, but his overall effectiveness is on par with any of his other villains. One supposition used during the Byrne era's Superman was that magic bypasses his ability to defend against it due to his inability to understand it. Other suppositions assumed his alien heritage left him vulnerable but who can be sure? As usual, DC has never effectively explained why magic works against him when so many other things do not. Inconsistent storytelling with poorly defined mechanics Given that magic is not explained effectively, it can be inferred that metahumans such as Black Adam and Captain Marvel who derive their powers from a magical source are more effective against Superman and that would be a misnomer. The strength of Hercules used by Captain Marvel is super-strength on par with Superman's. His ability to affect Superman is because his strength is as great as Kal-el's not because it is an active magical effect. Unless the Captain or Black Adam are using a directed energy attack such as the Summoning Lightning Discharge against Superman, or a directed magical energy attack, it is a struggle of physical equals. However, the summoning lightning is a powerful directed magical attack and has been used against Superman to stun and weaken him. Magical objects, weapons and the like are able to affect him and bypass his natural defenses. Hence Wonder Woman's weapons, forged by powerful magical divine beings, are more than capable of harming Superman. He has also been scratched by werewolves and vampires whose magical nature is inherent and required for their very existence. In most storylines, Superman has been considered to be equal to or slightly ahead of Captain Marvel in terms of raw power and durability. Superman has always been considered to be the DCU flagship hero on Earth in terms of physical superiority with Captain Marvel being considered second to him and titled "the World's Mightiest Mortal". Given that DC prefers to have the two characters locked in a perpetual dead heat because it promotes fanboy enthusiasm, it will likely never be revealed which of them is more powerful. A note: All of the references used as examples in other answers are non-canon references, Superman/Shazam!: The Return of Black Adam, Smallville and Kingdom Come are all divergent timelines/continuities and do not reflect canon Superman. Nor should they be used as definitive references to the character.
111	Presumably, "their tears have healing powers" as Dumbledore puts it is an accurate description. You can not "heal" an inanimate object, which the diary is, so Phoenix tears would have been ineffective on the notebook. Moreover, the tears may have been able to neutralize the Basilisk poison, but the poison ALREADY did the damage to the notebook - it wasn't like it was slowly spreading around the notebook with the blood flow (as was happening to Harry) doing more damage.
112	Superman has indeed been shown to be vunerable to magic, at least in some universe versions For example, when he encountered Arathaza (New Earth, written/illustrated by John Byrne), he is essentially defeated, Arathaza draining all his life force and power from him. At the end of the battle he is an old white-haired and weak man. Eventually he is able to trick Arathaza, using only human powers and cunning to take away and destroy her magical staff, thus rendering her powerless. He then immediately regains his powers.
113	I can still add: The Art of The Hobbit: Thror's Map. Copied by Bilbo Baggins Map of the Misty Mountains and the upper part of the Great River Map of the Lonely Mountain and surrounding lands Plans of the Lonely Mountain The Lonely Moutain and map of the Long Lake Wlderland, earlier version The Shaping of Middle-earth: the First 'Silmarillion' Map 'The Westward Extension' 'The Eastward Extension' 'Diagram I-III': Diagrams of the World Map IV: Arda in Valian Year 500, after the fall of the lamps Map V: [Arda] After the War of the Gods The Lost Road Chasm of Ilmen I,II The Second 'Silmarillion' Map (that's a really good one) The Return of the Shadow: older Map of the Shire Plan of Bree The earliest map of the lands south of the Map of Wilderland in The Hobbit The Treason of Isengard: The First Map of The Lord of the Rings (Maps I, Ia, II, IIIa, III, IVa-e) (Sketch-plan of the scene of the Breaking of the Fellowship) The War of the Ring: Frodo's Journey to the Morannon Minas Morghul and the Cross-roads Plan of Shelob's lair (1) Plan of Shelob's Lair (2) Harrowdale The White Mountains and South Gondor Minas Tirith and Mindolluin Plan of Minas Tirith The Second Map (West) The Second Map (East) Silmarillion: Map of Beleriand and the Lands to the North The Realms of the Noldor and the Sindar Unfinished Tales: Map of Númenor The Children of Húrin Simplified map of Beleriand Pictures: Map V of Arda: Plan of the Lonely Mountain: Early Map of Wilderland: Second Silmariliion Map:
114	Anyone could use a lightsaber, but Jedi and Sith have force reflexes to deflect bullets and do awesome stuff. So for non-force wielders, a lightsaber isn't an effective weapon at all!
115	"Every direct hit from a laser seemed to kill a storm-trooper outright, " Not necessarily true. We see troopers being hit by laser fire and falling, but we don't follow any of them to learn their actual fates. As Wookieepedia explains in greater detail, some of the basic protections the armor affords includes: The armor and body glove worn beneath were designed to disperse the energy of a blaster bolt and insulate the wearer, lessening injury It could partially deflect or disperse energy from low, medium, and high-energy blaster bolts. While the trooper may be left incapacitated, they would survive long enough to receive medical treatment. It deflected stun beams and provided general protection against explosions and shrapnel. Glancing blaster bolts were deflected or damage-reduced The armor included air filters and were fully sealed against chemical and biological attacks. Some were effective in vacuum conditions for limited times. The body glove worn beneath provided protection in hot or cold climates.
116	I always assumed that the Trooper armor was part of an all-purpose enviromenal battle suit. If you think of it in terms with our own bulletproof vests that police wear, or the Improved Ballistic Armor (IBA) that coalition forces wear, then it is there to improve the chances of a wearer's protection. The original flak jackets were made for shrapnel, and had insertable metal plates that stopped pistol rounds, while we now have plates that can stop military-grade rounds. Yeah. Nothing's foolproof. If you also think of what the Star Wars weapons are capable of (blasters are essentially particle accelerators, while lightsabers are high-frequency tight-beam energy swords), what could one use to protect against as such? Practical armor probably isn't practical; too bulky, too heavy, etc. Remember that we've had bullets for a lot longer than we've had a means to personally protect ourselves from them. You would think that a protable deflector shield would be rather standard issue, as the Gungans had them in the Battle of Naboo.
117	In the old West End Games Star Wars RPG (which was considered low canon) Stormtrooper armor is actually fairly good. It provides something like +2 resistance against energy weapons and +2D against physical. This means that when you rolled to soak damage from a blaster, you added 1D6 to your roll (for an average stormtrooper, that would make it 4d6). Against physical, you added 2d6 (making it 5d6 for an average stormtrooper). This sounds impressive (4-26 points of damage soaked) until you realize that Han's blaster (a heavy blaster pistol) deals 5d6 damage, and the blaster carbines and rifles that other characters use deal 5d6 damage as well. Lightsabers start at 5d6 damage, and add damage based on your force abilities. Pretty much any energy weapon does the same (or more) dice worth of damage as a typical stormtrooper (in armor) can soak. This gives a stormtrooper about a 50/50 chance of taking damage from any shot from the weakest blaster. The long and short of it? Stormtrooper armor isn't that effective, it's just the best there is (in common usage). Much like modern body armor isn't able to stop typical assault rifle AP rounds at typical distances, stormtrooper armor isn't designed to make the wearer invulnerable. It just serves to absorb some of the damage and give you a better chance at surviving.
118	He was referring to Simon, or perhaps merely how horrifically Simon managed to put his foot in his mouth when talking with Kaylee. Wash and Zoe come in right after this conversation between Simon and Kaylee: SIMON (smiles) Ah... Well, you're a, a kind of a genius when it comes to machines... you always say what you mean, and your eyes are... KAYLEE Yeah? Eyes, yeah? SIMON And, um... I don't know how to, um... (joking) Plus, every other girl I know is either married, professional, or closely related to me, so you're more or less, you are literally the only girl in the world. Those famous eyes of her darken considerably. She draws back. KAYLEE Mm. That's a hell of a thing to say. SIMON I was joking... KAYLEE No, no, I get it. I do. Back on Osiris you probably had nurses and debutantes crawling all over you. But down here at the bottom of the barrel, it's just me. SIMON No, that's, that's, that's not even -- KAYLEE Well, I'm glad I rated higher than dead bessie here. < Why don't you tell the cow about its beautiful eyes? > [Nee GAO-soo NA niou, TA yo shwong mei-moo?] She is storming out just as Wash and Zoe are coming in. Simon watches Kaylee despairingly. WASH Oh my god, he's grotesque! Oh, and there's something in a jar. Immediately after, Zoe comments that he (Simon) scared her (Kaylee) away again, and asks if there is anyone he is good at talking to, so it seems likely that Wash and Zoe overheard at least part of the conversation.
119	This is revealed in The Search, a comic book set after the events of The last airbender: Zuko's mother used to live in a simple village along with her boyfriend. Then the Fire Lord Azulon, upon finding the location, decided to marry her to his son, prince Ozai. This is because he found out that she was avatar Roku's daughter, and wanted to strengthen the royal bloodline. It seemed like Roku tried to hide her for that very reason. She couldn't refuse. Fast forward several years, she kept sending secret letters to her boyfriend in the village. She suspected that the letters were being intercepted, so she wrote a lie in one of these letters implying that Zuko is actually the son of her and the boyfriend, rather than Ozai's. As suspected, Ozai was indeed intercepting the letters; he was furious with that lie (he knew that it was a lie because he had spied on her for several months before meeting her) and confronted her. He decided that as punishment, he would indeed treat Zuko as if he wasn't his own son. Years later, when Azulon commands Ozai to kill his firstborn to have a taste of Iroh's loss during the war, Ozai accepted immediately. Zuko's mother stopped him and offered him a deal: she would make a poison that Ozai could use to kill Azulon and take the throne, in exchange for sparing Zuko. He accepted, but at the condition that she would leave the palace because he feared her ability to make such deadly poison. Zuko's mother went back to the village where she found her boyfriend again. They met a spirit with the ability to change someone's face and memories, and she decided to get a new face and erase her memories (so she forgot about Zuko, Ozai, Azula, Roku, etc) and lived happily. After the events of The Last Airbender, Zuko asks for Aang's help to find her. Azula also helps. They find her and restore her memories. She stays at the village.
120	They're as alive as King Arthur was around the end of his story. So not really. "Lady of the Lake" ending was quite clear on that matter. The scene was quite a direct Avalon reference, but you know that yourself. As long as Witcher video games are considered canon, they both got better though. Geralt reappeared in Witcher, and Yennefer is also set to appear in Witcher 3. As long as "Storm Season" is considered canon (which is not an obvious consideration, if you ask me), Geralt is also alive in some capacity several decades after the saga concludes, in Nimue's (the sorceress who studied Witcher's legend in "Lady of the Lake") times. Though that scene is also open to interpretation.
121	This is dealt with in the EU novel "Labyrinth of Evil". Master Sifo-Dyas commissioned the Clone Army, presumably with a small down-payment and a blank cheque from the Jedi's own accounts. Count Dooku (with the assistance of Senator, then Chancellor Palpatine) kitted the army out with fancy hardware and big ships using his own vast personal wealth and any other cash he could lay his hands on: “Questioned, the Kaminoans were. Furnished much they did.” “Did they?” Obi-Wan said in surprise. “When?” “Reticent they were when first to Kamino I went. Only what already they had told you, I heard. That Sifo-Dyas the order placed; that Tyranus the donor clone furnished. That for the Republic the clones were. Seen by the Kaminoans, neither Sifo-Dyas nor Tyranus was. But later, after attacked Kamino was, more I learned from Taun We and Ko Sai. About the payments.” “From Sifo-Dyas?” “From Tyranus.” Although the book isn't G-canon, it's noteworthy that the final 3 episodes of season 3 of Clone Wars were based on this novel. As to how Dooku/Palpatine/The Republic/The Jedi were able to afford to create a enormous clone army, it would seem to boil down to a range of payments being sourced from a variety of places: Dooku's vast personal fortune Funds skimmed from the Republic's budget by Palpatine Money taken from the Jedi budget by Sifo-Dias. Money appropriated from the Trade Federation by Dooku Sith funds.
122	Hego Damask, a leading member of the Intergalactic Banking Clan, provided Jedi Master Sifo Dyas the funds for the Clone army. Sidious first convinces Damask that the Republic must lose its faith in the Jedi. Sidious took a moment. "We will have to exploit their vanity and blind obedience to the Republic," he said with greater confidence, and as if the truth of it should be obvious. "They must be made to appear the enemies of peace and justice rather than the guardians." Damask is concerned about the PR of massacring Jedi. "Great care has to be taken not to turn them into martyrs, Darth Sidious--if in the end we want the beings of the galaxy to turn their backs to the light side of the Force." Damask at this point, wants to create an army of force-resistant creatures called the Yinchorri to fight against the Jedi. He meets with Kaminoan cloners and discusses the possibilities. He does not tell the Kaminoans why he wants to use Yinchorri. The Kaminoans explain to him that it would be a difficult procedure, but possible. They also explain that their facilities are too small to host an army. Damask provides funding for the Kaminoan cloning facilities so that they can create an army. "More important," Lac Nor said, "while we might be able to grow a few clones, our facilities are at present inadequate to produce an army of any size." "We would also need to consult with military specialist regarding programming," Ko Sai added. "That can all be arranged," Damask said. "Would you have any objections to working with Rothana Heavy Engineering?" "Of course not," Ni Timor said. "Then Damask Holdings can provide whatever funding you need." Ko Sai's eyes appeared to widen. "The Prime Minister will be very pleased to learn of this". Damask shares his concerns with Jedi masters Dooku and Sifo-Dyas about a growing threat of star systems becoming disillusioned by the Republic. During their conversation, Damask remembers what Sidious told him before (see the first quote I posted). He then decides that the clone army should be used to fight with the Jedi rather than against them. Mulling it over anew, Plagueis began to wonder whether he had taken the wrong approach on Kamino. Perhaps, he thought, it would be better to have the Kaminoans create an army capable of fighting alongside the Jedi rather than against them ... Damask later approaches Sifo-Dyas and says that an army must be created for the Republic. "Master Jedi, I want to share with you a suspicion I've been carrying like a burden." Damask paused. "I have reason to suspect that the Trade Federation has secretly been procuring more weapons than anyone realizes." ... "To go further, I predict that a civil war is brewing." ... "The Jedi will be too few to turn the tide. A military needs to be created now, while there's still a chance." I skipped the quotes for the sake of brevity, but Sifo-Dyas is reluctant at this point and encourages Damask to talk to Supreme Chancellor Valorum. Damask explains the need for secrecy by saying he can't go public with his beliefs because he would be going against some of his own clients. Sifo-Dyas is convinced that Damask's concerns are genuine and admits his own concerns. "You have read my thoughts, Magister. I have also sensed that war is imminent. I've confessed as much to Master Yoda and others, but to no avail. They give all appearances of being unconcerned. Or preoccupied. I'm no longer sure." Damask tells Sifo-Dyas about the Kamino cloning facility and their ability to raise an army. "I believe that the Kaminoans could be induced to grow an train a cloned army." Sifo-Dyas took a long moment to reply. "You said yourself that the Republic would never sanction an army." "The Republic needn't know," Damask said cautiously. "Neither would the Jedi Order have to know. It would be an army that might never have to be used, and yet be available in reserve should need ever arise." "Who in their right mind would fund an army that might never be used?" "I would," Damask said. ... "The Kaminoans will not create an army for me, but they would do so for the Jedi Order. They have been fascinated by the Jedi for millennia." ... "The Kaminoans need only a modest down payment, which I could provide to you through untraceable accounts I maintain in Outer Rim banks." Sifo-Dyas tells Damask that he has to think about it. Damask and Palpatine discuss this later on. Palpatine thought about it for a moment. "And Sifo-Dyas? Will he do it?" "Even if he decides against it, there may be a way to place the order in his name. But the Force tells me that he will do it." @Richards answer explains some of the events that occurred with Dooku and Sifo-Dyas after this.
123	I'd like to just add a point that hasn't been touched on I don't think, though all the above is pretty much spot on as well. Consider for a moment taking a blade-less sword, just the hilt and how quickly it could be wielded with no weight in the blade itself. Now attach the deadly light saber to it, you can move it so quickly that I would argue in a real fight it would be quite deadly to a non jedi opponents in close combat, but very deadly to the user as well. One wrong reflexive twitch and you cut yourself wide open. It would be like wielding a real sword, to an extent, but never so much as touching any edge of the blade even lightly, sharp side or not. The jedi have situational awareness of exactly where the hilt is pointing, and where it is going next, it would be very deadly to the user if you didn't have that awareness. Basically part of its amazingness, the combination of quick and deadly, the ability to maneuver it almost instantly with the flick of a wrist, is what also makes it to easy to hurt yourself with and too impractical for non jedi. It has a far too high expense to usefulness ratio to be practical for everyone even a well off fighter to carry I would think. That being said, given no other option in close combat, should it come to that, if a light saber were nearby and available, I would certainly expect that anyone would attempt to use it with no other weapon available, likely even over conventional close weapons. In season 1 or early season 2 of the clone wars, princess Amadala is taken hostage with some other senators and happens to have Anakin's lightsaber. She poses to another senator whether she should use it should she need to. I think this scenario is very realistic, it is still a devastating option in close combat, but it is more useful in situations like this where you wouldn't ideally find yourself as a non jedi in the first place. Non jedi are going to spend their efforts not being put in a situation where a lightsaber would ever be useful. Just like today's war forces, or even home protection, you never want to be close enough to come to blows with the opponent ideally. Also, while the movies and such focus on activities surrounding jedi, keep in mind that jedi are extremely rare (I seem to recall reading somewhere at the height of the council, there were around 10,000 known jedis, and estimates figured ten times that many unknown, so 110,000 out of trillions of being force attuned, and 10,000 out of trillions that actually practice). The odds of coming across that kind of weapon, or having to defend against it are quite rare in reality, and even if you had to defend against it, you aren't going to beat a jedi in a lightsaber dual, fighting fire with fire does not hold here for non jedi. One unlikely scenario.... If for some reason the price went down and proliferation of lightsabers went up, like say if an army decided it would/could equip all it soldier with lightsabers, and it made tactical advantage to do so, then you'd suddenly see an increase in the use by everyone else so that they had some sort of close combat defense against it. You'd also likely see unintentional self inflicted casualties rise in said armies!
124	Mandalorian Armor used Mandalorian Iron, which used a special refinement technique that was lost to the galaxy at large with their defeat at the end of the Mandalorian War (Boba Fett's armor was likely worth a bantha's weight in gold). Also, the empire, as several above posters pointed out, equipped storm-troopers by the billions. There were roughly 1.7 MILLION worlds under imperial control, the total garrisoned strength of the storm troopers would have bankrupted the empire to equip in high-end mercenary armor. That being said, they did have elite corps like the imperial guard and shadow troopers that were supposed to have better armor. As for storm-troopers, even us issue isn't truly top-of-the line, it's common knowledge that low-bids are a HUGE consideration in who the senate picks to get the contracts to supply the military. And that is in the US, where human rights and lobbyists work to promote the value of a soldier's life. Now, take the empire, whose battle strategy in space combat was "throw swarms of the cheapest, fastest, unshielded guns with cockpits against the enemies and they'll go down eventually". The life of their soldiers was obviously not a top resource priority. Storm trooper armor would be the least expensive way the empire could find to field as many troops as possible in as many different environments as possible. The empire spent money on WMD and terror; death stars, clones of the emperor, star destroyers, at-ats, super star destroyers. They did not spend money on individual frontline troops.
125	If you think about it there have been plenty of non-Force sencitives who have used lightsabers: Han Solo on Hoth, Viszla and the Darksaber, the girl who stole Ahsoka's lightsaber and was stopped by the old wise Jedi with the white saber, and Cad Bane when he fought Obi-Wan with Quinlan Vos's lightsaber. Boba Fett was able to use a lightsaber against Vader, and General Grievous used a lightsaber. Plus there are special laser swords called lightfoils that were used by nobles of some sector I can't remember at the moment. These nobles were called saber rakes.
126	I have different opinion on how book story ends. As you know, Ciri is ruler of space and TIME. She has these abilities and she can use them on herself plus other living beeings (horse Kelpie). After massacre in Rivia when Geralt was dying and Yenefer was trying to help him, they were taken to another world - i think it was just some world/space which should represent traveling in time. After leaving Geralt and Yenefer, Ciri told the story to a boy and she mentioned Geralt's and Yenefer's wedding. This wedding was well described in second or third book (i am not sure). After wedding Ciri told that she have to leave so she already knew something bad would happen in the future. When i was reading this part about wedding i was very confused because it absolutly did not fit to the rest of the story - Ciri was young girl in this part of the story and Geralt and Yen would not let her leave alone so she had to be older (this is possible because she returned in time). So i think that the wedding was the point where story should actualy continue because everything what happened after wedding was only in Ciri's memory. It actualy happened but Ciri threw Geralt and Yenefer to this moment. Book also says that they died peacefully - Geralt of heart failure and Yenefer right after him.
127	Incredible Hulk/Savage Hulk She Hulk Savage She Hulk Grey Hulk/Joe Fixit Maestro Hulk Skarr, Son of Hulk Professor Hulk Rick Jones Red Hulk Red She Hulk Zombie Hulk Hulked Out Heroes
128	It depends on how you count. There are four separate characters called "Hulk". However, there have been several very different incarnations of The Hulk (Bruce Banner); there are also a few other gamma-powered characters that aren't called Hulk but have similar powers. The Original The original Hulk is, of course, Bruce Banner. His most popular, familiar, and longest-running persona is as the green-skinned Hulk. This version is usually called the "Savage" Hulk, because once Banner turns into this version, he is out of control. However, Banner has gone through a few other iterations of the Hulk. For a period of time, he was the Grey Hulk, using the alias Mr. Fixit, where he was in full control of his mind even as Hulk. He also, on a few occasions, has "merged" his various personas together, such as his Doc Green persona (the Savage Hulk with Bruce Banner's mind). The Red Hulk This is General Thaddeus Ross, who allowed himself to be turned into a Hulk to get revenge on the Savage Hulk. Red Hulk get stronger as he absorbs energy, but he also gets hotter and can "overheat". This Hulk no longer exists; the Doc Green version of the Hulk "cured" him of his gamma powers. She-Hulk A lawyer named Jennifer Walters, who is a cousin of Bruce Banners. At one point, she received a transfusion of his blood, and it also transferred his gamma poisoning to her. Unlike Banner, Walters has control over her transformation, and maintains her mind in her Hulk form. She tends to maintain the Hulk form most of the time. Because she seemed to have control over her Hulk, Doc Green allowed her to keep her powers. Red She-Hulk Bruce Banner's ex-girlfriend, and Thaddeus Ross's daughter, Betty Ross was turned into Red She-Hulk (at the request of her father), but secretly brainwashed her to kill her father. She eventually regains control over her mind, but never really comes to grip with her Hulk persona. Doc Green took her powers away as part of his quest to be the only gamma-powered person on Earth. Gamma-Powered Non-Hulks Several other characters have powers similar to The Hulk, but aren't called that. Some of the more notable: Abomination: Emil Blonsky, a frequent enemy of The Hulk. Retained his human intelligence but cannot change his body back. Still alive, AFAIK. (Also notable for being the bad-guy in The Incredible Hulk.) Doc Samson: Leonard Samson, on on-again/off-again Hulk enemy. Originally a colleague of Banners, he exposed himself to gamma radiation siphoned from Hulk and became a bulked up, though not "Hulked-out", version of himself. Currently still dead. Skaar: Hulk's son. Depowered by Doc Green. A-Bomb: One of the personae of Rick Jones. Depowered by Doc Green. Alternate-Universe Hulks All of the above are from the main Marvel (Earth-616) continuity. There are other variants of The Hulk that have appeared in alternate universes, including Zombie Hulk, Maestro Hulk, and Ultimate Hulk. There are also a few variants of the other Hulks; particularly notable is Lyra, an alternate universe She-Hulk that is currently trapped on Earth-616:
129	In addition to the number of Hulks already mentioned, it it worth noting that Bruce Banner has a somewhat-infinite number of hulks within his subconscious that could emerge, each a metaphor for a different aspect of his personality. It just so happens that Savage Hulk and Joe-Fixit are the strongest entities of his subconscious and thus always "win" to be released into the world. A couple other noteworthy manifestations that have not been (or very rarely) released are 'Devil Hulk' and 'Guilt Hulk'. This 'subconscious' story-line came about in the early 90s during Peter David's run, I believe. There is a great panel explaining this all in 'Hulk: The Incredible Guide', though I cannot find a picture online.
130	Well I think the stormtrooper armour saved LucasFilm a lot of money. They could use the same actors to play different stormtroopers in each scene, and the viewer wouldn't know any better, unless you paid attention to their height and gait.
131	There are two major reasons why non-force users aren't seen using the light saber. The first I think is often exaggerated because of various lazy references in the literature which can no longer assumed to be part of the new cannon. There are early references to the "gyroscopic" effect making it difficult to use a blade but frankly I think the original movies themselves undercut this notion because of the ease with which Han uses one to cut open the TaunTaun and the ease with which Luke waves one around in the first movie. I think if there were really was a gyroscopic effect going on we would see some kind of difficulty in controlling it. The counter that Luke is force sensitive is very weak because it is demonstrated very clearly that what he lacks is the ability to control the force. Which he would require in a gyroscopic type test. The first and most important reason that the lightsaber isn't more popular among non force-users is actually very simple--they can't get their hands on one. Jedi are very rare in a Galactic sense, and their weapons are therefore also rare. One isn't going to simply find one lying about in a junkyard. More importantly though they are the only source of constructing them. They also (and this would appear to be valid in new canon based on Rebels) require kyber crystals to construct. And seem to be constructed using the force. The second reason is practicality. They are, in an absolute sense, bringing a sword to a gun fight. If you brought a lightsaber to a fight against a blaster you will lose (unless you are fighting a stormtrooper who can't hit anything except Aunt Beru and Uncle Owen). If you brought a lightsaber to a fight against a Jedi you will lose even faster. The advantages Jedi have in fight with them are mostly due to the force. There is one other reason, but it is mostly related to story telling. Lucas wanted them to be the knights (not unlike the knights of the round table) of the romance. They were chivalrous and noble. Swords are the weapons of knights. In early mockups they were a commonplace weapon, however they were quickly restricted to the the Jedi to make them more distinctive. In summary they can and do use them. They just almost never get the opportunity.
132	Han solo used Luke's Lightsaber in Episode V! Watch this:
133	Yes. As we know, Kylo Ren is neither a Jedi nor a Sith, yet he uses a lightsaber. Ergo, some people who use lightsabers are not Jedi or Sith.
134	Here is evidence that the armor offers some protection. In line with phantom's answer, the energy blast gets dispersed although the trooper may be knocked out for a while. In the canon Clone Wars cartoon series (S2 E10, "The Deserter"), Rex gets shot just below the neck but survives. You can see the black mark on his suit. Given that the sniper rifle used on him is more powerful than a normal blaster, I'd imagine that the armor is probably reasonably effective.
135	Now first of all, I'll concentrate solely on book canon here, since you're asking about the ending of the actual novel series. In the games Geralt is very much still alive, however you construe that out of the book ending. In lack of an official English translation, let alone one I have at hand, the excerpts quoted here have been translated into English by me (as accurately as my abilities allowed me) from Erik Simon's official German translation of Lady of the Lake. One thing you might want to consider is Ciri's vision. At the moment when Geralt is hit by the pitchfork, he remembers the time back in Kaer Morhen with young Ciri, when she repeatedly had strange visions and dreams, including about Geralt's death: "Tell me again what she said", Vesemir commanded and emptied his cup in one gulp. "Word for word." "Word for word doesn't work", Geralt said, his view directed into the blaze. "But the meaning, if there is meaning in looking for a meaning in there, was this: Me and Coën will die. Teeth will be our demise. Teeth will kill us both. Him two. Me three." And if we remember, Coën indeed died at the battle of Brenna. When he is brought into Milo "Rusty" Vanderbeck's field hospital the following conversation occurs: "Strange." Rusty tried to wipe his face with his elbow, but even that was full of blood. Iola came to his assistence. "Interesting", the surgeon repeated and pointed at the patient. "Stung with a fork or some kind of partisan with two tips ... One prong of the weapon pierced the heart, there, please look. The chamber is doubtlessly penetrated, the aorta nealy severed ... And he breathed just one moment ago. Here on the table. Hit right in the heart he made it to this table ..." "Do you want to say", the trooper from the Voluntary Light Cavalry asked gloomily, "that he is dead? That we carried him out of the battle in vain?" "It is never in vain." Rusty did not lower his gaze. "But to say the truth, yes, he does not live anymore, sadly. Exitus. Bring him ... Hey, damn ... Take a look at this, girls." Marti Sodergren, Shani and Iola bent over the corpse. Rusty pulled the eyelid of the dead man back. "Have you ever seen something like this?" All three shrugged. "Yes", all said in unison. They looked at each other, as if being a little astonished. "Me too", Rusty said. "This is a witcher. A mutant. This would explain why he lived so long ... This was your combatant, you people? Or did you bring him by coincidence?" "This was our companion, sir doctor", the second voluntary, a beanpole with bandaged head, confirmed grumpily. "From our squadron, a voluntary like we. Alas, he could handle a sword! His name was Coën." So Coën did indeed die (and Rusty's competent medical opinion leaves no doubt in this) from some kind of two-pronged fork, like the vision prophecied. And Geralt is just about to be stabbed by a three-pronged pitchfork, too. This might already be a very strong hint that Geralt is indeed about to die right now. And in fact Yennefer has a similar flashback (albeit not directly when she supposedly dies by trying to heal Geralt, but a little ealier before she helps Triss summon the hail) to an earlier experience of hers, when she unsuccessfully tried to kill herself and woke up in bed at the care of Tissaia de Vries, who also spoke about Yennefer's actual future death: "You will live." The voice of Tissai was factual, serious, even strict. "Your time has not come yet. When it comes, you will think of this day." What she indeed does right now. Now it is true that those might just be red herrings to make us think the end is nigh when it actually isn't (and in fact this wasn't the exact point of Yennefer's supposed death yet). But seeing how both of them have flashbacks to some kind of death prophecies, one very clear and accurate and one a bit more fuzzy, it is a strong motif that adds to the bigger picture. Then we have to consider the mythical nature of their waking up on some strange unknown meadow supposedly being together forever. Neither do I think this is just one of the many parallel worlds that Ciri can just switch through at will and where she dumped them to be happy for now and to visit them whenever she pleases, it is somewhere else, it is something else. This is evident from her tearing eye when she recounts how Geralt and Yennefer marry later, with all the other living and dead characters joining the party, an obvious sugar coat ending: "So what was then?" "Well, what", she snorted. "They married." "Tell." "Ah, what's to tell there? There was a happy feast. Everyone came together, Dandelion mother Nenneke, Iola and Eurneid, Yarpen Zigrin, Vesemir, Eskel ... Coën, Milva, Angoulême ... and my Mistle ... I was there myself, ate and drank. And they, to say Geralt and Yennefer, later had their own house and were happy, very, very happy. Like in the fairy tales. You understand?" "Why are you crying, Lady of the Lake?" "I'm not crying at all. My eyes tear from the wind. And that's it!" So I don't think Ciri could ever reach them again, nor bring them back anywhere else. From all those aspects and the general tone they set added together I would draw the conclusion that they are indeed dead, or at least not "alive in a meaningful way". Wherever strange mythical paradise they are, be it heaven, be it Avalon, or whatever you want to call it, in their very universe and in their very reality they are for all intents and purposes dead, realistically speaking. But I won't deny the fact that the ending is indeed a little ambiguous and open to interpretation. This is merely my conclusion based on how the story was presented. As an addendum, the rather new standalone novel Season of Storms from 2013 does reference Geralt's possible fate and survival in its epilogue. Where he saves the young Nimue from a monster on her way to Aretusa, 105 years after his supposed death. However, that whole epilogue is pretty much as mysteriously ambiguous and open to interpretation as the ending of the novel series. It does not make a clear statement about Geralt's actual survival or what happened to him at all either, or if the described encounter even happened in reality. If anything it rather supports the mythical themes of afterlife invoked in Lady of the Lake.
136	Sapkowski's ending to the saga in 'the lady of the lake' is clouded with ambiguity making it unclear whether it is conventional or not and what the ending actual is. We are meant to interpret the ending in our own way based on what we took from the saga. But realistically, there are three possible endings: Ciri, with her power escorts a dying (or already deceased) Geralt and Yen and takes them to an isle (lets call it the isle of Avallach for arguments sake considering that's the name the games give it), and here they are revived and healed due to the magical nature of the place, and there they live out their days and live happily; and Ciri goes traveling, where she ends up in an Arthurian-inspired fantasy world (not England, just a heavily Arthurian-inspired world). For whatever reason, she cannot return to the Isle, which the game hints at being due to the Wild Hunt which, although the game isn't cannon to Sapkowski's own image of the saga, its still plausible as Sapkowski consulted with CD projket red on several areas regarding plot and story. Ciri then goes travelling and becomes a witcheress travelling this Arthurian landscape and traversing between worlds. Geralt and Yen both die and are transported to an afterlife or heaven. This isn't too different to the first theory though in this, they are both dead. There's nothing to say that an afterlife doesn't exist in the saga. Ghosts and specters are a heavily and influential part of the cannon and are indisputably part of the lore. If these exist, surely an afterlife can. This is supported by the fact that the characters could see deceased past friends in the mist carrying Yen and Geralt. The afterlife and the intricacies of said afterlife in the witcher world are never completely explored so it isn't too far fetched to assume the two are transported to an Avalon or heaven, hence why Ciri cant reach them. The saddest and grimmest of all I am afraid- They are both dead. No afterlife, no magical isle, they are dead. Finished. Gone. Fin. Ended. Done. The part of the chapter where Geralt awakens and Yen is with him in the meadow could just be an imagining by Ciri, falsified along with the story that they get married after, to help her cope with her grief. Now, you must conclude, which of these three is the cannon. I believe that the third is the least likely. Why would Sapkowski write of Geralt awakening with Yen if it didn't happen in some way, shape or form, be it in another world or an afterlife. Also, he gave CD projket red consultation on several aspects of the game plot. Also, in Season of Storms it is hinted that Geralt saves a young Nimue, future Lady of the Lake, which, although an ambiguous passage in an ambiguous time frame, adds fuel to the argument- why would Sapkowski do that. He wouldn't simply write of Geralt and Yen waking up in another world and of Geralt (potentially) saving someone several decades later unless it happened; he wouldn't write these things unless they were canonical in some form. You could argue that in Season of Storm, he is hinting to the reader subtly that Geralt survived. Now. Do they survive in another world as in the game, or do they go to an afterlife? Well, if Season of Storms is to be taken literally then they survive and go to a world to heal and be resurrected. Though, why would their deceased friends be transporting them there too if this was the case? You could argue that the past friends carrying Geralt and Yen was just Sapkowski's way of throwing the reader off and making an ambiguous ending. I believe that the most likely ending is that they go to a magical land typical of fairytale to be resurrected; I believe this because I enjoy, no, I LOVE the games, and I want their canonical ending of the books to be true. Also, this too good to be true ending is on the surface very stereotypical of fantasy stories. It's a happy ending they live happily ever after! Well, wouldn't a stereotypical ending just be counter-typical of a saga which strives on being counter-typical, making the ending stereotypical but counter-typical to its own respective saga. That's a whole other fox whole no one wants to go down. Heads are spinning. Regardless, that's what I believe. They go to a fantasy world, and with the unicorns magic and Ciri and the magic of the world they are resurrected and healed and live happily. Ciri has to flee, maybe because of the wild hunt, maybe because of the same reason she leaves in 'Something Ends, Something Begins', which is that she needs adventure. And MAYBE! The wedding in this short story isn't totally not canonical actually happens when the two leave the isle. Regardless of the short story being cannon, this outcome where they are transported to a magical world and healed is likely because it is the one the games chose, and they chose is to continue the game yes but also BECAUSE IT MAKES SENSE! They could have explained away any of the three potential endings, but they chose this one because it's logical. To be fair a part of me believes that they're in an afterlife because it explains better why Ciri left and is upset at not being able to see them, and it also supports the prophecy of Geralt, Cohen and Yen dying, though the outcome of them travelling to a magical world outweighs this. If you read this then thank you very much. I wrote this on my phone so I apologise for inevitable typos and confused lines. I am a huge HUGE Witcher fan. And just to be clear, I still haven't decided myself which of the two endings is true or most likely. I have leaned towards the ending I chose because it is easier to grasp for those playing the games which if you haven't played, PLAY, and if you have played, PLAY AGAIN haha enjoy, my fellow Witcher lovers.
137	As explained in World of Ptavvs, the sunflowers are under the control of the Tnuctip, something that Kzanol is too dim to figure out but that Greenberg does. So whether they have a natural enemy is only one part of the question, and to an extent besides the point. They are artificial, and have a control interface. An enterprising hominid species simply needs to find it and hit the off switch. As for "natural" enemies: A hominid who doesn't know their control interface but that finds them a threat to itself, its family, or its species, is their enemy. Never underestimate the ability or the will, to just kill off stuff wholesale, of the group that is responsible for the Holocene Extinction. And sunflowers do appear to be a genetically engineered monoculture. Our enterprising hominids, adept at such biological warfare as the use of myxomatosis to kill rabbits, just needs to find the right strain of Sunflower Root Rot, or Bulb Blight. A sunflower will have a spot of difficulty attacking a disease that is transmitted below ground. Then there's the minor point that they are obviously vulnerable when the shadow squares are hiding the sun. Our enterprising hominids know how make mirrors and dig tunnels, moreover. They also know how to farm, and the joy of hyperintensive agriculture. Give them a nice source of ultra-tough reflective stuff, and before you know it they'll be sewing together shiny protective suits made of harvested sunflower leaves and doing to sunflowers what they do to bananas, tea, wheat, cotton, rice, olives, and oranges. Sunflowers have a good defence against predation; but that does not mean that they are invulnerable, or that they lack predators. Or that they stand much of a chance against hominids that have decided that We like your species; we think that we'll like you on the wall over the fireplace, stuffed. Nor should we ignore the possibility that they could acquire a parasite plant or two. "What? You'll send lots of juicy sunlight my way in a vain attempt to kill me and you'll kill off all of my competitors? Why, thank you very much, M. Host Plant!" Think of it as evolution in action. ☺
138	The new canon novel "Battlefront: Twilight Company" shows that stormtrooper armor is not necessarily as vulnerable as may be perceived by the films / tv series as several protagonists mention / think of the armor as strong and forbidding (too many instances to cite) Recording capability Additionally, the armor has recording capabilities that can be used to reprimand (or possibly reward) soldiers: "When her armor's memory was downloaded, she'd probably be caught, her indiscretion flagged and automatically appended to her record" Environmental controls "You know that stormtrooper armor has environmental controls? Internal cooling options?"
139	I took it that they are actually alive but in a place where Ciri can't go back to or can't for sometime. Basically Aen Elle where I think the Unicorns helped resurrect and heal Yen and Gerald. Why Little Horse came to them in the first place and and why Ciri asked Kelpi to follow him. I took it that Ciri knows where they are going and followed them. Remember she escaped Aen Elle via a boat and it is logical she gets back into it via a boat. I think when little horse arrived he gave Ciri the power to get back when Ciri touch his horn. It was odd when in the end Yen said she does not know where they are when Gerald asked. I mean if you are in an after life place you would surely know?. Besides Gerald woke up with bandages which was also odd if you are in an afterlife/heaven place?. Gerald was seriously wounded and it makes sense he would take more time to heal and wake up later. Yen was already up because she was not wounded as badly. Again I find this strange in an after life place if both of them don't wake up together and both fully healed at the same time. I took it means that Gerald is still recovering from his wounds as such they are still both alive. Ciri before leaving told Triss she can't stay and fulfill what the lodge wanted of her because Gerald and Yen are departing. This didn't make sense to me because both Gerald and Yen were already dead by then?. I took it means that Ciri had to go with them to a place to heal them but she was not sure if it will work because they were on the verge of departing forever. She was the only one that could take them and by doing so Ciri knew she won't be back for sometime or rather within the timeframe that the lodge wanted her to conceive a baby. Hence what she said to Triss Ciri knows her destiny and knows how important she is in saving the world from the end. Why despite everything shes been through with Leo and Vligafortz she was still willing to do what the lodge wanted which was similar. Ciri would never just abandon what she agreed to do to conceive a baby and help save the world unless it was for a really important reason which was her trying to save Yen and Gerald. I really doubt she would have abandoned her mission if she knew that there was no hope in saving Yen and Gerald, if they were infact beyond saving. If she knew there was no hope for Gerald and Yen I believe she would have stayed and complete her mission for the Lodge and save everyone which includes Triss and Dandelion and her friends that are still alive. It makes no sense to take Yen and Gerald and abandon her friends at that time if she knew there was no hope of bringing both Gerald and Yen back. To be clear I actually think they died. However Ciri knows that there is a chance they could be resurrected/resuscitated and then healed provided she goes and takes them then to Aen Elle to the unicorns with no delay. Why Ciri told Triss the Lodge will understand implying that it is time sensitive that Ciri takes Yen and Gerald then which the lodge will understand and it was the right decision. If Ciri knows there is no chance of them being resurrected it would be logical for her to just bury them like Mistle and the rest and just continue with her mission to conceive a baby and to help save the World. Ciri is a remarkably brave girl.She agreed to get impregnated to escape Aen Elle the first time. Agreeing to sacrifice her self for Yen and then again agreed to sacrifice her future to fulfill the aim of the lodge to eventually save everyone from the end. I just don't see any other situation where Ciri would have broken her agreement with the lodge unless it is to save Yen and Gerald when the time came. As for why Ciri can't be with Gerald and Yen in the end of the book. My theory is the Unicorns understand how dangerous she is especially if she falls in the hands of the Elves. It was said that when Ciri first arrived in Aen Elle that there was a lot of unrest among the Unicorns because of the power she posses. I think this is where the Witcher games story started off when the Wild Hunt abducted Yen when both Yen and Gerald where in Aen Elle. At the start of the Lady of the lake Ciri was singing. This was straight after Rivia which I found odd. It seemed to me that she actually managed to saved them however she is sad she can't see them for at least sometime. Yen and Gerald would be stuck in An Elle and she can't just go there when she wants to. The Unicorns remember helped her escape the first time because they didn't want her to be there because of the Elves. Personally I like the ending of both of them having died, gone to heaven and live out their lives happily ever after. However there are so many small details that cropped up that makes me believe that they are still alive.
140	Why would she transport them to heaven(Avalon/Avallachs Isle) if they are dead? Wouldn't they just go there if they died? And Geralt waking up with bandages and wounds and Yennefer telling him to slow down... Well, I really believe that they are not dead, but still, since it's not clear, it's up to the reader to decide.
141	Zelena is the older half-sister of Regina. Cora was tricked into pre-marital consummation by a palace gardener, Jonathan, who pretended to be a prince (and consequently reneged on the marriage). This story takes place in episode 18 of season 3, and is the only episode we see Jonathan in.
142	He could have, but nothing like that is ever shown. Doc still has the plutonium at the end of the movie - he jumps to the future with it, because the DeLorean still needs that fuel. It's likely he got rid of it once he had the new Mr Fusion as a power source, but it's never brought up where he ditched it. The news report only indicates that the plutonium was indeed noticed missing, and this is likely when Doc's terrorists stole it. If Doc had returned what was left (presuming he would be able to do so, he's not the stealthiest of people), they still would have been short the pellets he used, and the news report would still have happened. If he altered records, the theft would never have been noticed at all, and there would have been no news report, so still not likely. The only reason the news would report a clerical error is, in typical fashion, someone attempting to cover up the theft rather than admit there's plutonium loose and no one knows where.
143	Yes. Vampires exist, as we see in the other answers, but there's a point not mentioned: We know the reason why Vampires don't turn up more. According to Ibid's exhausting research into Harry Potter canon, there's a cure to Vampire bites. The following is a (non-exhaustive) selection of new canon that we can learn from the W.O.M.B.A.T.s. The list focuses on canon exclusive to the Wombats. Much other content merely corroborates things we know from interviews, pottermore writings, the Daily Prophet newsletters, and the famous wizard cards. (The WOMBATs are actually the only source that includes info found on the PoA FW cards.) ....There are no female centaurs and no male veela. Vampire bites are curable nowadays, and ghosts can cause movements in liquids and gases. Source: The Rowling Library, Ibid, What The Wombats Are And What They Mean For Canon
144	In addition to (most of) the above answers, one must remember that the Empire needed to maintain uniformity among its ranks. The Stormtrooper armor, as well as the armors of their more specialized units, served both as protection and as a symbol of unit and rank structure. Additionally again, it made certain that Imperial units were identified by the populace, and the black-and-white style of the armor became a symbol itself. It almost acted as it's own propaganda for the Empire.
145	Tarley has some incredible achievements under his belt: he was the first to warn about the White Walkers when every other Maester thought they were fairy tales, and he discovered what kills them. He found a cure for Greyscale in adults when every other Maester was convinced that it was incurable. He is unbiased in his approach and unaffected by old beliefs and baseless traditions that infect the institutionalized Maesters. All of those things make him an invaluable adviser to the king, and perhaps he is destined to lead a revolution in the Citadel.
146	Years later, Scootaloo parents make their debut in the show, during episode S09E12 - The Last Crusade. Coincidentally, the episodes manages to be coherent to Lauren initial vision referenced in guildsbounty answer. "My thoughts on Scootaloo--is that she's got parents, they're great people, we just don't...meet them. We hang out with Scootaloo when she's hanging out with her friends--and if there was ever a reason to introduce her parents in any kind of short story that we wanted to tell, then we would." According to the chapter book Riddle of the Rusty Horseshoe Scootaloo lives with her two aunts Aunt Holiday and Auntie Lofty because her parents do indeed have some "demanding job" that hold them away most of the time. During the season nine episode it is then revealed that her parents - Snap Shutter and Mane Allgood - are actually two world travelers who study exotic plants and creatures for medical research purposes. It is also worth noticing that the same episode also feature an appearance of Scootaloo two aunts in the show, in a way enforcing the canonicity of the chapter book.
147	It's only hinted at, but I think yes. In addition to Edlothiad's answer, Aragorn tells Boromir he's seen Minas Tirith "long ago." Boromir: I will find no rest here. I heard her voice inside my head. She spoke of my father and the fall of Gondor. She said to me “Even now there is hope left.” But I cannot see it. It is long since we had any hope. My father is a noble man, but his rule is failing. And now our people lose faith. He looks to me to make things right and I would do it. I would see the glory of Gondor restored. Have you ever seen it Aragorn? The White tower of Ecthelion, glimmering like a spike of pearl and silver. Its banners caught high in the morning breeze. Have you ever been called home by the clear ringing of silver trumpets? (he turns towards Aragorn) Aragorn: I have seen the White City, long ago. Boromir: One day, our paths will lead us there. And the tower guards shall take up the call: “The Lords of Gondor have returned!” In the books at least, the only time Aragorn visited Gondor was during his adventures as Thorongil. So that makes two lines of dialogue that correspond with his biography in the books. I guess it's possible that in the movie universe Aragorn rode to war with Thengel under the name "Pinky" and visited Minas Tirith for a raging keg party. But given the level of detail and fidelity to Tolkien's works generally displayed in the original trilogy, I don't see any reason to believe that, except when explicitly contradicted, everything true of Aragorn's biography in the books is also true in the movies. It certainly seems like the writers went out of their way to make nods to Aragorn's backstory. To put it another way, officially there's no answer, but I think there's pretty strong indication that if you got Fran Walsh, Philippa Boyens or Peter Jackson on the phone and asked if the Thorongil adventures happened to their movie's Aragorn, they'd say "yeah."
148	It all depends on the risks that you're backing up against but one option you'd missed is the dedicated devices for backing up memory cards (Jobo and the like) - we had one of these circulating at our wedding, so that all the guests didn't have to worry about memory card space.
149	KenRockwell.com also has a great article on how the two work, with practical information including where it will help (low light and hand jiggle), and where it won't (aircraft vibration).
150	The new breed of P&S cameras that are coming out all use the same size sensor as your grandmother's D40. That is to say, they all use the APS-C size sensor. In order of physical size some to look at are the Sony NEX-3/5, Leica X1, Fujifilm X100. All have "automatic" modes and come with built in (or attachable in the case of the NEX) flashes. The X1 is $1999 (MSRP) new, the X100 is $1199 (MSRP) but not available in the US yet, and the NEX-5 will run about $700 with the kit zoom. The NEX accommodates interchangeable lenses, the X1 has a zoom, and the X100 has a fixed-length lens. All can use the LCD screen on the back for composing and focusing but only the X100 has an integrated viewfinder. This allows for removing the prism (a big, heavy hunk of glass) and the mirror the DSLR must have and allows for a smaller form factor. The 4/3rd and Micro 4/3rds cameras have a smaller sensor size then the D40 but offer excellent picture quality, small-ish form factors, and a wide selection of lenses. I expect with the enthusiasm of the X100, though, that we will be seeing more cameras with integrated viewfinders, APS-C sized sensors... and interchangeable lenses. The rumor mills, in fact, point to an unconfirmed Nikon EVIL (electronic viewfinder, inter-changeable lens) camera and the Sony NEX-7 as possible products in that direction. In full disclosure, I've owned the Leica D-Lux2, Panasonic L1 (4/3rds), Leica M8 and Nikon D3000 (both APS-C-esque), but am currently hooked on my Sony NEX-5 which is smaller by far than the others, has full-automatic and full-manual exposure and focusing modes, a detachable flash, a low buy-in dollar-wise (comparable to the D-Lux), and offers what I consider to be equal to superior image quality when compared to the other digitals I've owned.
151	Image size is what if often called resolution, basically the number of pixels stored in the image file. So on a 12 megapixel camera, you can usually choose between 12 MP, 6 MP and 3 MP or similar values. Image quality is independent of size and is usually called compression. This controls how much information is discarded from images while they are saved. You can read this article which I wrote several years ago for a comparison between the two.
152	JPEG is a "lossy" compressed image format meaning that, at various levels of compression, data is thrown away to make the image smaller in file size as opposed to image dimensions. So "fine" setting on the quality is going to do little compression and therefore lessen the amount of data discarded as a result and give a nicer looking image. An "economy" setting is going to throw away more data, which will degrade the image detail, but give you a smaller file size. In general, unless you have a real serious need to do it, I would be shooting at the largest image size and at the highest image quality.
153	Quality refers to the level of JPEG compression used. JPEG images use lossy compression to reduce filesizes. The compression method converts the image into a frequency representation (a set of waves instead of a set of pixels) and removes frequencies whose amplitude are below a certain threshold, on the assumption that missing these will affect image quality less. Whilst this works well for mild compression, after a while you start loosing important components and thus detail in your image.
154	Disks are still pretty cheap these days so there are advantages to JPEG files, even if they are as big as the original RAW, instant image preview, being able to display on computers without RAW software. The "quality" parameter determines the quantization matrix used to compress the data. Without going into too much detail this determines the degree to which the frequencies contained in an image are approximated to achieve compression. The important thing to note is that there is no direct correspondence between "quality" and final size. Therefore quality merely determines what proportion of image information will be lost, if an image that contains more information to begin with (in terms of high frequency details) you will get a larger JPEG file even with the same quality settings. There is therefore no global setting you can use, if you want files of a certain size you have to tune the quality for each image. Alternatively you might want to use a higher setting for images with more fine detail (or noise - noise doesn't compress well so can result in more artifacts). If you are doing a one off image I would use any program that gave you a preview of the compressed image (Photoshop does this) and play with the value until you get the quality you want at a size that is reasonable. I never archive in JPEG format, I always keep the original RAWs, so any time I'm producing a JPEG it is for display on screen. I used to start with quality 7 (out of 12) in Photoshop, unless I noticed artifacts, then I would increase it. Then I moved to 9/12 as my default quality. As internet connections speeds and storage increased much faster than screen resolutions, these days I just use 11 (one step down from maximum, there's a bit of a jump in size when you select 12) all the time and don't worry about it. When sending images to print, if they have to be JPEGs I use the highest quality I can unless the print company complains. You've worked hard on an image, there's no sense reducing the quality to cut upload times by a few minutes.
155	What Matt said, but I want to add that JPEG actually has two compression schemes built in. The first is based on a discrete cosine, which allows certain frequency components of the image to be thrown out. This is the lossy compression with the "quality" parameter that can trade off compression with fidelity. At maximum quality, this compression scheme is mostly eliminated. JPEG also uses huffman encoding for additional compression. That is a lossless scheme, so it is always there without any need to control it. So even at maximum "quality", JPEG will have some useful compression. I just looked at sizes of one example image of a ordinary scene for comparison. The Nikon NEF raw file is 26 Mb, which contains 14 bits/pixel and is uncompressed. My post-processed JPEG version saved at maximum quality is 9.1 Mb. This contains 24 bits/pixel, although of course some information is lost and other information interpolated from values in the original raw image. This same post-processed image converted to a TIFF file with LZW and forward differencing compression (both lossless) resulted in 20.3 Mb. As a final experiment, I copied the 9.1 Mb post-processed file and the TIFF file resulting from it both to JPEG files with maximum quality setting. Both resulting JPEG files are exactly the same size to the byte of about 8.5 Mb. This shows that even at maximum quality, just a little lossy compression is going on, but not much. It also proves the point that no information was lost at all going to the TIFF file. As Matt does, I archive the original RAW files from the camera. I also archive my general purpose post-processed version as JPEG with maximum quality. Even pixel peeping at high contrast and sharp edges doesn't reveal compression artifacts to the human eyeball. I like having the post-processed picture in JPEG form because its probably the most immediately usable format. If there is a issue and I want something different, I've always got the raw file to re-derive a another post-processed version from with different tradeoffs. I used to use 80 as the default quality level of my JPEG images (my software has 0-100 for its quality range), but lately I've been using 100 as default unless there is a specific need for a smaller file size. There usually isn't. I have gone so far as changing the default for the JPG image driver in the source code so that I don't have to keep specifying the quality level most of the time. It's not like the old days where a Gb was a lot of memory. (Actually, I'm old enough to remember when 1 Mb was a decent amount of disk space, but back then we weren't doing digital photography either).
156	To get the best possible compromise between compression and quality you would have to try each image with different compressions to see where the quality is acceptable. If you don't want to do that to every image, you can try out a few images and then go with that compression level, and accept that the level is close enough. As a starting point: quality 60: good for web quality 80: good for online printing What to look for, to spot JPEG compression artifacts: Every 2x2 pixel block share the same color hue, so along very sharp borders between contrasting colors you may get colors bleeding through the border. The compression is based on 8x8 blocks of gradients, so at lower compression you see the blocks starting to emerge. Where a sharp contrast appears close to a smooth area, for example a tree line against the sky, the compression is most visible, in the form of crincles in the smooth area.
157	Use 90, or preferably 95. In my experience, the size gain when using anything under 90 is in most cases no longer beneficial in relation to perceivable quality loss, and should only be used on very specific images that can profit from JPEG compression and/or need to stay under a maximum file size (e.g. images used when building a website). JPEG compression lower than about 75 will definitely show visible artifacts.
158	I keep my jpeg quality slider at 100% for my "developments", and will so I lose less detail before the online site will recompress it anyway. If I put it on my own site through ftp I might choose 90% and supply a thumbnail. 80% of online people watching photos online has a fast DSL anyway. Here is a test with quality from left to right: 10,20,30,40,55,70,80,90,100% I show crops from each file. File sizes for the full files are: 210k, 278k, 347k, 477k, 601k, 709k, 987k, 1.7M, 7M. The raw file was 8M but remember that is basically a monochrome image and a smaller thumbnail plus a little meta data. The BMP is 30.5Mb! To me the difference from 100 to 90 is noticeable but very small. But I would never go under 100% if there is a chance I might want to open it and process it further. below 100% is a "process time EVER" deal. From 90 to 80 the difference is bigger, and 70% starts to look like crap. So my conclusion is: for backup and possible reopening 100% if you need to save some space/upload/DL time and it wont get repacked: 80-90%. Look at the detail differences in the BMP File
159	To be frank, it is entirely anecdotal that a JPEG image should be exported at a certain compression level all the time. The amount of JPEG compression should really depend on the usage purpose for the JPEG, and the contents of the JPEG. The quality level one should choose when exporting an image to JPEG is highly dependent upon the kind of detail contained within the image. An image of a smooth blue sky or a sunset sky with large areas of orange gradient should probably use a high quality setting, 90-100. An image that contains nothing but complex detail could probably get away with a quality setting of 50-60, possibly even lower. There is no single "best" JPEG compression setting, and depending on the type and complexity of detail (or lack of complexity and detail), you may find yourself using 40-60, 70-80, or 90-100 as appropriate for the photo(s) you are exporting. An excellent visual resource for how JPEG compression affects IQ can be found here: An Analysis of Lightroom JPEG Export Quality Settings This site demonstrates JPEG compression from the lowest to highest settings in discrete ranges for a series of sample images of differing content. You can clearly see, by observing each image at each compression level, why a higher setting such as 90-100 may be required in some cases, and a lower setting such as 40-60 is entirely acceptable for others. As a side note, if you are saving a JPEG for any kind of print purpose, or for viewing on-screen at a large size (i.e. as a wallpaper for a 30" 2560x1600 screen), there is no reason not to use the best quality setting available. When saving for web, compress as much as you can without introducing visible compression artifacts. Different classes of images will regularly fall into certain JPEG compression levels (the site linked above can help learning what fall where)...so it can quickly become second nature to know what compression level to use when saving various images for the web.
160	No, you can't crop a single layer. The closest thing would be to copy the layer to a new image, crop that image, and copy the layer back to the original image. It's easier just to erase or mask the part of the layer that you don't want.
161	The relationship is a simple inverse, i.e. object size in image = Object size * focal length / object distance from camera If you keep the same object and the same focal length you get: size = 1/ distance (the =-sign should be proportional-sign).
162	I'm sure this is a duplicate, but I can't find a good answer to the question in the archives so here goes. The relationship between object size and distance is an inverse linear relationship, i.e. size is 1 / distance. This makes sense when you think about it as if you double the distance the size halves. This is why you appear to be observing an exponential: the exponent is -1, if you take the reciprocal of the size, your graph should be a straight line.
163	Inversely linear is a good approximation. Imagine a 1,7m tall girl at 1 m distance b. Her head is at point B. How does the size/length of an object vary with distance? Let the girl walk away from you. Her size a stays the same. She appears smaller, because she is appearing under a smaller angle. Her angular size changes. Try to imagine it with the picture attached. Using arctangent to calculate her angular size is the correct way. For small angles you can simplify: Angular size is inversely proportional to its object distance, without using optical devices. An object on full-field with focal length of 12 mm would be measured incorrectly. An error 2-5% in length measurement may be made. For fish-eye lenses this may be even worse. Hands-on rule: Use the inverse relationship if angular size is smaller than 10°.
164	It's for cameras that do not have a PC sync port so that they're able to fire strobes that do have one, common in professional lighting equipment. So, in this realm, the PC means "Prontor/Compur" and that is (becoming "was") the standard port used by cameras to trigger off-camera strobes over a cabled connection. This has, slowly, started to be replaced by 3.5mm jack, when cabled, but it is still quite common and the port can be found on most professional and semi-professional cameras today. However, for cameras that fall into the more amateur mode, the sync terminal adapter you linked to above is designed to provide the same feature via the hotshoe of the camera. Comes in handy from time to time, though less and less so as time goes by. I'd rather use radio triggering myself. Wikipedia has a handy article on flash synchronization that has more detail.
165	It depends on the camera, but it probably doesn't matter all that much, especially for newer models. Some medium format folks are religious about always keeping the works in tension. Some models only engage and link with the lens when cocked, and this linkage is key to whole works -- you can't even remove a lens without cocking the shutter release in some cases. An SLR model doesn't have the same design, of course, but I was told to store my K1000 cocked, always. (I actually don't have a good reason other than habit, so I am interested in other answers.) And Canon F models had a problem with squealing if stored cocked, so those guys had a ritual of always firing the shutter before bed. Again, this ritual may not be based on fact. About the only thing folks agree on is that you shouldn't let the camera sit for too long between firing the shutter. For cars and mechanical cameras both, letting them sit for months without rolling takes a toll. I suspect none of this matters much for modern SLRs. Most of the mechanics have been replaced with electronics, and the mechanics that are present are under the slightest tension, or are actuated using something other than stored kinetic energy, generally.
166	There are a large number of options available to you all over the price/reliability spectrum. You basically just want TTL-capable triggers for Canon. The difference between using them and using manual-only triggers like the V5s, is that you may be limited on what lights or other triggers play nice together, and integrating studio strobes might be more of a pain. There are triggering options from Yongnuo, Phottix, Pixel, Godox, RadioPopper, and PocketWizard, to name just a few, but you're very much NOT limited to only PocketWizard choices, and in the case of the 580EXII, you're probably better off not using PocketWizard, given the radio interference issues Canon 580EX and 580EXII shooters have had with them. All the other RF TTL triggers out there operate on 2.4GHz, though, and don't exhibit this problem. Yongnuo As a cheap hobbyist and 580EXII owner, my solution was to go for the YN-568EX, Yongnuo 622 transceivers, and a dedicated transmitter (YN-622-TX), and I recently added a YN-685 (built-in receiver) to my setup. But, while inexpensive, the drawbacks of this are that all my RF-602 triggers don't play well unless I stack a transmitter on a 622, so a 560III/IV wouldn't integrate well, and the MkI 430EX and 580EX I have can only be controlled via ratios. You also pretty much need a camera that's Digic 4 or later (has the flash control menus). Yongnuo is frustrating in that they have three separate triggering systems (603, 622, and RT) none of which plays with the others. As you know, you also could get YN-560III/IV or (when it comes out) the YN-660, and use a YN-560-TX to remote power control them. Selling the 580EXII could get you multiple cheapie Yongnuos, but reliability/build quality may become an issue, especially under hard pro use. Canon's RT system There is also Canon's own RT system. The 600EX-RT not only has a number of third-party clones popping up, but also 3rd party triggers to integrate other lights (including a 580EXII) into the RT system. But, of course, without an RT unit to begin with, you can't take advantage of having triggers built in, and remote-controlling the power on studio strobes is not possible. RadioPopper Phottix and RadioPopper are at the higher end of the price scale for triggers, but they both make manual triggers that interoperate with their TTL ones. For expansion over time, or to have a lower-priced simpler trigger for non-TTL flashes, and for reliability, this can be more useful. In addition, RadioPopper now has modules for older Sekonic meters, as well as the Paul Buff Einstein, so if you think you'll expand to studio strobes and would like to remotely control the power level on one, that's one way. Phottix Phottix, otoh, has gone a different route and built a TTL studio strobe with a built-in Odin receiver, as well as their own Mitros+ TTL flashes with built-in RF receivers. And LumoPro now builds an all-manual but remote-power controllable LP180R--with a built-in Odin receiver. So, other ways to expand your system. Godox Godox's lights are now both manual-only with power control and TTL with appropriate triggers, but they're mostly interesting in that they offer bare-bulb flashes (Wistro AD line)--think of it as sort of halfway between a speedlight and a studio strobe. The head unit is only a bit bulkier than a speedlight (external battery pack required), but it's much more powerful than a speedlight, and because it's bare bulb, the character of the light (and the modifiers you can use) are more like a studio strobe. Godox also uses Lithium battery packs in their barebulb flashes and speedlights, which makes battery management hecka easier than a huge pile of AAs, and better recycle times. Considerations As a pro, you want to consider not just what you need now, but what kind of upgrade path you may eventually want, because the triggering system you purchase can determine a lot of other choices down the line. A really good website to research all the options that are out there, and to keep up with the high-speed churn of new products arriving on the scene, is the Flash Havoc blog. Their (not 100% up-to-date) guide on TTL triggers is here: http://flashhavoc.com/flash-trigger-guide-ttl/
167	Graphic Design Stack Exchange: How to cut how hair accurately Advanced hair extraction tutorial First off, plugins and simpler methods are available. This is if you want to get higher quality results. I'll be using this photo from Photo by Ariana Prestes on Unsplash.com: Note: I'm going to be doing the body in a separate layer so I'll be ignoring it for most of this tutorial until the final few steps Select the Channel with the most contrast in the fine outer hairs. I think Green is the best option: I'm going to duplicate that channel and rename it to Hair Mask. This will be what I work on until otherwise stated. Important: If your hair is light on a dark background then you need to invert some of this as far as when to Dodge/Burn and when to use Black/White. Now to start Apply Image. Multiply or Overlay are good options, sometimes you can even Apply Image twice. Here I applied the Hair Mask to itself with the overlay and lowered the opacity in the settings a bit to not lose the really fine hairs: I actually did Apply Image Overlay a second pass with a lower Opacity pushing the contrast a bit more. This isn't undoing the first one, its doing it a second time: Then go into Curves (Ctrl/Cmd+M) and adjust the White and Black point sliders. Setup some Guides so I could periodically show original vs current at 100%. Here's the first look after just doing Apply Image, Apply Image, Curves: Now you can like ACEkin said use Brush set to Overlay. I prefer starting with Dodge and Burn though. Burn set to Shadow and I used Exposure of 12 then went over the hairs as carefully as possible. The more careful and time you take the better the results will be. This was maybe 3 minutes, not long at all: Then at this point go ahead and switch to Brush, Black and fill in the inside. If you want you can first do Black set to Overlay and make another pass at the edges. Again, more time you take the better the results: Alright, now use Dodge on the spaces between the hairs. Brush set to Overlay White is another option, again I prefer Dodge and Burn. I did Dodge Exposure 12 on Highlights. Then fill the rest with White. And let's see where we're at in the 100% view: With your completed mask selected go back to RGB channel and then layers and apply the mask. I did the body with a separate layer as I mentioned earlier so now I've applied that as well. Then just refine your mask using the Refine Edge command be sure to use Decontaminate Color Now the background I picked doesn't really match the lighting and picture, but that's alright. Its not about whether the picture looks real, just about the mask. Could almost always take more time, this is by no means perfect, but here it is which is pretty good for the point of teaching the technique: And our 100% crop this time looking at the original vs the finished: I didn't really think about the crop area when choosing a background image to drop in. Since its hard to see that particular area, here's with absolutely no changes to my mask, just got rid of that background for a plain white background for the comparison instead: Not bad for a Mask from a JPG. In your case once you learn the technique it shouldn't take more than a few minutes. Without using my Wacom I pushed the colors, created an alpha mask, burned the inner portion, and dodged the outer portion then used it as a mask for a simple curves adjustment.
168	Given a large enough print size, the difference in image quality will make itself apparent. The question then becomes, what is that print size? The graphic in this answer leads us to believe that the difference is a print size of ~11x17 and ~13x20. And honestly, that's not taking interpolation into it. It is possible to increase an images size up to a point - but one has to take the viewing media and distance into account to calculate that. I'm going to just go out on a limb and say that, no, for most consumers, there will be no noticeable difference. However, given more pixels, you gain the ability to crop into your photo and still have enough pixels for a decently sized print. And if we're talking about newer technology, and not just pixel count, there are gains in image processing technology that lessen the noise at any given ISO. There are many reasons one might upgrade cameras - but more pixels for the sake of more pixels is not one of them...Unless you like making the day of the marketing team at (Insert Camera Company Here).
169	The answer appears to be forthcoming in the wikipedia article on silicon monoxide and references therein — to quote: $\ce{(SiO)_{n}}$ irreversibly disproportionates into $\ce{SiO2}$ and $\ce{Si}$ in a few hours between 400 and 800 °C and very rapidly between 1000 and 1440 °C, although the reaction does not go to completion. The article implies that $\ce{(SiO)_{n}}$ generates a passivating layer of $\ce{SiO2}$ in contact with dioxygen, so presumably the slag would be encapsulated in a thin layer of that. Additionally, silicon is not generally considered to be a metal, but rather a semimetal or metalloid.
170	Glycerin and glycerol are both names for the same molecule. However, depending on where you are getting the glycerol from, it could be more or less pure.
171	Nope, there is no chemical difference between glycerol, glycerin or glycerine. All 3 names refer to the same compound, propane-1,2,3-triol.
172	As far as I know, glycerin and glycerol both refer to the same compound: propantriol.
173	No, in the gas phase sodium chloride exists as a monomer (the sodium chloride molecule) along with its dimer $\ce{Na2Cl2}$. The dimer has a roughly rectangular shape and is quite floppy with chlorines located diagonally across from each other. The dimer makes up about 27% of the mix. All of the bond lengths, etc. can be found in this thesis. Go to the end and you'll see the full paper that appeared in JACS with all of the data.
174	The two are related, in that most nucleophiles are (Lewis) bases and vice versa. Some good nucleophiles are also strong bases, e.g. $\ce{HO-}$. However, a species can be a good nucleophile and a weak base, e.g. $\ce{I-}$; or a species can be a weak nucleophile and a strong base, e.g. $\ce{t-BuO-}$. How can we separate this behavior? Nucleophilicity is a kinetic phenomenon. Nucleophilicity is most often defined based on the relative rate of the reactions of nucleophiles with a standard substrate in a standard solvent. For example, a standard reaction might look like: $$\ce{CH3I ->[Nu-][H2O] CH3Nu}$$ The nucleophilicity will be related to the relative rate constant of reaction with the nucleophile (relative to the rate constant of the reaction with water $\equiv 1$). Basicity is a thermodynamic phenomenon. Basicity is based on the position of equilibrium: $$\ce{B + HSol <=> BH+ + Sol-}$$
175	There is a difference indeed: basicity is a particular kind of nucleophilicity. A nucleophile is a chemical species that donates an electron pair to an electrophile. A nucleophile can also be called a base when this donation occurs towards a particular electrophile, which is an hydrogen ion (a proton).
176	glycerols are the triol compound used for many purposes in pure or mixed form , but glycerine is the commercial name of glycerol, which is not pure ,which contain mostly 95% of glycerol , it can't be used when pure glycerol is required .
177	Carboxylic acids can act as nucleophiles of course. Consider reactions with isobutene or thionyl chloride (although base certainly helps in this latter case). However, whether it's in $\mathrm{S_N2}$ or $\mathrm{S_N1}$ reaction mechanisms is another matter. If you beast something with enough heat it will usually react. I would not be surprised if a carboxylic acid reacted with triflouromethanesulfonic anhydride without base. It's still $\mathrm{S_N2}$ as mechanistic studies have shown the S=O bonds do not open up like acyl electrophiles. I suspect you would need to resort to a continuous as opposed to a batch approach to push a reaction between the acid and an alkyl halide without using any base. Expose the reaction to high temperature (I'm thinking 250C and higher) for 5 seconds or less under continuous liquid flow.
178	Molecular compounds such as water exist as discrete particles, molecules. This is due to the forming of covalent bonds where each atom has a specific partner to which it is bonded. Each molecule of water contains one atom of oxygen and two atoms of hydrogen. So, H2O is its formula. This can be more specifically called a molecular formula. In ionic compounds such as table salt, NaCl, the atoms (as ions) do not bond to specific neighbors. Surrounding each chloride ion in a salt crystal are six sodium ions. Likewise, six chloride ions surround each sodium ion. This attraction of oppositely charged ions extends throughout the entire crystal. There is no discrete bonding of a particular sodium ion to a specific chloride ion. So the formula for sodium chloride is expressed as the smallest whole number ratio between the Na and Cl ions which is 1:1 for sodium chloride. So, NaCl is also a formula but not a molecular formula. The reason for the term "formula unit" is that it is useful when we talk about how much of one substance is required to combine with a particular amount of another substance. For example: to make the smallest amount of hydrogen carbonate we combine one molecule of water with one molecule of carbon dioxide. But now suppose we want to combine silver nitrate with sodium chloride. Both of these are ionic compounds, they do not form molecules. In this case you would say that one formula unit (FU) of sodium chloride combines with one FU of silver nitrate. The one-to-one combining in both these examples is simply coincidence. It may take 3 FUs of substance A to combine exactly with 2 FUs of substance B in a different example.
179	Sigma bonds are defined as having their electron density along the bond axis, while pi bonds have their electron density above and below the bond axis. What this mean is that pi bonds cannot rotate the same way as sigma bonds since rotation would break the pi bond interaction. See the picture below for clarification. If you're wondering why it rotates then the more freely that a bond rotates, the more favorable the entropy. In general, the more kinds of motions and the more unconstrained those motions are, the more favorable the entropy.
180	I think it is a poor phrasing. The strong force is responsible for keeping quarks together inside a proton or a neutron, but also between quarks belonging to different proton/neutron (but I am not sure for proton-proton interaction because of the repulsive electromagnetic force). By contrast, the weak force is responsible for turning one type of quarks into another type or quarks, thus transforming a proton into a neutron in the case of beta+ radioactive decay, with emission of a positron (the overall charge is always conserved).
181	Ammonia is a surfactant, like detergents, but it also reacts chemically with some quantities of oils to convert them into other things. In addition, as a cleaning agent, unlike detergents and soap, ammonia has anti-microbial action. Ammonia is a historically notable cleaning agent. It was readily available, prior to the advent of the industrial era, as it is a natural by-product of the breakdown of animal (and human) waste (1). Aging urine produces a liquid with a high ammonia content. Ammonia has significant antimicrobial properties (2) as well as anti-grease/oil properties. As an anti-oil agent, it has both surfactant and transmutational properties (3)(4)(5). In plainer English, that means that ammonia emulsifies grease and oils, like soap and detergents, so that the mess can be washed away with water, and it changes the nature of some of the oil. As a surfactant, ammonia acts like soap and detergents, meaning they pick up and disperse the oil into tiny droplets in the water (emulsification), which then can be rinsed away. Soap and detergents are a relatively unstable emulsifier. Which means that, as the original soap or detergent breaks down, the oils come out of emulsification, and regroup. And, voila, you get your fat back - just in a different location - and probably with lots of other impurities. Ammonia, as a surfactant, does the same thing: i.e. it acts to emulsify the oil. And, when it breaks down, the emulsion ends. However, ammonia also chemically interacts with the oil, in significant amounts, in a process called ammonolysis, in which it also has catalytic effects. In this process it converts some of the grease and oils into other substances (e.g. amines), which no longer have the same properties as the original grease or oils. (4)(5) Ammonia does this latter through ammonolysis, in which it also may act as a catalyst. This is the part of ammonia's action that is similar to saponification, in which the original substances are altered, and no longer exist in their original form. How much of the oil is converted into amines depends on the temperature of the interaction, the type and characteristics of the oils, etc. However, this change is stable, and permanent, in that the end products do not revert to being oils. (1) history: Smithsonian Magazine: The science behind historic uses of urine (2)Ammonia is not currently recognized as a primary antimicrobial product, as, for example, is bleach (chlorine). Chlorine, my example, is far more effective as an antimicrobial. However, in ammonia's favor, is the fact that ammonia is far more effective in this regard than soap or detergents alone. Please note that, on the linked chart, bleach (chlorine) is referred to by its chemical name: sodium hypochlorite. Antimicrobial Spectrum of Disinfectants (3) Surfactants: Dawn Chemical: Chemistry of Cleaning Essential Chemical Industry: Surfactants (4) Ammonolysis (subset of Solvolysis) (5) Catalytic Effects in the Ammonolysis of Vegetable Oils
182	It sounds like an ANOVA (analysis of variance) setting, except that usually ANOVA is used to ask the question whether there are differences in growth between the concentrations. If you used ANOVA and found that there is a difference, then it wouldn't indicate which is the "best" one, just that they are different. There are post-hoc tests to look at all the different pairs. I'd take a different approach though: Can the different concentration be considered as gradually increasing? (rather than just "different" from each other). What kind of relationship do you anticipate between the feed concentration and the growth? How many concentrations to you have? how many records per concentration? If you have more than 2-3 concentrations and sufficient data on each concentration level you could fit a parametric or nonparametric growth curve (x-axis is concentration, y-axis is growth). This would give you a clearer idea of what is going on, with less assumptions.
183	Short answer: they differ by a quantile of the reference (usually, the standard normal) distribution. Long answer: you are estimating a certain population parameter (say, proportion of people with red hair; it may be something far more complicated, from say a logistic regression parameter to the 75th percentile of the gain in achievement scores to whatever). You collect your data, you run your estimation procedure, and the very first thing you look at is the point estimate, the quantity that approximates what you want to learn about your population (the sample proportion of redheads is 7%). Since this is a sample statistic, it is a random variable. As a random variable, it has a (sampling) distribution that can be characterized by mean, variance, distribution function, etc. While the point estimate is your best guess regarding the population parameter, the standard error is your best guess regarding the standard deviation of your estimator (or, in some cases, the square root of the mean squared error, MSE = bias$^2$ + variance). For a sample of size $n=1000$, the standard error of your proportion estimate is $\sqrt{0.07\cdot0.93/1000}$ $=0.0081$. The margin of error is the half-width of the associated confidence interval, so for the 95% confidence level, you would have $z_{0.975}=1.96$ resulting in a margin of error $0.0081\cdot1.96=0.0158$.
184	First of all, a CI for a given confidence percentage (e.g.95%) means, for all practical purposes (though technically it is not correct) that you are confident that the true value is in the interval. If this is interval is "narrow" (note that this can only be regarded in a relative fashion, so, for comparison with what follows, say it is 1 unit wide), it means that there is not much room to play: whichever value you pick in that interval is going to be close to the true value (because the interval is narrow), and you are quite certain of that (95%). Compare this to a relatively wide 95% CI (to match the example before, say it is 100 units wide): here, you are still 95% certain that the true value will be within this interval, yet that doesn't tell you very much, since there are relatively many values in the interval (about a factor 100 as opposed to 1 - and I ask, again, of purists to ignore the simplification). Typically, you are going to need a bigger interval when you want to be 99% certain that the true value is in it, than when you only need to be 95% certain (note: this may not be true if the intervals are not nested), so indeed, the more confidence you need, the broader the interval you will need to pick. On the other hand, you are more certain with the higher confidence interval. So, If I give you 2 intervals of the same width, and I say one is a 95% CI and the other is a 99% CI, I hope you will prefer the 99% one. In this sense, 99% CIs are more accurate: you have less doubt that you will have missed the truth.
185	The 95% is not numerically attached at all to how confident you are that you've covered the true effect in your experiment. Perhaps recognizing that "interval using 95% coverage range calculation" might be a more accurate name for it. You can make the choice to decide that the interval contains the true value; and you'll be right if you do that consistently 95% of the time. But you really don't know how likely it is for your particular experiment without more information. Q1: Your first query conflates two things and misuses a term. No wonder you're confused. A narrower confidence interval may be more precise but, when calculated the same way, such as the 95% method, they all have the same accuracy. They capture the true value the same proportion of the time. Also, just because it's narrow doesn't mean you're less likely to encounter a sample that falls within that narrow confidence interval. A narrow confidence interval can be achieved one of three ways. The experimental method or nature of the data could just have very low variance. The confidence interval around the boiling point of tap water at sea level is pretty small, regardless of the sample size. The confidence interval around the average weight of people might be rather large because people are very variable but one can make that confidence interval smaller by just acquiring more observations. In that case, as you gain more certainty about where you believe the true value is, by collecting more samples and making a narrower confidence interval, then the probability of encountering an individual in that confidence interval does go down. (it goes down in any case when you increase sample size, but you may not bother collecting the big sample in the boiling water case). Finally, it could be narrow because your sample is unrepresentative. In that case you are actually more likely to have one of the 5% of intervals that does not contain the true value. It's a bit of a paradox regarding CI width and something you should check by knowing the literature and how variable this data typically is. Further consider that the confidence interval is about trying to estimate the true mean value of the population. If you knew that spot on then you'd be even more precise (and accurate) and not even have a range of estimates. But your probability of encountering an observation with that exact same value would be far lower than finding one within any particular sample based CI. Q2: A 99% confidence interval is wider than a 95%. Therefore, it's more likely that it will contain the true value. See the distinction above between precise and accurate, you're conflating the two. If I make a confidence interval narrower with lower variability and higher sample size it becomes more precise, the likely values cover a smaller range. If I increase the coverage by using a 99% calculation it becomes more accurate, the true value is more likely to be within the range.
186	For a given dataset, increasing the confidence level of a confidence interval will only result in larger intervals (or at least not smaller). That's not about accuracy or precision but rather about how much risk you're willing to take about missing the true value. If you're comparing confidence intervals for the same sort of parameter from multiple data sets and one is smaller than the other, you could say that the smaller one is more precise. I prefer to talk about precision rather than accuracy in this situation (see this relevant Wikipedia article).
187	The standard deviation is the square root of the variance. The standard deviation is expressed in the same units as the mean is, whereas the variance is expressed in squared units, but for looking at a distribution, you can use either just so long as you are clear about what you are using. For example, a Normal distribution with mean = 10 and sd = 3 is exactly the same thing as a Normal distribution with mean = 10 and variance = 9.
188	You don't need both. They each have different purposes. The SD is usually more useful to describe the variability of the data while the variance is usually much more useful mathematically. For example, the sum of uncorrelated distributions (random variables) also has a variance that is the sum of the variances of those distributions. This wouldn't be true of the SD. On the other hand, the SD has the convenience of being expressed in units of the original variable.
189	If John refers to independent random variables when he says "unrelated distributions," then his response is correct. However, to answer your question, there are several points that can be added: The mean and variance are the two parameters that determine a normal distribution. The Chebyshev inequality bounds the probability of a observed random variable being within $k$ standard deviations of the mean. The standard deviation is used to normalize statistics for statistical tests (e.g. the known standard deviation is used to normalize a sample mean for the $z$ test that the mean differs from $0$ or the sample standard deviation is used to normalize the sample mean when the true standard deviation is unknown, resulting in the $t$ test). For a normal distribution $68\%$ percent of the distribution is within $1$ standard deviation. $95.4\%$ within $2$ standard deviations and over $99\%$ within $3$ standard deviations. The margin of error is expressed as a multiple of the standard deviation of the estimate. Variance and bias are measures of uncertainty in a random quantity. The mean square error for an estimate equals the variance + the squared bias.
190	Removing some of the data points in the middle would change the empirical distribution and therefore the qqplot. This being said, you can do the following and directly plot the quantiles of the empirical distribution vs. the quantiles of the theoretical distribution: x <- rnorm(1200000) mean.x <- mean(x) sd.x <- sd(x) quantiles.x <- quantile(x, probs = seq(0,1,b=0.000001)) quantiles.empirical <- qnorm(seq(0,1,by=0.000001),mean.x,sd.x) plot(quantiles.x~quantiles.empirical) You will have to adjust the seq depending on how deep you want to get into the tails. If you want to get clever you can also thin that sequence in the middle to speed up the plot. For example using plogis(seq(-17,17,by=.1)) is a possibility.
191	I am adding to some good answers here that I gave upvotes to. I think there is a little more that should be said to completely clear up the conclusion. I like the terms accurate and correct as Efron defines them. I gave a lengthy discussion on this very recently on a different question. Moderate whuber really liked that answer. I will not go to the same lnegth to repeat that here. However to Efron accuracy relates to the confidence level and correctness to the width or tightness of the interval. But you can't talk about tightness without considering accuracy first. Some confidence intervals are exact those are accurate because they have the actual coverage that they advertise. A 95% confidence interval can also be approximate because it uses an asymptotic distribution. Approximate intervals based on asymptotics are for a finite sample size n not going to have the advertised coverage which is the coverage you would get if the asymptotic distributionwere the exact distribution. So an approximate interval could undercover (i.e. advertise 95% when its actual coverage is only 91%) or in the rare but less serious case overcover (i.e. advertised coverage is 95% but actual in 98%). In the former case we worry about how close the actual coverage is to the advertised coverage). A measure of closeness is the order of accuracy which could be say 1/√n or 1/n. If the actual confidence level is close we call it accurate. Accuray is important with bootstrap confidence intervals which are never exact but some variants are more accurate than others. This definition of accuracy may be different to the one the OP is referring to but it should be clear now what Efron's definition is and why it is important to be accurate. Now if you have two methods that are exact we can prefer one over the other if for any confidence level it has the smaller expected width. A confidence interval that is best in this sense (sometime called shortest) would be the one to choose. But this required exactness. If the confidence level is only approximate we could be comparing apples and oranges. One could be narrower than another only because it is less accurate and hence has a lower actual coverage than its advertised coverage. If two confidence intervals are both very accurate or one is exact and the other very accurate comparing expected width may be okay because at least now we are looking at just two two varieties of apples.
192	I'm not sure #1 has a specific course of action, other than "add some more predictive features to your model". There are probably many potential causes to #2, but one can be outliers in the training dataset skewing some of the parameters in a logistic regression model.
193	While calculating the variance, we squared the deviations. It mean that if the given data (observations) is in meters, it will become meter square. Hope it's not correct representation about the deviations. So, we square root again (SD) that is nothing but SD.
194	The variance of a data set measures the mathematical dispersion of the data relative to the mean. However, though this value is theoretically correct, it is difficult to apply in a real-world sense because the values used to calculate it were squared. The standard deviation, as the square root of the variance gives a value that is in the same units as the original values, which makes it much easier to work with and easier to interpret in conjunction with the concept of the normal curve.
195	In terms of the distribution they're equivalent (yet obviously not interchangeable), but beware that in terms of estimators they're not: the square root of an estimate of the variance is NOT an (unbiased) estimator of the standard deviation. Only for a moderately large number of samples (and depending on the estimators) the two approach each other. For small sample sizes you need to know the parametric form of the distribution to convert among the two, which can become slightly circular.
196	Lets start by assuming the binomial distribution standard deviation is correct (it is). This is the standard deviation of the distribution of the number of successes out of $n$ trials given constant probability of success $p$. Call the number of successes, $X$. So $Var(X) = np(1-p)$, which is what you have (standard deviation squared). Since a proportion is the number of successes over the number of trials, we have: $Var(\frac{X}{n}) = \frac{Var(X)}{n^2} = \frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}$. And thus standard deviation is of course $\sqrt{\frac{p(1-p)}{n}}$. In one case you are looking at counts, in the other you are looking at counts divided by sample size. Intuitively, you can imagine the counts of the number of successes are much higher ($X = 0, 1, 2, \ldots, n$) than a proportion ($0 \leq p \leq 1$). As $n$ increases, $X$ can take many different (and larger) integer values and has more variability; $p$, on the other hand, is restricted between 0 and 1. So $X$ has more variability.
197	I believe what you are looking for is Item Response Theory. The "useless" questions you refer to are items with poor discrimination. Using IRT analysis you can calculate the discrimination, difficulty, and the associated probability of guessing on items by survey participants. The R program has an easy package for using IRT and I imagine other statistical software packages do as well. If you want a quick overview here's the wikipedia page, but I would advise researching it more. http://en.wikipedia.org/wiki/Item_response_theory
198	In general, one can show that if $X_1, \ldots, X_n \text{ i.i.d. } \sim F$, then: $$\sqrt{n}(X_{(np)} - p)\overset{d}\rightarrow \mathrm{N}\left(0, \frac{p(1 - p)}{f^{2}(\xi_p)}\right)$$ where $f$ is the density of $F$. This result is classical, and can be proven in many ways, for one possible reference, see Example 2.4.9 in Lehmann's book: Elements of large-sample theory. In your case, based on this result, you can show that: $$\sqrt{n}(X_{(n/3)} - 1/3)\overset{d}\rightarrow \mathrm{N}\left(0, \frac{2}{9}\right).$$ The above statement is about convergence in distribution, using Slutsky's theorem, your educated case can be confirmed --- but you have to point out the convergence mode: it converges in probability. It is incorrect to just say "it converges to 1/3". To show it converges in probability to 1/3, it is more straightforward, you can just show $\mathrm{Var}(X_{(n/3)}) \rightarrow 0$ as $n \to \infty$.
199	Taking a transpose doesn't really make sense. You define vectors as either rows or columns (based on the notation used here it appears column vectors are used) and then define the kernel/mapping function accordingly. Basically, everything revolves around the following notation of inner product in feature space after using the mapping function $\phi(\cdot): \mathbb{R}^I \mapsto \mathbb{R}^F$ with $I$ and $F$ the input and feature space dimensionality, respectively (assuming column vectors): $$\kappa(\mathbf{u}, \mathbf{v}) = \langle \phi(\mathbf{u}), \phi(\mathbf{v}) \rangle = \phi(\mathbf{u})^T \phi(\mathbf{v}).$$ The reason the correct answer is A is evident, as all distances using $\phi_2$ will be a factor 4 larger than those of $\phi_1$. $\phi_2$ is essentially the same mapping as $\phi_1$, but scaling each mapped coordinate by a factor 2. If you have two (column) vectors $\mathbf{u}$ and $\mathbf{v}$ and a feature-wise scaling factor $\alpha$, then: $$\langle \mathbf{u}, \mathbf{v} \rangle = \mathbf{u}^T \mathbf{v}$$ $$\langle \alpha \mathbf{u}, \alpha \mathbf{v} \rangle = \alpha^2 \mathbf{u}^T \mathbf{v} = \alpha^2 \langle \mathbf{u}, \mathbf{v} \rangle$$ In the assignment $\phi_1(\mathbf{x}) = [\mathbf{x}, \mathbf{x}^2]^T$ and $\phi_2(\mathbf{x}) = [2\mathbf{x}, 2\mathbf{x}^2]^T = 2 \phi_1(\mathbf{x})$, which immediately means that all distances in the feature space induced by $\phi_2$ are a factor 4 larger than those in the space induced by $\phi_1$. For the final notation you assume column vectors, but you might just as well use row vectors (then a dot product is $\langle \mathbf{u},\mathbf{v}\rangle=\mathbf{uv}^T$ instead of $\langle \mathbf{u},\mathbf{v}\rangle=\mathbf{u}^T\mathbf{v}$). It's a matter of definition. However, if you start working in column vectors you have to continue doing so.
200	Not quite: these statements are only about Lance, not about all vegetarians. Suppose that we add the following piece of information to the little narrative: "Lance is not a vegetarian." Then $P(S_3) = P(S_4)$, since your event $B$ has probability zero. Since it's possible from the information given that Lance is a vegetarian, it's possible that $P(S_3) = P(S_4)$. Now, if we were asked to assign probabilities to these events based on the given narrative, it would only be reasonable to assign some probability to $B$, and moreover to assign some probability to $B \setminus A$ (Lance is a vegetarian and doesn't like barbecue). So, to anyone with common sense interpreting this narrative, $P(S_4) > P(S_3)$. (In general, it's a very bad idea to assign zero probability to anything that isn't logically impossible, because then no matter how much evidence you see to the contrary you'll never believe it.) I think then the "right answer" is somewhat debatable, depending on how you interpret this kind of weird problem setup, but $P(S_4) \ge P(S_3)$ seems the "most" correct to me.
201	This is an expanded (or exegetical expansion of @StasK answer) attempt at the question focusing on proportions. Standard Error: The standard error (SE) of the sampling distribution a proportion $p$ is defined as: $\text{SE}_p=\sqrt{\frac{p\,(1-p)}{n}}$. This can be contrasted to the standard deviation (SD) of the sampling distribution of a proportion $\pi$: $\sigma_p=\sqrt{\frac{\pi\,(1-\pi)}{n}}$. Confidence Interval: The confidence interval estimates the population parameter $\pi$ based on the sampling distribution and the central limit theorem (CLT) that allows a normal approximation. Hence, given a SE, and a proportion, $95\%$ the confidence interval will be calculated as: $$p\,\pm\,Z_{\alpha/2}\,\text{SE}$$ Given that $Z_{\alpha/2}=Z_{0.975}=1.959964\sim1.96$, the CI will be: $$p\,\pm\,1.96\,\sqrt{\frac{p\,(1-p)}{n}}$$. This raises a question regarding the utilization of the normal distribution even if we really don't know the population SD - when estimating confidence intervals for means, if the SE is used in lieu of the SD, the $t$ distribution is typically felt to be a better choice due to its fatter tails. However, in the case of a proportion, there is only one parameter, $p$, being estimated, since the formula for the Bernouilli variance is entirely dependent on $p$ as $p\,(1-p)$. This is very nicely explained here. Margin of Error: The margin of error is simply the "radius" (or half the width) of a confidence interval for a particular statistic, in this case the sample proportion: $\text{ME}_{\text{@ 95% CI}}=1.96\,\sqrt{\frac{p\,(1-p)}{n}}$. Graphically,
202	Compilation and expansion of comments: Let's presume your data is Normally distributed. If you want to form two-sided error bars (or confidence intervals), say at the 95% level, you will need to base that on the Student t distribution with n-1 degrees of freedom, where n is the number of data points. You propose to have 2 data points, therefore requiring use of Student t with 1 degree of freedom. 95% 2-sided error bars for n = 2 data points require a multiplicative factor of 12.71 on the sample standard deviation, not the familiar factor of 1.96 based on the Normal (Student t with $\infty$ degrees of freedom). The corresponding multiplicative factor for n = 3 data points is 4.30. The situation gets even more extreme for two-sided 99% error bars (confidence intervals). As you can see, at either confidence level, there's a big "savings" in the multiplicative factor if you have 3 data points instead of 2. And you don't get dinged as badly by the use of n-1 vs. n in the denominator of sample standard deviation. n Confidence Level Multiplicative Factor 2 0.95 12.71 3 0.95 4.30 4 0.95 3.18 5 0.95 2.78 infinity 0.95 1.96 2 0.99 63.66 3 0.99 9.92 4 0.99 5.84 5 0.99 4.60 infinity 0.99 2.58
203	Here is an example of a 2-dimensional Kalman filter that may be useful to you. It is in Python. The state vector is consists of four variables: position in the x0-direction, position in the x1-direction, velocity in the x0-direction, and velocity in the x1-direction. See the commented line "x: initial state 4-tuple of location and velocity: (x0, x1, x0_dot, x1_dot)". The state-transition matrix (F), which facilitates prediction of the system/objects next state, combines the present state values of position and velocity to predict position (i.e. x0 + x0_dot and x1 + x1_dot) and the present state values of velocity for velocity (i.e. x0_dot and x1_dot). The measurement matrix (H) appears to consider only position in both the x0 and x1 positions. The motion noise matrix (Q) is initialized to a 4-by-4 identity matrix, while the measurement noise is set to 0.0001. Hopefully this example will allow you to get your code working.
204	Setting aside your initial explanation of the time-series context, it might be useful to look at this as a simple case of observing two data points. For any two observed values $x_1 , x_2$ the sample standard deviation is $s = |x_2 - x_1| / \sqrt2$. This statistic is exactly as informative as giving the sample range of the two values (since it is just a scalar multiple of that statistic). There is nothing inherently wrong with using this statistic as information on the standard deviation of the underlying distribution, but obviously there is a great deal of variability to this statistic. The sampling distribution of the sample standard deviation depends on the underlying distribution for the observable values. In the special case where $X_1, X_2 \sim \text{IID N}(\mu, \sigma^2)$ are normal values you have $S \sim \sigma \cdot \chi_1$ which is a scaled half-normal distribution. Obviously this means that your sample standard deviation is quite a poor estimator of the standard deviation parameter (biased and with high variance), but that is to be expected with so little data.
205	If you only have 2 values, just present those 2 values. It doesn't make sense to convert 2 measurements into 2 other quantities (mean and stdev) if your audience is going to argue about the significance of one or the other. If you want to estimate uncertainty, these other responses are right on, but don't forget to add other potential sources of error (measurement instrument bias errors, resolution, etc.).
206	The $p$-value takes into account both the strength of the correlation $r$ as well as the number of samples. For example, if you had only two samples, you could easily fit a line through them, but your $p$-value would be large because 2 samples just aren't enough to tell you what's going on. Or in your example with $r = 0.98, p = 0.14$, how many samples do you have? If even with a nearly perfect correlation you do not get statistical significance that tells you that you might as well never have bothered to collect the data because no matter how strong the association you wouldn't be able to verify it. To avoid something like this, one can determine how many samples one needs before even conducting the analysis.
207	No, a probability mass function cannot have a value above 1. Quite simply, all the values of the probability mass function must sum to 1. Also, they must be non-negative. From here it follows that, if one of the values exceeded 1, the whole sum would exceed 1. And that is not allowed.
208	Your question has 2 parts Probability Mass Function: It have discrete values and we count only those values for probability. So F(x):Pr(R=x) is only the probabilty which is always less than 1 Probability Density Distribution: Here we don't have discrete values and if we consider a point Pr(of single point)=0. Hence we consider area during continous distribution counting. Now since we don't know the exact points(x) for probability distribution there can be cases when probability can be concentrated on a small points rather than the asked points(x). And we also know that area under such PDF curve should be 1. Hence if x is less than 1 then in order to keep area sum 1 value of F(x) should be greater than 1
209	With a fixed number of total cases N and 4 cells in the confusion matrix needing numbers of cases, you need to have 3 different additional sources of information. It's important to distinguish between the number of TP, TN, FP, and FN cases and the corresponding rates. Putting together this answer about what you can do with the True Positive Rate (same as Sensitivity) and the False Positive Rate, with this answer to a related question on Precision (also a rate) and Recall (same as Sensitivity), shows what you can do just with Specificity (True Negative Rate) and Sensitivity, which is what you would "ideally" like to be able to do. As the above answers and the Wikipedia page on evaluating binary classifiers show, with the standard definitions the false negative rate, FNR, is simply given by FNR = 1 - Sensitivity as the denominator in both measures is the number of cases with Condition Positive (CP). Similarly, the false positive rate, FPR, is simply given by FPR = 1- Specificity as the denominator in both measures is the number of cases with Condition Negative (CN). That's as far as you can get with only Specificity and Sensitivity. As the Wikipedia page notes, these measures are independent of prevalence (CP/N), which is a third source of information that can be used to place case numbers into the confusion matrix. Knowing the prevalence among the actual number of cases, N, would be best, but if you have a reasonable estimate of prevalence "according to the reference test" then you could use the prevalence to get estimated values for CP and CN for any given N, then use those numbers with the rates as calculated above to fill in the matrix with the numbers of cases. You could proceed to use that matrix to calculate all the other measures used in binary classification, like Precision, Positive and Negative Predictive Values, etc., as shown in the Wikipedia page linked above. That said, none of these measures is necessarily a good way to evaluate a classification model. This answer gives some introduction to that issue, with links to more complete discussion.
210	As in a logistic regression, the response variable of a cumulative link model is not the ORDINAL_response variable, but the probability that the ORDINAL_response variable will be below each of its possible levels. Plotting predicted values of the ORDINAL_response variable is thus impossible and does not make much sense: it is an ordinal variable, a type of qualitative variable, so it cannot take any numerical value (although the levels can be labelled with numbers), and any values between the levels are not meaningful. To understand this last point, replace the numbers with which you labelled your levels by words such as "not at all", "very little", "a little", "a fair amount", "a lot", "all" (for 6 levels). In your situation, you could either plot the probability of each levels for each value of the continuous variable, or plot the most probable level for each value of the continuous variable. For the first option (here the example is for a five level ordinal response): p <- predict(model, newdata = data.frame(continuous_predictor = sort(continuous_predictor)), type = "prob", interval = TRUE) plot(sort(continuous_predictor),p$fit[,1], type = "l") lines(sort(continuous_predictor),p$lwr[,1], col = "red") lines(sort(continuous_predictor),p$upr[,1], col = "red") for (i in 2:5){ lines(sort(continuous_predictor),p$fit[,i], lty = i) lines(sort(continuous_predictor),p$lwr[,i], lty = i, col = "red") lines(sort(continuous_predictor),p$upr[,i], lty = i, col = "red") } You can of course remove the confidence intervals if the graph is difficult to read, or plot the predicted probability for each level on a separate graph. For the second option, after calculating the predicted probabilities as in the previous example: most.probable <- apply(p$fit, 1, which.max) plot(sort(continuous_predictor),most.probable) In the limit case where your variable is not really an ordinal variable but rather a discrete numerical variable (that is, there is always the same difference between successive levels, proportionality holds such that level 4 really represent twice as much as level 2, and calculating an average between different levels is meaningful), then you can calculate the statistical expected value for each value of the independent variable: expected <- p$fit %*% 1:5 plot(sort(continuous_predictor), expected)
211	After some more reading I came to following conclusion: Invertible NN are just neural networks that represent bijective functions $f$. Normalizing flows are invertible NN $f$ that also have a tractable determinant of the Jacobian $D_x f$ as well as a tractable inverse $f^{-1}$. This allows for following interpretation: Let $X \sim p_X, Z \sim p_Z$ be some random variable with $Z = f(X)$. Then $$p_X(x) = p_Z(f(x)) \det D_x f .$$ Because $f$ has a tractable inverse $f^{-1}$ we can therefore easily sample from one of the two distributions $p_X, p_Z$ by sampling from the other one and using the transformation above. This could be applied in the following way (just as an example): We could train $f$ such that $p_X$ represents a distribution of images (e.g. represented by MNIST) and $p_Z$ a Gaussian. Then we can easily sample from the distribution of images by sampling $Z \sim p_Z$ (Gaussian) and just transforming it back to $X = f^{-1}(Z) \sim p_X$.
212	The margin of error is the amount added and subtracted in a confidence interval. The standard error is the standard deviation of the sample statistics if we could take many samples of the same size.
213	Each sequence of 1000 tosses of a fair coin will have its own peculiarities. There are some easily derived statements about what you can expect most of the time. Some involve counting the number of Heads. Let $X$ be the number of heads in $n = 1000$ independent tosses of a fair coin. Then $\mu=E(X) = 500,\, \sigma^2=Var(X) = 250,\,$ $\sigma = SD(X) = \sqrt{250} = 15.8114.$ So you would expect [exact computation in R] $$P(\mu-2\sigma \le X\le \mu+2\sigma) \approx 0.95 \approx P(458 \le X \le 532) = 0.9765.$$ diff(pbinom(c(457,532), 1000, .5)) [1] 0.9765306 However, you could get $X = 500$ exactly, which is the most common outcome and yet have 250 Heads followed by 250 Tails, which would be very 'unusual' because there are only two runs. (A run is a sequence of repeated outcomes.) On average, one would expect about 501 runs in a sequence of 1000 tosses. The fewest possible runs is 2 and the greatest is 1000 (alternating H and T throughout). Thus you can get a very 'ordinary' value of $X$ and a (tiny or huge) number of runs that makes you wonder whether coin tosses are truly independent. In order to say whether your 20 consecutive coin tosses are "different from ideal," you would have to state your criterion for ideal. Do you mean an almost average number of heads, an almost average number of runs, or something else? You have raised an important question. People who seek algorithms for generating pseudo-random numbers by computer, have long lists of criteria for "satisfactory" behavior. The idea is to generate numbers by computer that cannot be distinguished from "random" for practical purposes.
214	As hinted by @whuber (with thanks), the key is to transform the expectation to the (pure) moment of another normal distribution. We first recognise the expectation in question is, by definition $$ \mathbb{E}_{X \sim \mathcal{N}(\mu, \sigma^2)}(X^n e^{tX}) = \int x^n \exp(tx)\frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}\right) \,\textrm{d}x .$$ We combine the exponential terms on the RHS to obtain $$ \int x^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{1}{2}\left[\frac{(x-\mu)^2}{\sigma^2} - 2tx\right]\right) \,\textrm{d}x $$ Completing the square within the square brackets we have $$ \int x^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{1}{2}\left[\frac{(x-(\mu+t\sigma^2))^2}{\sigma^2}\right]\right) \exp\left(\mu t + \frac{1}{2}\sigma^2 t^2\right) \,\textrm{d}x $$ The rightmost exponential term can be moved out of the integral. What is left inside is the moment of a different normal $\mathcal{N}(\mu + t\sigma^2, \sigma^2)$ by definition. Thus $$ \mathbb{E}_{X \sim \mathcal{N}(\mu, \sigma^2)}(X^n e^{tX}) = \mathbb{E}_{X \sim \mathcal{N}(\mu + t\sigma^2, \sigma^2)}(X^n) \cdot \exp\left(\mu t + \frac{1}{2}\sigma^2 t^2\right) $$ (For completeness) for $n = 1, 2$, $$\mathbb{E}_{X \sim \mathcal{N}(\mu + t\sigma^2, \sigma^2)}(X) = \mu + t\sigma^2$$ $$\mathbb{E}_{X \sim \mathcal{N}(\mu + t\sigma^2, \sigma^2)}(X^2) = Var(X) + \mathbb{E}^2_{X \sim \mathcal{N}(\mu + t\sigma^2, \sigma^2)}(X) = \sigma^2 + (\mu+t\sigma^2)^2.$$
215	One of the most popular ways to learn a (deterministic) function is Gaussian Process (GP) regression. It is commonly phrased in the Bayesian framework so that our 'prior beliefs' are $$ f(\cdot) \sim GP(m(\cdot), C(\cdot, \cdot))$$ where $m(\cdot)$ represents our prior expected value of $f(x)$ for any $x$. It's usually a 'rough and ready' approximation. E.g. you might be able to say $f(\cdot)$ is approximately linear over the domain of interest. Or perhaps a quadratic. Nothing too fancy here. The powerful component is $C(\cdot, \cdot)$ - the covariance function. By definition, $$Cov( f(x), f(x')) = C(x, x')$$ that is $C$ tells us about how correlated $f(x)$ is with $f(x')$. A very common covariance function is $$ C(x, x') = \sigma^2 \exp \left\{ -\frac{(x - x')^2}{\theta^2} \right\}$$ which is commonly called the 'squared exponential' covariance function. It's useful when $f$ is thought to be very smooth (in fact, the squared exponential covariance implies $f$ is infinitely mean square differentiable.). The GP (with this covariance function) also has the nice property that if you observe $f(x_0) = y_0$ the GP predicition at $x_0$ will be exactly $y_0$. It is an interpolator. Now, suppose I have observed outputs $y_i = f(x_i)$: $y = (y_1, y_2,\ldots, y_n)^T$ at $x = (x_1, x_2, \ldots, x_n)^T$. Denote the dataset $D_n = (x, y)$. Suppose I want to predict $y_0 = f(x_0)$ for some 'unseen' $x_0$. Under these GP assumptions, any finite collection of $y$s will be multivariate normal: $$ \begin{pmatrix} y \\ f(x_0) \end{pmatrix} \sim N \left\{\begin{pmatrix} m(x) \\ m(x_0) \end{pmatrix} , \begin{pmatrix} \Sigma_{yy} & \Sigma_{yy_0}\\ \Sigma_{y y} & \Sigma_{y_0 y_0 }\end{pmatrix} \right\}$$ Now the $\Sigma$ terms contain $C(x,x')$ for the various choices of $x_i$ we have observed. Then, conditional on $D_n$ we have $f(x_0) \sim N(m^*, v^*)$ with \begin{align} m^{*} &= m(x_0)- \Sigma_{y_0 y}\Sigma_{y y}^{-1}(y - m(x))\\ v^{*} & = \Sigma_{y_0 y_0} - \Sigma_{y_0 y}\Sigma_{y y}^{-1}\Sigma_{y y_0} \end{align} This is just a bit of simple matrix computation (can be a bit fiddly in practice though). Using some nice formulae, these predictions update nicely. See the equations between (8) and (9) here - this allows for 'online' prediction. Let's wrap it up with a nice little picture of a prediction, given some data: I'd also like to suggest Bobby Gramacy's textbook, Surrogates for further reading. It's geared specifically towards learning functions, it's quite new and a really nice read. There's also GPML an older textbook that is very popular (because it's very good!)
216	One approach is a scatter plot matrix with jittering of points given over-plotting of identical values. Refinements might include, depending partly on taste: Bubble plots, where bubble size encodes frequency. Hinton- or Bertin-type twoway bar charts, where bar height encodes frequency. In this case visual patterns can be supported by measures of agreement (not correlation) such as Lin's concordance correlation: Rating_1 Rating_2 0.633 Rating_1 Rating_True 0.630 Rating_2 Rating_True 0.839
217	Document everything. If you can't get a reply from the editors of the journal, write to the publisher. Or if it's the journal of a learned society, contact them. You probably can't act alone, but you may get more powerful allies (deeper pockets) on your side. There are others around you who have a vested interest in your work. In particular, the journal where you published your work… given that you transferred them the copyright, I suppose they might act in their own name against the plagiarist. Even if it does not escalate all the way to a legal action, the publisher of the plagiarized work might respond (or respond faster) to a well-known publisher. Your employer may also have an interest in helping you enforcing your copyright. They may also have a legal department who can advise you on this matter.
218	To answer some of your questions, a lot of this will vary from university to university, and vary by location. One major aspect is to determine your research focus as early as possible and plan long and medium term objectives, and how these objectives are to be met at the beginning, in consultation with your advisors (that is the advice I was given). Duration There is usually an upper limit of how long a student can take to complete the dissertation, and it is generally expected that the research, experiments, dissertation write up is performed within the time frame dictated by the university. Note, the length of time taken to complete the PhD is not necessarily a measure of how credible it is. (I completed my PhD in Physics in 2.5 years). Papers are often published in consultation between you and your advisor(s). But, during my PhD I was advised that it is a good idea to get some publications completed while you are studying (I completed 4 while completing the research). Courses This varies between universities and places, for example, I was not required to take any courses whatsoever - just pure research. That is something you will need to check with any university you apply to. I did my PhD while working full time in an unrelated field, so I arranged regular (fortnightly) Skype meetings with my advisors, where short term goals were set and the medium and long term goals checked up on. As you are doing sciences by the looks of it, it will involve a considerable amount of experimentation (potentially) - some of it can be tedious, make sure you plan and get into that as soon as possible, while ensuring you get the most accurate possible data in a safe and efficient manner. Completion You complete your research when you have met your objectives and have, through research and experimentation, 'answered' your research focus. What happens then varies between universities, some you will be expected to defend your thesis, and some, as in my case, your thesis is peer-reviewed. Once all that is done and your advisors and the university are satisfied, you will be told that you have passed (in my case, I received a letter stating as such). But, the research never really ends, once you have that passion for that topic - you may find that the research continues, but now to be published as papers (this also has been my experience). Find a topic that ignites the fire in you and you'll find that the PhD is just the start of the journey. Finally and critically, make sure what you are doing is something that you find fascinating, something that you won't mind putting in many hours of research and work into. Choose something that is either your passion or something related to it. Get ready to challenge yourself on a regular basis. I hope this helps.
219	I searched her name in Google Scholar and the first paper "CLIL implementation in Italian schools..." includes a footnote on how to cite it: Di Martino, E. & Di Sabato, B. ... So, in short "Di Martino" is the surname and cite/use it as such.
220	One thing to keep in mind is that there is a substantial difference in several continental languages between uppercase and lowercase versions of a last name: it is wrong to write "de Martino" if the person's last name is normally written "De Martino." This is a historical artifact, where the use of the capital letter indicates nobility, while the lowercase letter denotes a more traditional relationship. Similar rules apply to "von" in German and "van" in Dutch, but not to "de" in French or Spanish. Therefore, when capitalized, the particle should always be treated as part of the last name. If lowercase, you can treat it as a suffix that goes after the first name. The exception are names like "de Gaulle" where "de" is followed by a one-syllable name. So, it's: Beethoven, Ludwig van Clausewitz, Carl von de Gaulle, Charles Di Martino, Emilia Martino, Emilia di Maupassant, Guy de Van Allen, James My source is the MLA Handbook.
221	It is standard practice in the US for students to apply for graduate programs before they have received a degree, and the TOEFL exam is normally taken as part of the admissions process. However, you should also be aware of the fact that you have largely missed the admissions "window" for this coming fall: at most American graduate schools, you need to apply during the previous fall. So, for instance, to apply for admission in September 2014, you should have applied during the period (roughly) September 2013 to January 2014. It is unlikely you will be able to secure admission to any American graduate school starting this September. At best you will be able to apply for admission in the fall of 2015. The only exception will be schools with "rolling admissions," which accept applications at any time. As for the acceptance of the "triennale" degree, you will need to ask the individual schools you're interested in; I'm not aware of any such master list (because the number of recipients of such degrees who enroll in any particular program probably isn't big enough to support such a list).
222	Distance learning students who will not enter the United States are not required to get a U.S. visa. In fact, by federal law, online-only students are not eligible for a student visa.
223	This really depends on the publisher's style guide. If the style calls for the use of periods after "et al." or other such expressions, then you should use them, independent of whether the reference forces an additional period. if the guidelines don't ask for one, don't use it.
224	Typically journal editors are volunteers. I suppose for some of the flagships (Nature, Science, Cell, etc.) they might have full-time paid editors, but your typical niche research journal editor doesn't get much if anything at all.
225	It depends on the journal and on which type of editor you are talking about. A lot of journals do not have paid scientific staff. They have editorial staff doing administrative work and a senior editor dispatching the received papers between "Associate editors" (but each journal has its own designation). The associate editor decides if the paper is suitable for the journal, finds reviewers and makes a decision. These associate editors are generally not paid, they are academics doing this as a community service. If the journal is run by a scientific society, editors are usually members of this society.
226	I quite often asked this question myself but realized that much of the works out there simply are not focused for those fluent in the field. Granted, that doesn't mean someone from the field can't read it; it's more of a factor that the work is meant to appeal to people outside of the field too. For instance, a document explaining how to use a piece of software, while it will obviously be rudimentary to people who use the software, the "John Does" of the world might not even understand the point or some of the spicy terminology. The software could be something like Microsoft Paint (where the use-case is at least somewhat intuitive) all the way to complex software development software such as NetBeans, Eclipse, and IntelliJ IDEA. Think of it this way: If I wrote a paper on how software is made but I use what are basic terms (such as compiler, IDE, etc.) to me, would you be able to understand what is going on in the work? I would argue that having such details on some of the concepts may help people such as new learners to the field or even spark the interest of those who were not previously interested in the field. Reading works of others when I was much younger has prompted me to take up the field I've taken now. I rambled a bit, so I'll summarize. It is because those not as fluent in the field will likely read the work or in the event that someone such as that does, the work can at least assist them to understanding basic concepts and terms used within the work.
227	Let's tease apart two issues here: Has a paper undergone peer review of its technical content (which will include the statistical content)? Should you believe the statistics in the paper? If it's in a well-respected peer-reviewed journal, then you can assume that it's undergone reasonable peer review. That means it's unlikely that the content is blatantly and obviously crazy, and that in fact it's likely to be fairly solid. It does not mean, however, that it is correct, particularly when it comes to something as subtle and frequently mis-applied as statistical analysis. Bad statistical analysis is extremely common in every field of science, for a number of different reasons. Ignorance is a really big one, though, and one that's likely to be shared by the peer reviewers. Thus, if you want to know whether to trust statistical analysis, you need to look at it yourself.
228	You can publish anything interesting. There are instance where a new proof of a new theorem is not interesting. There are also cases where a better exposition of the existing proof is interesting.
229	An editor can ask for coherence. He can also throw out the chapter if there are omissions that he thinks are critical. He can, in that vein, request that references be included. But the responsibility on the article lies with the authors, and so the editor can never modify the content of the article without their approval; he must ask their permission. This falls out side of his "jurisdiction" (exceptions can exist in commercial publication/scriptwriting where the rights on the material may not fully lie with the concrete author). Imagine the extreme case of the editor quoting some crank papers under the author's name. In the concrete case, OP should consider: whether the citations are, content-wise, appropriate and acceptable or not; if they are acceptable, whether OP wishes to place the matter of the unauthorised addition on the table; if OP decides to put them on the table, whether they would withdraw the article if the editor's justification is unsatisfactory. Depending on the responses, OP may consider to withdraw the article; or insist on the references being removed; or accept the references and not work again with this editor in the future; or accept the references as a welcome addition to the paper.
230	If you were in deep space, i,e., a spot somewhere between galaxies, then the night sky would look a lot like the sky seen by astronauts in the ISS, when they look away from both the ecliptic plane and the galactic plane, minus the individual Galactic stars. That is, it is like our deep sky photos in those directions that are dominated by galaxies, but no atmospheric distortions, no night sky lines, and no zodiacal light. The spectrum is dominated by different things at different wavelengths, but basically it is the sum of the light of galaxies and perhaps intergalactic stars that escaped their galaxies. At long radio waves, it is dominated by supernova remnants and AGN as self-absorbed synchrotron radiation, peaking between 1 and 10 Mhz (Simon 1977). The mm band is dominated by the microwave background radiation at 2.7 C. The far-ir is dominated by cold galaxy dust at 60 microns. The optical is dominated by galaxy thermal starlight at 1 micron. The UV is dominated by hot stars at 0.2 microns (see summary). The Xray spectrum from 3 to about 45 keV (Marshall et al 1980, Fabian 1992) is well-fitted by a ~40 keV thermal bremsstrahlung model. Above 45 kev the spectrum falls and is thought to be the sum of many AGN at all redshifts. The spectral energy density (SED) from radio to X-ray is shown in this diagram from the paper by Hill et al. (2018) The Spectrum of the Universe: The width of the line in the diagram shows the present uncertainties in the measurements. Dark energy does not shine, it has an effect on the redshift as a function of time and thereby indirectly affects the shape of the background spectrum.
231	A constellation is more of a direction than a place, a sort of a three dimensional wedge of space extending from Earth to infinity. So saying that astronomical objects are "in" constellations can be a little bit misleading. Basically the sky looks sort of like a hemispherical dome at any one time. And since Earth is a ball floating in space it looks like it is surrounded by a spherical shell. It is impossible to see how far away astronomical bodies are - their distances have to be measured using precise instruments - so all the visible stars look like they are the same distance away. So for thousands of years scientists more or less assumed that the stars were lights on the surface of a spherical shell far beyond Earth. And for thousands of years people have been noticing apparent patterns in the stars that appeared to be at the same distance. And so they gave names to those patterns and called them constellations. And as the Sun and Moon and planets moved around in space, each planet believed to be attached to an invisible crystal sphere, they appeared to move in front of various constellations, and thus they were said to be "in" those constellations, even though they were believed to be much closer to Earth than the shell of stars was. And a few centuries ago the scientific revolution more or less destroyed belief in invisible crystal shells with planets attached, and thus in the sphere of stars, and astronomers became open to the idea that stars might be at various distances from Earth. After a century or two of attempts to measure the distances to stars, the distances to three stars were measured in the 1830s, 61 Cygni at over 10 light years, Alpha Centauri at over four light years, and Vega about 25 light years. Obviously they could not be attached to a spherical shell centered on the Sun. In the 20th century, astronomers established official borders for the constellations. The simplest possible shape for a constellation is a rectangle drawn on the celestial sphere. Since the celestial sphere doesn't physically exist and space extends to infinity, the actual shape of a simplest possible constellation would be a sort of a pyramid, with a rectangular cross section and a steep slope, extending from the solar system to infinity. And many constellations have more complex shapes, being composed of several attached two dimensional rectangles and thus being complex three dimensional pyramids extending from Earth to infinity. And since constellations extend from Earth to infinity, saying that an astronomical body is "in" a constellation, or giving its coordinates on the celestial sphere, can show where to point a telescope at it, but doesn't say how far it is from Earth. For example, the Moon passes through the Zodiac constellations as it orbits the Earth. The average distance of the Moon from earth is 384,399 kilometers. During solar eclipses, the Moon passes in front of the Sun, and thus appears to be very close to the Sun. But the average distance from the Earth to the Sun is 149,597,870.7 kilometers, or one Astronomical unit, or one AU. That is about 389.17 times as far as the Moon. And sometimes the Moon passes in front of, and occludes, a star, thus appearing very close to that star. For example, in July 1997, the Moon occluded the star Aldebaran. Astronomers and science fiction writers measure large distances in light years and parsecs. A light year is defined as 63,241.077 AU, or 24,611,841.27 times the distance of the Moon, and a parsec is 206,264.806 AU, or 80,272,074.55 times the distance of the Moon. Aldebaran is about 65 light years from Earth, and thus about 159,976,977 times as far from Earth as the Moon, so looking right beside each other just before the Moon occludes Aldebaran is not very informative about their actual relationship. Aldebaran appears to be a member of the Hyades star cluster, but the Hyades are actually about 153 light years or 47 parsecs from Earth. The Pleiades star cluster appears near to Aldebaran and the Hyades but is actually about 400 light years from Earth. Stars in the Constellation Andromeda, that appear to be close together as seen from Earth, include: Ross 248, only 10.32 light years from Earth. Upsilon Andromedae, 44 light years from Earth, with four planets. OU Andromedae, 440 light years from Earth, 10 times as far as Upsilon Andromedae. HAT-P-32, 1,044 light years from Earth, 100 times as far as Ross 248. HD 225518, 1,680 light years from Earth, 38 times as far as Upsilon Andromedae. And of course the Andromeda galaxy, the center of which is 2,540,000 light years from Earth, or about 246,124.03 times as far as Ross 248. It is quite possible for a star 100 light years from Earth to appear next to a galaxy 100 million light years from Earth, or for a galaxy 10 million light years from Earth to appear next to a galaxy that is 10 billion light years from Earth. It is perfectly possible for the Moon to occult a galaxy billions or trillions of times as far away as it is. So saying that astronomical bodies are "in" constellations can be deceptive. It may narrow down the directions to those astronomical bodies, but it doesn't specify the very important distances to those bodies. It is perfectly possible for two bodies "in" a constellation to be so far apart that one of them is hundreds or thousands of times closer to a body on the opposite side of the sky than to the other body "in" that constellation. Constellations should be thought of as directions instead of places.
232	It's a little unclear what you're asking for, but... "Heliocentric velocity" means measured radial velocity of an object relative to the Sun. (Which basically means relative to us, except you take out the variations due to the Earth's motion around the Sun.) For galaxies more distant than, say, the Local Group, the heliocentric velocity is the combination of a) the Sun's motion in our Galaxy; b) the local peculiar motion of our Galaxy; c) the local peculiar motion of the other galaxy; and d) the cosmic expansion of the universe ("cosmological redshift"). The first three never vary that much, but the fourth increases with distance, so for distant galaxies, it's (almost) all due to the cosmic expansion. "Rotation velocity" for a galaxy generally means the speed of stars and gas clouds about the center of that galaxy; it is not one single number but a function of distance from the galaxy's center -- though in the outer parts of the galaxy it often settles to a nearly constant value, which may indeed be referred to as "the" rotation velocity. The two have nothing to do with each other, though. For example, the rotation velocity in the outer part of M31 (the Andromeda Galaxy) is about 230 km/s, while its heliocentric velocity is about $-300$ km/s. If it were 100 megaparsecs away in the Coma Cluster, its heliocentric velocity would be something like 7000 km/s, but its rotation velocity would be the same.
233	A thermal inversion is defined as when the temperature of the air increases with height. By default, there always exists an inversion at the tropopause due to the exothermal Chapman cycle. But let's ignore that, given the context of the question. Let's take a look at the thermodynamic equation and see how the stability changes. The diagnostic equation for the dry adiabatic potential temperature ($\theta$) is $$\frac{D \theta}{Dt}=\frac{\partial \theta}{\partial t}+u\frac{\partial \theta}{\partial x}+v\frac{\partial \theta}{\partial y}+w\frac{\partial \theta}{\partial z}=Q$$, where $u$,$v$,and $w$ are the zonal, meridional, and vertical components of the wind vector, and $Q$ is the diabatic heating rate. Taking the vertical dervative of the above equation is $$\frac{\partial}{\partial t}\frac{\partial \theta}{\partial z}+u\frac{\partial}{\partial x}\frac{\partial \theta}{\partial z}+v\frac{\partial}{\partial y}\frac{\partial \theta}{\partial z}+w\frac{\partial}{\partial z}\frac{\partial \theta}{\partial z}+\frac{\partial u}{\partial z}\frac{\partial \theta}{\partial x}+\frac{\partial v}{\partial z}\frac{\partial \theta}{\partial y}+\frac{\partial w}{\partial z}\frac{\partial \theta}{\partial z}=\frac{\partial Q}{\partial z}$$. From this equation, we can see that differential diabatic heating, advection of stable air, and vertical wind shear in an environment prone to thermal gradients that can enhance inversions. Intrinsically, the wind speed tends to decrease during an inversion, but not all slow winds note an inversion. Inversions tend to occur overnight into the morning, as the air cools at a slower rate than the land. There are tons of other factors that influence air pollution, but it really depends on the pollutant. For example, ozone pollution won't be affected much by an inversion, with the exception of accumulating morning $\ce{NO_x}$ for a morning peak. Other factors include the amount of water for PM2.5 formation. There is also wet and dry deposition to consider. The question you are asking is very general.
234	As explained in https://electronics.stackexchange.com/a/521282/73158 it is a pressure switch. The resistance of the hose and shower head will cause the pressure to rise with increasing flow. As you have stated, "When there is fast water flow, it pushes the switch on the left of the round white part". Any ideas whether it needs certain pressure or psi to turn on? Yes. It has to overcome a specified spring pressure.
235	Sometimes, it is meaningful to visualize high dimensional data since it may tell us physics. There is at least one example in astrophysics where you project your data down to principal components generated by PCA and those principal components correspond to much physical insight about the galaxies. For detail, see the paper. Here is the basic idea. The authors apply PCA to many spectra (e.g., 10,000) from a telescope. Each spectrum has ~1000 attributes. Since this data set has large dimensions, it's difficult to visualize it. However, the first 4 components from PCA reveal much physics about the spectra (see sections 4.1-4.4 in the paper above).
236	I agree with main points of @Upper_Case well put answer. I like to put forth a perspective that emphasizes on "machine learning" side of the question. For a classification task using kNN, logistic regression, kernel SVM, or non-linear neural networks, the main disadvantage that we are concerned about is decrease in model performance, e.g. decrease in AUC score on a validation set. Other disadvantages of skeweness are often investigated when the damage of skeweness on the quality of result is hard to assess.ّ However, in a classification problem, we can train and validate the model once with the original (skewed) and once with the transformed feature, and then If performance declined, we do not transform, If performance improved, we transform. In other words, damage of skeweness can be easily and objectively assessed, therefore, those justifications do not affect our decision, only performance does. If we take a closer look at the justifications for using lets say log transformation, they hold true when some assumptions are made about the final features that a model or test directly work with. A final feature is a function of raw feature; that function can be identity. For example, a model (or test) may assume that a final feature should be normal, or at least symmetric around the mean, or should be linearly additive, etc. Then, we, with the knowledge (or a speculation) that a raw feature is left-skewed, may perform log transformation to align the final feature with the imposed assumption. An important intricacy here is that we do not, and cannot change the distribution of any raw feature, we are merely creating a final feature (as a function of raw feature) that has a different distribution more aligned with the imposed assumptions. For a classification task using kNN, logistic regression, kernel SVM, or non-linear neural networks, there is no normality, or symmetric assumption for distribution of final features, thus there is no force from these models in this regard. Although, we can trace a shadow of "linear addition" assumption in logistic regression model, i.e. $$P(y=1|\boldsymbol{x})=\frac{1}{1+e^{-(w_1x_1+..+w_dx_d)}}$$ and in neural networks for weighted sum of features in the first layer, i.e.$$y_i=f\left(\boldsymbol{W}_{i,.}\boldsymbol{x}+b\right)=f\left(W_{i,1}x_1+W_{i,2}x_2+...+b\right)$$I say "a shadow" because the target variable is not directly the linear addition of final features, the addition goes through one or more non-linear transformations which could make these models more robust to the violation of this assumption. On the other hand, the linear addition assumption does not exist in kNN, or kernelSVM, as they work with sample-sample distances rather than feature interactions. But again, these justifications come second compared to the result of model evaluation, if performance suffers we do not transform.
237	I would not concern yourself too much about any structuring of knowledge that declares that one subject is categorised as one thing or another. These structures are often wrong and knowledge in general is more fluid and difficult to define than can be viewed as some kind of Venn diagram. In addition, both Data Science and AI are poorly defined, and have more in common with marketing terms used to recruit staff and sell products than stricter academic subject areas such as Maths or Modern Languages. You will find Data Scientists working on "AI" projects and "AI Engineers" using basic statistics to analyse data. Having said that, I would prefer to say that Data Science and AI share a common set of tools, especially when it comes to machine learning. Neither contains the other in my opinion.
238	Natural rights encompasses human rights. Humans are, after all, a component of nature. I would add the diagram, but couldn't do it now, as I am having problems attaching the pictures. To get back to the topic, natural rights encompasses human rights. You could consider natural right as a universal set, and human rights as its subset. Hope this answer helps.
239	I would suggest that religion is an application of philosophy to a given faith or history. And science itself is at root the religion that arises from a faith in naturalism. We do not disown theologies in philosophy, within their own cultural constraints they are valid philosophy. And all of our very early philosophies were very much associated directly to given quasi-religious notions. We consider Platonism a philosophy, but beefed up just a little into Neo-Platonism, it is a religion. Was some specific addition between these two somehow the straw that broke the camel's back? No, Platonism is already a sort of personal religion. It just arose out of a single man's head, rather than a cultural tradition. And it is oddly compelling in a way that makes it easy to clip some corners and render it "consistent enough" with many other religions to make it worth keeping around. Everything that happens does so in some historical tradition, with some basic set of ultimately un-analyzed assumptions. So in essence systematic philosophy is, as a whole, a collection of ad hoc theologies. The constraints that separate where one or the other theology applies do not involve the whole religion, just its central principles or the observed 'facts' of its interpreted history. All the rest of any given religion is a collection of theologies, or involves more basic philosophy like logic, ethical analysis and ontological exploration applied within the frame of some theology of the religion. Even the raw experience of the religion in mysticism or personal investment is really an aesthetic engagement attached to a theology that shapes its details. The amalgam of all Hindu theology is Hinduism. The amalgam of all Christian theology is Christianity. The basic facts cannot be analyzed philosophically, and make up the 'core faith' of the religion, which sets it apart from other religions. But even the process of analyzing and isolating that core is a philosophical endeavor. Not all Christians or Hindus take the same axiomatic base to their overall religion, and not all of those with disjoint core notions would exclude others from the 'big tent' of Christianity or Hinduism. So theologies can be tied together in complex ways and they can overlap or include large parts of one another. Science is something that we seem to be able to share across most religions. But that is because all religions have to enclose a philosophy consistent with some contact with natural reality. If the religion just consistently disowns reality (like raw Buddhism), it can get along, but variants of it will arise that do not do so, and those who stick to the anti-realist standards will unconsciously adopt one of those variants to get through life, even while considering it ultimately incorrect. But at root, there is no reason to have faith in our experience of nature. We just do, because we are animals and animals are natural beings. So the philosophical explorations that arise from that root faith are not in essence different that those of a 'real' religion. They are just much more likely to be consistent with some pocket in each other faith.
240	The distinctions can be made in virtue of how much dogma and empirical evidence are involved, but philosophers have pointed out that the lines of demarcation are rather blurry, like the distinction between bald and not bald. Philosophy involves very little dogma and very little empirical evidence; it is the art of rational conjecture. Philosophers seldom agree with each other because common premises are few and far between. In the realm of opinions freedom should be absolute because the opinion doomed by one philosopher may be perfectly acceptable by another philosopher. Bertrand Russell preferred a quarrelsome atmosphere in philosophy and refused to play the authoritative role at the height of his career; he was generous to his attackers and lavished compliments to anyone who demonstrated some understanding of his philosophy. Science relies heavily on empirical evidence. Nevertheless philosophers have pointed out that there are hidden faiths in scientific knowledge; the empiricist creed that all knowledge is derived from sense-experience is itself a dogma. Because of these all-agreed-upon common criteria, scientific methods are widely accepted in scientific community, and peer review is a reliable procedure to ensure the quality of scientific work. Hidden faiths in empirical knowledge do not license other groundless faiths; empiricism too is not immune to doubt - this is what faith implies. Both philosophy and science are highly tentative, subject to revision based on new evidence. Religious pillars are dogmas. Paradoxically and by the same standard, scepticism can also be called a religion. The dogma that is fundamental to scepticism is this: It is undesirable to believe a proposition when there is no ground whatever for supposing it true. (Russell. On the Value of Scepticism) Bertrand Russell was the kind of philosopher who sifted through systems of beliefs and pointed out what were implicitly assumed a priori, then went on to reduce the number of postulates to bare minimum. This pattern of thinking recurred in his Critical Exposition of Philosophy of Leibniz, his mathematical philosophy and his theory of knowledge.
241	Science is a systematic method of increasing knowledge involving testable hypotheses and replicable methods. Philosophy is sometimes known as the "mother of sciences," it considers questions outside the reach of currently accepted reliable scientific methods. Not all philosophies do involve the rational exploration of truth, which would better be described as a philosophical approach, rather than the philosophical approach. Philosophies can be highly ordered and elaborated, but they are not generally verifiable in an objective fashion (this does not mean they are worthless or wrong). Successful philosophical consideration of a realm of inquiry can produce a science (for example, physics, astronomy, logic, psychology), which is why the founding figures of various sciences were often considered philosophers in their day. Religion is a set of rituals, practices, structures and beliefs, typically connected with a theology, which is a philosophy about God (although there are some non-theistic religions). If theology was a science, religion would be a technology.
242	The argument is a straightforward line of if-then statements. (1) If A then B; if B then C; if C then D; if D then E. (2) A is true. (3) Thus E must be true. If these animals are kept alive, then they have received large quantities of drugs. If these animals have received large quantities of drugs, then those drugs will remain in the animals’ flesh. If the drugs remain in the animals’ flesh, then humans will consume the drugs when eating the flesh. If the humans consume the drugs, then the humans will injure their health. Thus: the conditions under which many food animals are raised are unhealthy for humans.
243	When you use Chrome's Options > Manage Certificates > Import where are you placing the certificate? On the "Certificate Store" screen of the import, choose "Place all certificates in the following store" and browse for "Trusted Root Certification Authorities." Restart Chrome.
244	My vote goes to TrueImage, one of the rare commercial software that I use. Works great, has tons of options and it not that expensive (~50USD). Version 2010 has a nice new feature, Try&Decide, that takes a snapshot of your entire drive that you can revert to later (I use it for testing new software). On the Linux side I use rsnapshot. I guess you could expose your Windows drives over SMB, and then use rsnapshot on them too.
245	You can manually set a directory where you put aliases to your apps, just like Windows start menu. Put that directory to your Dock, and that's all!
246	YES. A micro-atx motherboard will work fine with an ATX case and power supply. Atx cases normaly included the standoff mounts for smaller mirco-atx motherboards. In fact, I have a micro-ATX motherboard in a full size ATX case and power supply. MicroATX was intended to be backward compatible. http://en.wikipedia.org/wiki/MicroATX microATX was explicitly designed to be backward-compatible with ATX. The mounting points of microATX motherboards are a subset of those used on full-size ATX boards, and the I/O panel is identical. Thus, microATX motherboards can be used in full-size ATX cases. Furthermore, most microATX motherboards generally use the same power connectors as ATX motherboards,[6] thus permitting the use of full-size ATX power supplies with microATX boards. microATX boards often use the same chipsets (northbridges and southbridges) as full-size ATX boards, allowing them to use many of the same components. However, since microATX cases are typically much smaller than ATX cases, they usually have fewer expansion slots.
247	This topic has been discussed many times on StackOverflow: The biggest issue with TightVNC and Windows <-> Mac is cutting and pasting Have a look here: What is the best client from Windows to Mac for VNC? iPhone development on Windows
248	HP isn't really any harder to upgrade than any other brands - you said you have already done the graphics and memory... It doesn't matter where you buy from, the CPU is always hard to upgrade! Quite frankly, as your machine is getting a bit older, you will not be able to upgrade to a very high end CPU simply because it probably isn't compatible, and for the ones that are, you probably will not notice that much of a speed increase. If I was you, I would look on eBay for whatever the highest CPU is that your board can take and if it is cheap, get it - otherwise, save your money up for a new computer. I have a bunch of four to five year old machines here, I can buy a brand new Celeron system now that is 64 bit and dual core that would outperform them in every way... and the depressing thing is, they would only cost about £150 to build! When you look at it like this, Just because it is possible doesn't mean it is economical or worth it.... If I was able to upgrade for £5-£20, it may be worth considering, but I wouldn't want to spend anything serious.
249	It depends. If you want to run Windows as the operating system, the answer is practically "no". Unless you really want to mess around with custom patches and hacks windows will not boot from usb, the reson being, IIRC, that it reloads the usb drivers/subsystem during the boot process. Some other operating systems (for example certain linux distributions) work fine though.
250	In general: no. It is up to each application to remember its own layout. (Some applications could provide some kind of mechanisms -- as console mode shortcuts do -- to specify position, but that is unusual.)
251	To get the Internet connection working on the Virtual Machine: Click VM from menu bar Click Setting Click Network Adapter In Network Connection choose Custom:Specific virtual network and then choose VMnet0 (auto bridging)
252	In the Export tab for your database, there's a checkbox on the lower right that says Data. Uncheck it and you should only have the bare structure in your export file.
253	Tar and GZip are 2 independent things. GZip can only compress one file and Tar can join a lot of files and folders in one file. So, you need to ugzip your tar, update tar and finally gzip it. In your case it's better to use ZIP or 7-Zip. Look at this link, 7-zip can easily compress all you like this way Or, you can use tar -u, but it will take more time to ungzip and gzip it again.
254	I hacked the nvidia-settings source, and got a working solution: This is done in Ubuntu, but porting it shouldn't be hard. Run these commands: sudo apt-get build-dep nvidia-settings apt-get source nvidia-settings cd nvidia-settings-195.36.08/src Edit "nvidia-settings.c", and replace main() with this: int main(int argc, char **argv) { ConfigProperties conf; ParsedAttribute *p; CtrlHandles *h; char * target; /* initialize the parsed attribute list */ p = nv_parsed_attribute_init(); /* initialize the ConfigProperties */ init_config_properties(&conf); /* allocate the CtrlHandles for this X screen */ h = nv_alloc_ctrl_handles(":0.0"); if (!h || !h->dpy) { return 1; } /* Get target from command line */ if(argc != 2){ printf("Usage: %s PRIMARY_DISPLAY\n", argv[0]); printf("Example: %s DFP-1\n"); return 1; } target = argv[1]; int i; for (i = 0; i < h->targets[X_SCREEN_TARGET].n; i++) { if (h->targets[X_SCREEN_TARGET].t[i].h) { printf("Setting primary display: %s\n", target); NvCtrlSetStringAttribute(h->targets[X_SCREEN_TARGET].t[i].h, NV_CTRL_STRING_TWINVIEW_XINERAMA_INFO_ORDER, target, NULL); break; } } return 0; } /* main() */ compile: cd .. make put the binary in path: sudo cp nvidia-settings /usr/local/bin/setPrimaryDisplay use it: setPrimaryDisplay DFP-1 gnome-panel --replace 2>/dev/null & Where DFP-1 is the name of the desired diaplay display. Gnome panel doesn't keep up with the times, and needs to be restarted. You can download my binary compiled for amd64 here: http://while1.no/files/setPrimaryDisplay
255	If you've got a bit of budget one of the simplest solutions is a remote controlled power supply. Something like these products from Dataprobe. They are extremely useful and pretty easy to setup. Most computers now days have an option in the BIOS to boot as soon as there is power, so this offers a very simple solution to your problem.
256	Use the HP program for flash disks located at: http://www.softpedia.com/get/System/Hard-Disk-Utils/HP-USB-Disk-Storage-Format-Tool.shtml If you can't find it there, google for "hp usb disk storage format tool". It is the HP format utility for flash disks, but works on any brand of flash stick. It automatically, as part of the format process, removes partitions.
257	Found a solution here Run the following: cmd /c "echo off | clip" You can even make it into a desktop shortcut if the problem keeps happening.
258	Unless your laptop comes with nVidia's Optimus technology, it cannot be enabled for reasons mentioned here Sony's name is absent in the list of featured laptops. It is also mentioned here that the CW series do not have switchable graphics, so seems like there's no way to do it.
259	Have you tried opening Terminal and typing: locate mysql
260	The installation layout is similar to that of a tar file binary distribution; all MySQL binaries are located in the directory /usr/local/mysql/bin. The MySQL socket file is created as /tmp/mysql.sock by default. See Section 2.7, “Installation Layouts”. From: http://dev.mysql.com/doc/refman/5.0/en/macosx-installation.html It's probably not added to your $PATH, thus why the commands aren't visible in the terminal. Try typing echo $PATH on your terminal to see if /usr/local/mysql/bin is included in the path. Additionally, on the terminal, you can type which mysql. If that returns nothing your environment is not finding your MySQL binary.
261	Googlebar Lite for Firefox includes such a feature. You can put multiple strings in the search field, click highligt and then see all matches.
262	Just answering a part of your questions: I cannot give you a way to determine for all addons. But generally speaking, if an addon has a special version for Windows, and another for Mac, and yet another for Linux (or specifies to work only for Windows OR Linux OR Mac), this indicates a binary addon in 99% of the cases. Of course this doesn't say all others are non-binary addons. And no, IMHO you don't mis-interprete what "default addon compatibility" means -- or I do so as well. As I understand it, it means that non-binary addons should no longer be marked incompatible when upgrading to a newer version of Firefox (even though their "maxver" might state so), and thus should not be deactivated by the update. And my experience is I am right with this (at least concerning my latest couple of FF-updates).
263	They are different things - The Command Prompt is Not MS-DOS - but as far as the user is concerned they could be the same thing as they do the same things. So it depends on your point of view. From a technical point of view your friend it correct, but from a user perspective you are correct (sort of as there are differences that an expert would spot).
264	This was true once, but it isn't anymore. From MS-DOS # Windows command-line interface - Wikipedia: All versions of Microsoft Windows have had an MS-DOS like command-line interface (CLI). This could run many DOS and variously Win32, OS/2 1.x and Posix command line utilities in the same command-line session, allowing piping between commands. The user interface, and the icon up to Windows 2000, followed the native MS-DOS interface. Consumer Windows (up to 3.11, Win9x, WinME) ran as a Graphical User Interface (GUI) running on top of MS-DOS. With Windows 95, 98, and ME the MS-DOS part was integrated, treating both operating systems as a complete package. The command line accessed the DOS command line (usually command.com), through a Windows module (winoldap.mod). A new line of Windows, (Windows NT), boot through a kernel whose sole purpose is to load Windows. One can not run Win32 applications in the loader system in the manner that OS/2, UNIX or Consumer Windows can launch character mode sessions. So no, in every Windows from the NT family (e.g., XP, Vista, 7, 8), the command prompt and MS-DOS are visually similar, but quite different.
265	From what I understand, MS-DOS is the disk operating system that Microsoft released. The command prompt is a non-graphical interface that allows you to interact with your operating system. Command Prompt is a command line interpreter application available in most Windows operating systems, officially called the Windows Command Processor but sometimes called the command shell. Command Prompt is a Windows program that emulates many of the command line abilities available in MS-DOS but it is not actually MS-DOS. Command Prompt is a GUI version of command.com in MS-DOS. cmd.exe is a native Windows application usually running in a Win32 console. This allows it to take advantage of features available to native programs on the platform that are otherwise unavailable to DOS programs. For example, since cmd.exe is a native text-mode application on OS/2, it can use real pipes in command pipelines, allowing both sides of the pipeline to run concurrently. As a result, it is possible to redirect the standard error in cmd.exe, unlike COMMAND.COM. (COMMAND.COM uses temporary files, and runs the two sides serially, one after the other.) In reality, cmd.exe is a Windows program that acts as a DOS-like command line interpreter. It is generally compatible, but provides extensions which address some of the limitations of COMMAND.COM (above explanations are referred by Wikipedia).
266	Your friend is right. MS-DOS is/was an Operating System (Microsoft Disk Operating System is what the acronym stands for.) The UI for DOS is called a (the) command prompt. The first few versions of Windows ran on top of DOS (making them technically operating environments, though I'm not sure anybody makes that distinction anymore), but later OSes, starting with the NT Kernel, didn't - DOS was gone. However, people still needed the functionality provided by the command prompt, and instead of command.com we got command.exe (and these days cmd.exe), which when run gives us a command prompt. But, that's not the only (nor anywhere near the first) command prompt that people have used. Command Prompts are also called Shells, and Unix has many, and the commands are different and often very powerful. Speaking of Power, Microsoft has created a new command prompt for Windows called PowerShell which is incredibly powerful and interesting. See Wikipedia for more: http://en.wikipedia.org/wiki/Command-line_interface#Operating_System_Command-Line_Interfaces
267	No. (Unless your definition of equality does not extend past »It is a text interface and I can run programs from it.«) What is run when you click Command Prompt in the Start Menu is the Windows Command Processor, a.k.a. cmd.exe. Its built-in commands and scripting syntax (including many quirks) are based on the ancient command.com from CP/M and later MS-DOS, but apart from that they are completely separate things. Also, command.com is a 16-bit program while cmd.exe is a native Windows console application. Things were different in Windows 95, 98 and ME where command.com would be run in a MS-DOS VM with Windows acting as the hypervisor (yes, they had that sort of thing at the time already). There you had an entire virtual machine running DOS. But on Windows NT, 2000, XP, Vista and 7 – no. DOS only lives on there in ntvdm.exe which is the NT Virtual DOS Machine which is just a thin emulation layer capturing calls that the CPU cannot execute directly (which is why it works faster but worse than DOSBox). In any case, even command.com was just a shell for DOS. It wasn't the operating system. Inside, I actually cringe each time I see people referring to a window with gray-on-black text as MS-DOS. In the vast majority of cases they don't actually know what they're referring to.
268	Iv'e found that this always fixes it: chown Username:Users ~/.ssh/config chmod go-rw ~/.ssh/config
269	This is a guess that you likely won't be able to confirm, given that you're now re-installing, but.... My guess is that you installed in BIOS mode on a GPT disk. I'm not familiar with recent Intel motherboards, but as of a couple of years ago, Intel boards with that configuration required that the EFI protective partition in the MBR (the type-0xEE partition that spans the whole disk) be marked as bootable in order to enable BIOS-mode booting from GPT disks. Alternatively, you could have gotten it to work by creating an EFI System Partition (ESP), installing an EFI-mode boot loader, and booting in EFI mode.
270	This has been fixed in the latest (mobility 13.4) stable driver. It appears that they have actively tried to tackle this problem (after reading specific reports about it probably) since the issue appeared to manifest itself in the slightest event of trying to manipulate the related lid mechanism or monitor/display drivers, even when trying to normally upgrade or downgrade the driver. Now, it can even upgrade the driver without a crash leading me to believe they probably actively tackled it with the installation process before and after installation of the new version. PS. There is a small probability that it coincided with a related Windows update but I doubt it.
271	The file that contains the bash history is "~/.bash_history", fittingly enough(at least in ubuntu, might be different in other flavors). just open it with your favorite text editor, note that each user should have their own .bash_history file. Also note that the preceding "." means that it is a hidden file, so it will not show up in a file browser or with the ls command unless you use it with -a.
272	The only way I know from what you say, is to use "Application Compatibility Toolkit" http://www.microsoft.com/downloads/details.aspx?FamilyId=24DA89E9-B581-47B0-B45E-492DD6DA2971&displaylang=en And how to use it: https://web.archive.org/web/1/http://blogs.techrepublic%2ecom%2ecom/window-on-windows/?p=635 Source: Can you turn off UAC for a single app?
273	You can use vbscript to rename Set fso = CreateObject("Scripting.FileSystemObject") set oFldr = fso.getfolder("C:\file\path") for each ofile in oFldr.Files splited = Split(ofile.Name, ".", -1, 1) ofile.name = splited(0) & "." & splited(2) & "." & splited(1) Next This script will split your file name via the . and then re-arrange it to swap the 2nd and 3rd extensions
274	With the newer phpmyadmin versions, in the export tab for your database or table click on custom. Under Format-specific options click dump table -> structure
275	I too found the same problem with a new W7 laptop, but have a solution. The answer it to make sure you have your Control Panel window set to VIEW BY: CATEGORY As much as you may hate this setting, it's worth the pain to avoid the Windows bug. In fact, with this setting not only does the 'focus lost after first keystroke' problem go away, but you will also find the search box is given initial focus when you first open the control panel window. Very important for keyboard addicts!
276	The solution was embarrassingly simple. Somehow the power cable to the DVD had become loose. Fixing that (and then resetting the BIOS by removing and replacing the CMOS battery) enabled me to boot and complete the Windows 7 installation.
277	I found a post on another website that stated the SMK Nano Dongle Bluetooth 4.0 LE +EDR available from Amazon worked just fine on a 2012 R2 server. So I gave it a try and it worked. I was able to pair an Apple Magic Mouse and Apple wireless keyboard to my Win 2012R2 server with no issues. I did need to reboot in order to see the Bluetooth icon in the lower left tray. All I had to do was right click on the Bluetooth icon and select add a device from the context menu and select keyboard/mouse. When you pair the keyboard, be sure to hit the Enter key on the Apple keyboard after you have entered the pairing key. The following 2 tips worked for Windows 7 but not for Win Server 2012 2k: One tip for getting Ctl+Alt+Del to work on the Apple wireless keyboard as Option(Alt) + Ctl + Fn(delete) is to download the bootcamp (just google bootcamp) install files. No need to try and install them all. Just extract them to a folder and install the driver for the keyboard. Path to keyboard driver install file = BootCamp5.1.5621\BootCamp\Drivers\Apple\AppleKeyboardInstaller64.exe. This will enable you to perform the traditional 3 finger salute to access the login screen. Also, to add all the magic mouse functions, you will need to install the mouse driver from the bootcamp download folder. Path = BootCamp5.1.5621\BootCamp\Drivers\Apple\AppleWirelessMouse64.exe. For Windows Server 2012 R2 the best I can do to get Ctl + Alt + Del to work is to click on the accessibility icon in the low right of the Legacy Desktop and select the on screen key board From there I can get the logon screen and enter my password with my Apple Key board. Still, I do like using the Apple Keyboard and Magic Mouse.
278	Add the following to the config: UseDNS no This will cause the SSH server to not resolve login attempts via DNS.
279	I ended up having to uninstall IIS Url Rewrite Module 2.0, then reinstalling. After the reinstall everything worked. I did not need to use the link in the question to reinstall.
280	When you go to setup a WPS WiFi connection the printer should tell you the PIN to use via its LCD. See page 20 of the Brother Network User's Guide; "Using the PIN method of Wi-Fi Protected Setup": Press "Menu". Navigate to and select "Network". Navigate to and select "WLAN". Navigate to and select "WPS w/PIN Code". When "network I/F switched to Wireless" is displayed, press "OK". The LCD will show an 8 digit PIN and the machine will begin to start searching for a WLAN access point/router for up to 5 minutes.
281	Select your database or table. Select the Export tab. Below Export method, select Custom. Below Tables, check the appropriate Structure boxes. Here's a screenshot:
282	Chromebook and Chromebox are notebook and desktop that run Google’s Chrome OS. Notebooks (known as Chromebooks) and Desktops(Chromeboxes), for more comparison click here
283	A Chromebook is a traditional notebook PC, also known as a laptop. The display screen, keyboard, and touch-pad are all built into the device that folds shut with a hinge. A Chromebox is square, thick, and compact, and it contains a CPU and an SSD like a Chromebook but has no display screen, keyboard, or touch-pad. Instead, the user must add these separately as peripherals using the USB and HDMI ports on the sides of the device. A Chromebase is a very large desktop display monitor that has a has a Chromebox built seamlessly into it and that comes with the keyboard and mouse.
284	MTTF is just that... Mean Time To Failure. One will die in a week, another will last 20 years, most will last roughly the claimed MTTF. You never know which you'll get. The only people who publish real-world results are Backblaze, who blog their test results a couple of times a year, based on their own backup server analysis. https://www.backblaze.com/blog/?s=hard+drive+stats will find some of the recent ones. Historically, [I've been watching their posts for a few years now], some WD drives have had incredible fail-rates, prompting me to never dream of buying one ever again.
285	It really depends on what exact HDD is inside that case. Generally, WD drives are very reliable and usually when I have returns for them is due to physical damage (transport accidents). However, if the drive inside is a WD green, of course it is statistically more likely to fail compared to a WD red or black. You should stick with the current model, since no model of that size is know to have excessive failures, but you should find out the exact drives inside the cases.
286	Instead of editing the User Rights Assignment on your workstations, consider using a Group Policy Preference (GPP) setting to modify the membership of the Remote Desktop Users group. By default, anyone that is a member of this group will be granted permission to establish a RDC connection to the machine. Edit the membership of the Remote Desktop Users group with a Group Policy Preference (GPP) setting as follows: Create a new Security Group such as My Remote Desktop Users. Members of this group will be granted permission to make Remote Desktop connections. Edit a Group Policy Object and navigate to Computer Configuration/Preferences/Control Panel Settings Right-click Local Users and Groups and choose New > Local Group Set Action: to Update In the Group name: drop-down choose Remote Desktop Users (built-in) Click Add... In the Local Group Member dialog box click the ... box and find your group (don't type it in manually) Confirm Action: is set to Add to this group Click OK two times then close the Group Policy editor. Apply the Group Policy object to computers to which you want users to be able to access. The advantage of this method is that you can easily grant/revoke Remote Desktop permissions by modifying a user's membership in the My Remote Desktop Users group, instead of having to edit Group Policy to set a new User Rights Assignment policy then wait for it to propagate to your workstations. Further, edits to the User Rights Assignment policy are not cumulative. In other words, if you have two Group Policies that modify that policy, only one will have an effect. On the other hand, multiple GPPs can be specified to modify the membership of the Remote Desktop Users group.
287	Right-click items in your start menu, and select properties. You will find the path to the executables.
288	Michal Politowski's comment is exactly correct. I use this method to automatically restart services when new artifacts are deployed. It is very helpful. To be clear, you need: srv.service [Unit] Description=srv 0.1: Service's description After=network.target [Service] Type=simple WorkingDirectory=/opt/srv ExecStart=/opt/srv/bin/srv User=root Group=root [Install] WantedBy=multi-user.target srv-watcher.service [Unit] Description=srv restarter After=network.target [Service] Type=oneshot ExecStart=/usr/bin/systemctl restart srv.service [Install] WantedBy=multi-user.target srv-watcher.path [Path] PathModified=/opt/srv/lib [Install] WantedBy=multi-user.target
289	Is a way to open and access the cropped version of the image or other information in the .AAE file? .aae files are only used by iOS and OS X 10.10+. They can be viewed by a text editor to see what edits were made to the photo, but won't allow you to access the modified photo in Windows. An AAE file contains edits made to an image using the Photos app on an iOS device. It is used to transfer non-destructive edits a user has made to .JPG images in iOS to the macOS system. AAE files can be found accompanying the images for which they contain edits. More Information AAE files are used by iOS 8 and later and OS X 10.10 and later. If you import pictures from an iOS device to Windows, the JPEG images will only get transferred and not the AAE files, which will cause you to lose your edits. Also, AAE files can be deleted without erasing your pictures but any edits made to them will be removed. The AAE file is referenced by the Photos app when opening the JPG file in which it is associated. It can also be opened by text editors such as TextEdit and Notepad to view the edits made to the corresponding photo. Source .AAE File Extension So how can I access the modified photo on Windows? Use any other photo editing app on your iOS device. Open the app and import the photo in it, and then save it again without making any changes. The only thing you need to be careful of here is that the app you use doesn’t add a watermark and that it doesn’t compress the photo, or crop it. You’re obviously going to want a free app in this case so we recommend Snapseed by Google or Darkroom by Adobe. Both let you save a copy of a photo without having to make single change to it. Once you’ve saved a copy, simply connect your phone to your PC/Mac and copy it from the device’s storage like you would any other photo. Source How To Import A Photo Edited On Your iPhone To Your Computer
290	i have checked WD 4TB Mypassport, it uses WD Blue and on arrival there was a small noise moving it around, makes me scared as hell :( i have other drivers which i have lugged around quite a bit ... 4TB WD Mypassport (uses WD Blue) using it for last 2 days only so lets see 2TB Transcend Jetdrive (Uses a WD Blue 2TB) using it for last 2 yrs 1TB Seagate backup plus 1TB usin git for last 4 years and Samsung 1TB spinpoint (mfg by Seagate) using for last 4 yrs also so both brands have worked fine for me this is my first 4tb external HDD so im scared and worried as hell ... 4Tb n higher have more failure rate ...
291	I have a userscript that does exactly this. It detects attributes on img tags that likely contain the real image url and changes the src attribute to that. I wrote it so sites with lazy loading images can be used without running their javascript. // ==UserScript== // @name fix-lazy-load-images // @version 2 // @grant none // @exclude /^https?://(?:(?:[^\W_]|-)+\.)?washingtonpost\.com(/.*|$)/ // ==/UserScript== // example site: https://www.howtogeek.com/167533/the-ultimate-guide-to-changing-your-dns-server/ function doit(){ var lazy_image_keywords = ['data', 'pagespeed', 'lazy', 'src']; var fix_lazy_load_element = function(element, src_attribute, keywords) { var last_valid = ""; for (var attribute of element.attributes) { var number_of_keywords = 0; for (var keyword of keywords) { if (attribute.name.includes(keyword) ){ number_of_keywords += 1; if (number_of_keywords >= 2) {break}; } } if (number_of_keywords >= 2) { last_valid = attribute; } } if (last_valid !== "") { element.setAttribute(src_attribute, last_valid.value); } } for (var element of document.querySelectorAll('img')) { fix_lazy_load_element(element, "src", lazy_image_keywords); } // now fix all the <source> tags in <picture> tag... for (var picture_element of document.querySelectorAll('picture')) { for (var source_element of picture_element.querySelectorAll("source")) { fix_lazy_load_element(source_element, "srcset", lazy_image_keywords); } } } if(document.readyState === "loading"){ window.addEventListener('load', doit); } else { doit(); } Greasemonkey or similar is required of course. I don't believe there's a way to do this without such an addon. The Washington Post is the only site I've encountered so far where this causes issues. As such, it is excluded.
292	They're not the same! Apparently lots of people don't realise that the DOS Prompt, and the Windows Command Prompt are not the same thing. They're actually two different programs - COMMAND.COM and CMD.EXE respectively. Know Your Command Prompts Firstly due to differences in the platform (DOS vs Windows) and interpreter (command.com vs cmd.exe), there will be obvious dissimilarities like DOS runs in fullscreen without a windowed mode, so no mode con:cols=COL lines=ROW command to resize the console, and no title command DOS doesn't support multitasking, multiuser, registry, permissions, long file names, symlinks/hardlinks, network, Unicode, dynamic disks and advanced volumes support... so no tools to manage those But there are also major differences in the capabilities and syntax of internal commands between command.com and cmd.exe, as well as some external tools in the two environments. In MS-DOS there are No functions, code blocks () and local scopes which mean for, if... must be followed by a single command on the same line no exit /b or goto :eof no setlocal and endlocal goto can only jump to a label, call can only start another batch file commands can't be grouped together like ( command1 command2 ) >output.txt No escape character ^. Printing special characters would be a pain, and no possibility of running multiline commands No special formats of if no if cmdextversion and if defined no numeric and case-insensitive string comparison if [/i] string1 compare-op string2 No command history and command argument completion No indirect expansion (e.g. call set %%var%suffix%=string) of variables and no delayed expansion (e.g. echo !var%suffix%!) No advanced string manipulation no ~xxxV variable support no substring %variable:~num1,num2% or string replacement support %variable:str=newstr% No partial variable name matching for set, and no set /a so you can't do arithmetic no set /p which means reading user input is a pain no set "var=value" syntax No %* for the whole command line No for /d, for /r or for /l. No for /f so reading input from files is also difficult. The only form of for in DOS is FOR %variable IN (set) DO command [command-parameters] No findstr, and find doesn't support Unicode No special environment variables like %CD% %DATE% %TIME% %RANDOM% %ERRORLEVEL% %CMDEXTVERSION% %CMDCMDLINE% %HIGHESTNUMANODENUMBER% Limited directory changing ability No pushd/popd No cd /d. Also no cd path with spaces and cd "path with spaces" due to the lack of long file name support No color No forfiles No assoc (because there are no GUI and files must be opened manually from command line, so no file association is needed) A lot of useful external commands in Windows like where, sort, more (in some DOS versions), choice... are also missing in DOS And this is what MS' Rich Turner said Also, Cmd != MS-DOS! I also want to point out a common misconception perpetuated by articles like the ones above: Cmd <> MS-DOS! In FACT: Microsoft last shipped a "new" version of MS-DOS (v8.0 in Windows ME), on September 16th, 2000 - 16 years ago (as of this writing)!! MS-DOS was an operating system (albeit a relatively simple OS by today's standards) whose primary user-interface was a command-line shell, until Windows 3.x & 9.x arrived and ran on/around MS-DOS MS-DOS' command-line shell's scripting language was relatively terse and moderately powerful, but lacked many of the richer, and more advanced features we enjoy in modern-day PowerShell, Bash, etc. While later versions of MS-DOS grew in sophistication and added/replaced some older assembly with new code written in 'C', much of MS-DOS remained written in x86 assembly for efficiency, and because it was the only way at the time to gain access to many hardware devices and peripherals. This made MS-DOS non-portable to non-x86 CPU's. If you're so inclined, you can actually download the source code for MS-DOS v1.1 and v2.0 to see just how much of the earlier versions of MS-DOS were written in x86 assembly (hint: pretty much all of it)! https://devblogs.microsoft.com/commandline/rumors-of-cmds-death-have-been-greatly-exaggerated/ Further reading Limitations of MS-DOS 6.22 Commands and Their Availability From MS-DOS 6.22 through Windows 8 New (and Removed) Commands in Windows 8 How do modern .bat files differ from old MS DOS .bat files? Windows batch files: .bat vs .cmd? cmd.exe: comparison with MS-DOS Prompt A command line interface is not a "DOS prompt" In conclusion, functionality-wise they may be a little bit similar, but otherwise hugely different
293	I was having this problem, but I realised windows has saved the edits! If you have a photo with an accompanying aae file, windows/apple is somehow making a copy of that photo. For example, if you have an apple photo IMG_2602 with IMG_2602.aae, another jpeg copy will be saved with IMG_e2602 and this image contains the edits. So we can go ahead and delete these aae files and it doesn’t have an issue with the img_exxxx copy
294	None of these solutions seemed to work for us. What we ended up doing is opening control panel > opening user accounts > Manage User Accounts > Click the add button if your user is not there. We did this on the device we were trying to remote to and added the devices user. Worked like a charm.
295	Oles, This method works well to deploy user permissions to a local / client machine from a Windows Server. This is especially powerful if you are trying to control the users and / or computers that can have RDP rights across a large organization. You just need to set up an appropriate Organization Unit structure in your Active Directory, and then apply this GPO as desired. The way you have suggested works, but it's difficult to manage many computers and many users this way, particularly if you are not on-site to do so. Also note, when you are using the Windows Remote Desktop connection to be sure to use the proper login credentials. At first, I was not including the domain name in the username field, which was causing the RDP connection to be rejected with the "The connection was denied because the user account is not authorized" that started this conversation. When using RDP to connect to a DOMAIN computer... Username: DOMAINNAME\USERNAME Password: ********** After I started using the domain name, this method works perfectly on Windows Server 2019 / Windows 10 clients.
296	"I use multiple Gmail accounts" Your proposed solution actually isn't the best way of solving this problem. Signing in and out repeatedly is inefficient. Even if the default Gmail account could somehow be prevented from switching to the last signed in account, it still creates additional steps and a frustrating workflow. Instead, use an add-on called Firefox Multi-Account Containers to allow you to open all of your Gmail accounts in Firefox simultaneously. Install the add-on Choose "Forget this account" for all accounts other than your main one, to remove cookies for the other accounts from your main Firefox session. Then leave your main account signed in. You no longer need to sign out in order to open a different Gmail account For each additional Gmail account, open a Multi-Account Container tab and only sign in to one Gmail account per container. This way, you will always be signed in to your main Gmail account and defaults won't come into it. Your regular, non-container tab session in Firefox will only be used by your primary Gmail account, and each additional Gmail account will then only be used inside its own dedicated container tab. The main Firefox session and each container you create will have completely separate cookies. To open a new container, simply perform a long-press left click on the new tab button, before choosing your desired account container from the dropdown menu: In the example above, no container exists for me.1@gmail.com as it is not necessary: the main session is always isolated from each container tab. It's effectively a container in its own right. This is a more elegant solution than using a Private Browsing window or Google Chrome Beta because: it allows unlimited additional accounts to be opened at the same time (not just one extra one) the cookies aren't cleared when you close and reopen Firefox, so you won't need to keep signing in. Each container behaves like an entirely separate Firefox installation as far as cookies are concerned. Private Browsing mode purges everything when you close the window you can view the other accounts in tabs in the same window, instead of having to switch to an entirely different window, as is the case with both Private Browsing mode and Google Chrome Beta
297	Yes, in network app performance terminology, "response time" is usually either time to the first byte of the response headers, or maybe time to the first byte of the response payload. It's usually not the complete time for the whole transfer.
298	You can change this in the registry through the following: Find the folder name of the OneDrive synced folder in HKCU\Software\Microsoft\Windows\CurrentVersion\Explorer\Desktop\NameSpace\{018D5C66-4533-4307-9B53-224DE2ED1FE6} Now navigate to HKCR\CLSID\{018D5C66-4533-4307-9B53-224DE2ED1FE6} and change the (Default) string entry with the name of your choice. This change would immediately be visible.
299	How about this: mklink /J your_desired_name "OneDrive - Company Name LLC"
300	This is a hacky, but the only working solution: First, close OneDrive: Click the icon in the taskbar, select More... then Close OneDrive Next open Registry Explorer: Press Win + R, then type regedit and hit enter. Press Ctrl + F to search for all occurrences of OneDrive - <Company> and replace these with the new desired name. For all files in C:\Users\<user>\AppData\Local\Microsoft\OneDrive (i.e., enter %AppData%\..\Local\Microsoft\OneDrive in the address bar) and subfolders, replace all occurrences of OneDrive - <Company> with the new desired name. Rename your original OneDrive - <Company> folder to the new desired name. Reopen OneDrive. OneDrive might realize that the folder name has been change and will ask to set up the OneDrive folder again. Do not do this or else your work will be reverted! Consider voting for the Rename-OneDrive-Root-Folder feature on UserVoice: https://onedrive.uservoice.com/forums/913522-onedrive-on-windows/suggestions/37945567-allow-users-to-change-the-onedrive-folder-director https://onedrive.uservoice.com/forums/913522-onedrive-on-windows/suggestions/8729746-allow-onedrive-for-business-folder-to-be-renamed
301	There are some good answers here, and here is a thorough one that includes the whole process and procedure in addition to what is missing. Process Close OneDrive (step 1 below) Rename OneDrive folder (step 2 below) (optional) Move the OneDrive folder to the desired location (step 3 below) Modify the relevant registry keys (steps 4-5 below) Modify the configuration file (steps 6-8 below) Procedure Close OneDrive. Rename the OneDrive folder. (optional) Move the OneDrive folder to the desired location. Open the registry (start menu >> search "regedit") Modify the OneDrive folder or path in the following locations: (or follow @xoxox advice and search for "OneDrive - (company name)" In HKEY_CURRENT_USER (HKCU) (4 locations) HKCU\Software\Microsoft\OneDrive\Accounts\Business1\UserFolder HKCU\Software\Microsoft\OneDrive\Accounts\Business1\ScopeIdToMountPointPathCache\(ID)HKCU\Software\Microsoft\OneDrive\Accounts\Business1\Tenants\(name)\(path)HKCU\Software\SyncEngines\Providers\OneDrive\(ID)\MountPoint In HKEY_LOCAL_MACHINE (HKLM) (2 locations) HKLM\SOFTWARE\Microsoft\Security Center\Provider\CBP\(ID)\NAMESPACEHKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\SyncRootManager\OneDrive!(ID)\UserSyncRoots\(SID) Open the following location: %UserProfile%\AppData\Local\Microsoft\OneDrive\settings\Business1 Locate the (ID).ini file (usually it's the 2nd file) and edit it (right click >> edit) Locate the OneDrive path in the first line (in the value of the libraryScope parameter) and modify it to be as the new path. Then save the file. Open OneDrive. Notes In step 4 above, we're modifying either the OneDrive folder name or its whole path, depends on the case - where you see only OneDrive - (company name) - it's only the OneDrive name, and where you see the whole path (C:\Users\(username)\OneDrive) - it's the whole path. In step 4 above, some parameters are quoted (e.g. (name), (ID), (path)) - that means that these parameters are interchangeable, and there should be some value that is probably unique to your case. Reference Changing your onedrive name in file explorer navigation How can I change default name of OneDrive for Business folder? OneDrive UserVote (try to vote and maybe Microsoft will consider to change it in the future) Allow OneDrive for Business folder to be renamedAllow renaming root folder (OneDrive folder)Make it possible to change the tenant name in Office365
302	CAUTION: This will work only if you place the cursor at the beginning of the first line that contains TARGET_LINE Ctrl+H Find what: (?:^(TARGET_LINE),\h*|\G)((?:(?!LAST_LINE).)*?)\R Replace with: $1$2, UNCHECK Wrap around CHECK Regular expression UNCHECK . matches newline Replace all Explanation: (?: # non capture group ^ # beginning of line (TARGET_LINE) # group 1 ,\h* # a comma followed by 0 or more horizontal spaces | # OR \G # restart fro mlast match position ) # end group ( # group 2 (?: # non capture group (?!LAST_LINE) # negative lookahead, make sure we haven't "LAST_LINE" after . # any character but newline )*? # end group, may appear 0 or more times, not greedy ) # end group \R # any kind of linebreak (i.e. \r, \n, \r\n) Replacement: $1 # content of group 1 $2 # content of group 2 , # a comma followed by a space Screenshot (before): Screenshot (after):
303	Check if this macro works for you. One negative consequence of it is if you wanted two spaces between sentences it would eliminate them. However, if your documents normally use only one space between sentences, then the macro should work fine for you. Sub elimBlankSpaces() Dim rng As Word.Range Set rng = ActiveDocument.Content With rng.Find .ClearFormatting .Replacement.ClearFormatting .Text = " {2,}" 'look for 2 or more .Replacement.Text = "" 'replace with none .Forward = True .Wrap = Word.WdFindWrap.wdFindStop .Format = False .MatchWildcards = True End With rng.Find.Execute Replace:=Word.WdReplace.wdReplaceAll rng.Find.ClearFormatting rng.Find.Replacement.ClearFormatting End Sub
304	I think the best way to get a "feeling" of what are your requirements, in this case in terms of memory is to get some samples of an MCU, program it and see how many memory is being used. In fact, it will depend on the compiler used. If it's your first time programming a MCU, don't bother too much with specifications. Just select one with lots of memory, lots of peripherals, etc. That way you can learn a lot from just one MCU. When you make your first project with that MCU you will have a better notion of memory you need for further projects. The most appropriate MCU for a task? How many ADC channels do you need? What about DAC? What is more important in your application: performance or low power? Is that kind of questions you have to answer when selecting a specific MCU.
305	An LED acts like a diode, and in the forward bias (when the voltage is applied in the correct direction), the diode will have a small voltage drop. The voltage drop for LED can be found in Wikipedia. Notice that diode does not behave like a resistor (does not obey Ohm's law): once a diode is in forward bias, its voltage drop will remain fairly constant for a large range of currents. That is, until the diode melts or overheats due to overcurrent. Other electrical elements may also melt. If your voltage source is much larger than 0.7V, this will lead to a very large electrical current flowing, and the heat caused by the electrical current will be dissipated along various places in the circuit (because the remaining voltage drop will have to be distributed along the rest of the circuit, which consists of mostly good conductors and therefore has a very low resistance). To prevent this from happening, please connect a resistor in series with the LED, or use a voltage source that is about the same as the LED's voltage drop.
306	This is a misquotation! The Selfish Gene was not written in 1989. It was written in 1976! What Richard Dawkins published in 1989 was the second edition of the book. Indeed, this second edition includes endnotes where he updated the data about transistors: "...my remarks about [computers] have become [...] dated. [...] The number of transistor-equivalents that you could pack into a skull today must be up in the billions.". Dawkins made his homework before writing about transistors, you didn't make yours before quoting him...
307	Scopes are pretty hard to blow up unless possibly you are working with circuitry directly connected to the power line (not thru a transformer or other isolated power supply). Ordinarly scope probes are usually switchable between x1 and x10. What is being multiplied is the impedance, not the voltage as you might think at first glance. The voltage is multiplied by the inverse. A x1 probe therefore has the impedance on the label (usually around 1 MΩ and 10-20 pF) and passes the voltage directly. A x10 probe has 10 times the impedance and attenuates the measured voltage by 10 before passing it to the scope. Therefore if you're not sure what voltage the circuit is, start by putting all the probes on the x10 setting and choose a high voltage scale. Since digital scopes can do math, nowadays you tell the scope (or fancy ones can sense for themselves) what setting your probe is and it automatically adjusts the voltage scale accordingly. For example, the 5 V/div setting for a x1 probe automatically becomes 50 V/div and is displayed that way when using a x10 probe. Otherwise there is little you can do to hurt a scope. Getting a useful display for various conditions is something else to learn. When I don't know much about the signal or am just using the scope more like a voltmeter because it's already on and sitting on my bench, I usually keep it at x1 probe, 1 V/div vertical, 1 ms/div horizontal, auto trigger, with the vertical offset adjusted so ground is one or two divisions from the bottom.
308	You probably cannot initialize the variable with other variables, so unsigned char display [4] = {1,2,3,3} would be OK, but the way you wrote it isn't. In that case just do like this: unsigned char display [4]; display[0]=j; display[1]=k; display[2]=l; display[3]=m; it's not working error : 32_8_MAIN.C(99): error C141: syntax error near 'unsigned' 32_8_MAIN.C(99): error C202: 'x': undefined identifier 32_8_MAIN.C(102): error C202: 'z': undefined identifier 32_8_MAIN.C(104): error C202: 'x': undefined identifier 32_8_MAIN.C(106): error C202: 'y': undefined identifier 32_8_MAIN.C(108): error C202: 'a': undefined identifier 32_8_MAIN.C(109): error C202: 'a': undefined identifier 32_8_MAIN.C(112): error C202: 'a': undefined identifier 32_8_MAIN.C(113): error C202: 'a': undefined identifier 32_8_MAIN.C(119): error C202: 'z': undefined identifier 32_8_MAIN.C(121): error C202: 'x': undefined identifier 32_8_MAIN.C(123): error C202: 'y': undefined identifier 32_8_MAIN.C(125): error C202: 'a': undefined identifier 32_8_MAIN.C(126): error C202: 'a': undefined identifier 32_8_MAIN.C(129): error C202: 'a': undefined identifier 32_8_MAIN.C(130): error C202: 'a': undefined identifier Target not created
309	The solid/dashed lines on wires like the ones pictured in your question are used to indicate polarity e.g. for the "wall wart" power supplies. Usually* the wire with the white stripe or the dashed lines carries the "positive" (+) end, while the other, unmarked wire carries the "negative" (-) end. It doesn't matter if it is striped or dashed, the presence of any kind of marker is the indicator of the wire being the "positive" end of things, as opposed to the unmarked "negative" wire. This kind of convention is used on speaker cables as well, where the wire that is marked in some manner (e.g. text providing wire information, a stripe, etc.) is the positive end, and the unmarked wire is the negative end. *I say "usually" since I've seen a wall wart with the wires were reversed, although every other wall wart I've used does it the way I've described above. The only way to be sure is to use a voltmeter and measure the voltage across the two wires. If you get a negative voltage reading, you know you have the test leads swapped.
310	How do you determine how many sensors a microcontroller can use That's would depend on how creative you can be and how many iopins you have available, and how many pins the sensor requires. If you have 4 3pin sensors, that doesn't necessarily mean you need 12 pins to control them, you can multiplex them and use 5 pins and save 7 io pins. So it all really depends. But one way of looking at it is, how many available io pins do you have, and how many pins do your sensors requires, that would give you a low limit on how many you can have. Creativity, experience, and understanding of how everything works, can increase the number of sensors. My understand is you cant embed C# directly on any microcontroller but you can use C# and communicate over the USB and look for a specific port is this true? While I haven't done much USB, I do know that if you are doing USB from scratch, that would involve writing drivers on your host machine. The more popular way is to use an IC that already handles all the USB protocol and the drivers and it behaves like a serial port on your computer. You basically have a USB-Serial bridge which can tie into a serial port on your microcontroller. I believe the Arduino does this. Not sure about Netduino. So yes you can use C# to communicate over USB THROUGH a specific port (assuming you are doing it the easy way and using a USB-Serial bridge). What you propose to do is definitely possible. You can write a program that interfaces to your database and that can send and receive serial data to your microcontroller.
311	Took me a while to realize what you mean by "High Pass Filter". When engineers say HPF, they usually refer to frequency domain, therefore HPF in context of your question is confusing. Now, what you want to do is to provide a low impedance path to the ground when the voltage on some USB pin gets below 1.5V, right? I'm sure that there are many ways to do this, but one which is the most obvious for me: simulate this circuit – Schematic created using CircuitLab You will have to find appropriate transistors based on your application (currents, voltages, speed). When \$V_{in} \geq 1.5V\$ the comparator outputs low voltage: NMOS is closed (effectively behaving as an open circuit) PMOS is open (effectively behaving as a short circuit) When \$V_{in} < 1.5V\$ the comparator outputs high voltage: NMOS is open (short circuit). The voltage of \$V_{out}\$ will be pulled to ground. PMOS is closed (open circuit). This will ensure that \$V_{in}\$ itself is not shorted to ground. NOTE: I assumed here some generic comparator which can output both high and low voltages. I can't suggest any specific part without additional info, therefore it's up to you to find an appropriate one. However, as Johnny B Good indicated in his comment, if you want to use an IC comparator (one chip solution), you need to make sure that it can switch rail-to-rail. This is essential because many comparators employ "open collector" output which goes "high impedance" instead of "high voltage" (these can be made a rail-to-rail by adding additional external circuitry). This is not an issue with comparators built around generic op-amps.
312	User1726, your start is not correct. The cut-off frequency of the first order highpass is defined as the frequency where the magnitude of Vout is 3dB less (factor 0.7071) than the MAXIMUM of Vout (which is Vout,max=Vcoll*RL/(RL+Rc). There is a simpler method for finding the cut-off frequency. You have nothing to do than to find the time constant of the circuit (simple visual inspection) which is T=C3*(Rc+RL). The inverse of T is the (angular) frequency for cut-off. And don´t overlook that the capacitive impedance is 1/2*Pi*f*C (and not 1/2*Pi*f)
313	In the guts of Eagle, there is really no difference. The difference is by convention what each layer means and how it is used. The intent of tPlace (and bPlace) is stuff that is directly drawn in the silkscreen on the final board. Actually which layers contribute to the ultimate silkscreen graphics is a function of how you set up the cam processor job to generate the silkscreen gerber file. Usually tName, tValue, and tPlace will contribute to the top silkscreen output, but you're not forced to use that convention. The intent of tDocu is what the name says: documentation. This is generally not written to the silkcreen, but may appear in board drawings and the like. Again, it's your choice how to use these layers, but using them as intended makes things easier. You could write tDocu to the silkscreen Gerber file, and use tPlace only for board drawings, but that would just invite confusion and errors. tPlace usually comes from two places. It is used to show the outline and other fixed geometric characteristics of parts in the package definition of parts. It can also come from explicit things drawn in the board editor. For example, you might write the product name, date, etc, in a blank area of the board.
314	I put on tDocu what I want to be visible when I put a copy of the PCB in a document. For instance, sometimes I have no room for the component designations and/or values on the PCB, so I put them outside the PCB, with an arrow or line to the component, all on the tDocu layer. I obviously don't want that info on the silkscreen, but I do want it in the documentation.
315	Usually, you put just tPlace and tNames into the silk screen, as they give you the outlines and names of components. tValues can be used for easier soldering by hand / documentation, but mostly is not used because of space restrictions. tDocu is usually not used for the silk screen. It could contain dimensions for a workshop which should build a case for you, or instructions for assembly like "do not mount this part". You may put it into the schematic, but the board manufacturer usually does not want to read your schematic, just the board.
316	You almost got it right. You just need to add R3 (120 ohm) back, so that you will have the carrier "on" continuously (all the time). You should be able to remove R2 (15k) without causing a noticeable effect.
317	There is a subtle bug in the eeprom.h file. The calculation of the PAGE1_BASE_ADDRESS is based on 1Kb value page rather than using the define which is supposed to accommodate different page sizes in the MCU's. Change the define #define PAGE1_BASE_ADDRESS ((uint32_t)(EEPROM_START_ADDRESS + 0x0400)) to: #define PAGE1_BASE_ADDRESS ((uint32_t)(EEPROM_START_ADDRESS + PAGE_SIZE))
318	Look closer... There is only a single pair of pull-up resistors for each bus. Your diagram shows four separate I2C buses. The multiplexer and the repeater isolates the segments. Thus, since you only have one bus, you only need two resistors: One for SCL and one for SDA.
319	You are right. If you wear gloves, they should be sufficiently conductive so that their surface does not retain a charge, which gets discharged through you to your connection to ground. The purpose of all ESD precautions is to get everything at the same potential. It doesn't have to be 'ground', but that is the most convenient level to choose. So insulators have no part in this, they allow potential differences to exist. Conductivity is what's needed. If you need to use a glove, to protect components from skin oils and salts, then wear plain cotton. The cellulose fibre they are made from retains some level of moisture (there's no magic to being 'natural') which renders them slightly conductive, sufficiently so for ESD protection purposes. Conductive gloves will not work for ESD protection by themselves. They need to be used as part of a full system that includes getting you, your worktop, your tools and all components at ground potential, and keeping them there. Wriststrap, conductive benchtop, both connected through safety resistors to a common ground are needed. Tools and conductive bags and tubes get grounded when placed on the bench or handled by you. While it's true that adding extra resistance in series with you will reduce the level of current that flows from a charged you into a device, it's not the right way to do it. The right way is to avoid you being charged in the first place. Think of insulating gloves as seat belts / airbags, and not being charged in the first place as driving so you don't crash into things. My heart sinks at work when a colleague approaches me, holding a circuit board that's intended for me, that's not in a conductive bag. Often they are gingerly holding it by some insulating part, apparently knowing there is an issue, but not knowing what to do about it. I make a point of touching them first to minimise the ESD problem they have caused, male or female, intern or CEO. Get at the same electrical potential, then pass the sensitive item. If it was insulated from them, then I find a large ground feature on the board, connector shells for instance, and take it by that, so that any current flows to a robust rather than sensitive part of the item. This error happens because people do not understand the number 1 goal of ESD protection, everybody and everything stay at the same potential. People peddling insulation, or denying that charge accumulates on an insulated person, do not help. Unfortunately, ESD unsafe practices are just that, unsafe, they do not guarantee failure. In fact, most people employing unsafe practices will get away with it all the time, and all people will get away with it some of the time. This means that failures are rare, and difficult to identify with specific times when they occurred. In industry, we need all the people to be working safely all of the time, which is why there are working practices which can at times seem a little draconian.
320	Less expensive speaker wire, often called zip-cord, indicates polarity with a raised ridge on the outside edge of one of the conductors rather than striping. You frequently find that convention on wall-wart wiring, too. Twisted pair used in network cables and some phone wiring indicates pairs and polarity with a similar scheme. Each pair has a different base color, such as blue, green, or orange. The polarity is indicated by having one wire a solid color and the other with a white stripe on a background of the same color.
321	Aside from the theoretical and worst-case chip specs mentioned elsewhere, there's also a possible source of error in the voltage drops across copper traces. Grounds are not equipotential at mV level with currents in the mA level or higher flowing through typical 1oz copper, so you could be reading that voltage drop. When you measure the voltage going into the chip put the negative lead of your meter directly on the GND pin nearest the Aref pin.
322	Trace at point A carries high di/dt current so it should have low inductance to the decoupling capacitor to minimize voltage spikes. \$ e = L \frac{di}{dt} \$ and in dc-dc converters di/dt is pretty high so you want to minimize L. A few amps switched in a few ns with a few nH inductance = VIN drops a lot when it switches. I've had a case where this trace was too long, so when the top FET in the dc-dc turned on, the high di/dt combined with trace inductance created a voltage drop that was large enough to basically crash and reboot the DC-DC chip. So, when output current exceeded a threshold it would hiccup. The fix was to lower the inductance between decoupling cap and dc-dc chip. Trace at point B is constantly switching between GND and VIN, so its parasitic capacitance to the nearest ground/power planes has to be charged and discharged at every switching. So low parasitic capacitance is best, like a short trace. A copper pour on the switching node would be a bad idea, due to wide area and high capacitance to nearest plane. In this case extra trace inductance doesn't matter since the trace is in series with an inductor anyway...
323	You can connect the Rx/Tx lines to something like a 74VHC123AFT (one chip for both lines), and drive the LEDs directly with the output (preferably the /Q output with a series resistor to Vcc). Try a time in the 100ms range. LED current of a couple mA should be sufficient with a good LED. The retriggerable multivibrator will cause the LED to illuminate continuously if the lines toggle at more than 10Hz. Once the activity disappears, the LED goes off.
324	The following seems to say that utility power transformers are nameplated with the no-load voltage ratings. IEEE Std C57.12.01™-2020 -- 5.5.2 Voltage rating -- The voltage rating at no load shall be based on the turns ratio. The transformer terminal voltage is subject to the effect of magnitude of load and load power factor.
325	An upgrade will only install security updates. So the short answer is no. The full answer is, that for 9.04 updates are no longer provided as it has reached the end of its life cycle last October. You should seriously consider updating to a newer release (using sudo do-release-upgrade). Using 10.04 (which is an LTS release) you will get php 5.3.
326	Grub must be installed in the hard drive that the computer boots, regardless of which OS you want to run. That means the hard drive that is set as 1st boot device in BIOS. You BIOS is probably set up to boot your "2nd" hand drive, where Ubuntu might be the boot partition, thus completely skipping grub. So, my hints are: Go to your BIOS. Usually this means pressing DEL or F2, or some other key during boot. The right key depends on which computer / brand / model you have. Usually when the PC starts, there is text like "Press XXX for BIOS settings" At BIOS setup screen, try to find your boot options. WHERE they are located also depends on your computer / brand / model. Make sure you choose your 1st hard drive as your 1st boot device. Save settings and quit. Now, install grub in THAT hard drive (usually /dev/sda). Like this: grub-install /dev/sda If you cant boot ubuntu after switching the hard drive boot order, change back to previous settings (so you can boot Ubuntu back). Now your 1st hard drive (the one that has XP partition) might be /dev/sbd. Just use the above command replacing sda for sdb. Now go back to BIOS and change boot order again If you need, i can give you more detailed instructions. Give me your computer (or motherboard) brand and model so i can guide you for BIOS keys and menus. Also, please post the contents of: gedit /boot/grub/grub.cfg sudo fdisk -l sudo blkid Hope that helps! UPDATE: From all the files you posted, I have 2 theories: 1 - grub-install warning suggests me that is actully NOT being installed. Read HERE for a great explanation about FlexNet and Grub. FlexNet looks like a licence manager, anty-piracy protection that writes data in the very MBR space grub uses for its multi-booting code. So you probably have some FlexNet-dependent software in your XP, and Grub refuses to overwrite it, thus refusing to install itself. The same link has info on how to fix that. Without grub installed on MBR, your HD is booting the traditional way: the partition flagged as bootable in your 1st HD. That means Ubuntu (check fdisk's /dev/sda1 marked as boot partition) 2 - Also, your grub.cfg dow NOT show windows XP, as if os-prober didnt find it. (take a look at your ### BEGIN /etc/grub.d/30_os-prober ### section. It should be something like this (just an example): ### BEGIN /etc/grub.d/30_os-prober ### menuentry "Microsoft Windows XP Professional (on /dev/sdb1)" { savedefault insmod part_msdos insmod ntfs set root='(hd1,msdos1)' search --no-floppy --fs-uuid --set 485083315dc8e22a drivemap -s (hd1) ${root} chainloader +1 } ### END /etc/grub.d/30_os-prober ### Instead, yours have no menuentry. Somehow grub did not "find" your XP parition when scanned your drives, or didnt think it was a valid OS. Thus, as grub menu would have no OS other than Ubuntu, it automatically skips the menu and boots straight into your 1st (and only, acoording to him) OS. You could force grub to show the menu by holding SHIFT key right after the POST. But, again, it would only have Ubuntu (and memtest, and previous kernel, and recovery mode), but not XP. So, either grub is not installed (it resuses to do so when it finds FlexNet and silently aborts), or it is installed, but since it has only Ubuntu, it bypasses the menu. Or both. Any would make Ubuntu to boot. Now lets check and fix both theories: 1 Is grub actually installed on /dev/sda? Keep SHIFT pressed on boot, and menu will show up instead of being bypassed. If it doesnt show up, grub is not actually installed. Do so by removing FlexNet code from MBR (the same link above have instructions on how) . Then install grub and check if there is no warning. Remember that wiping FlexNet from MBR will make its dependent software fail to work 2 Is your XP install a valid one? Can it boot without grub, in a single-OS enviroment? Somehow grub's OS Prober didnt think so. Lets test it then: In Ubuntu, use gParted to mark its partition as BOOT (right-click partition -> Flags -> check BOOT) Also, try to mount your XP partiton (double-click on it in Nautilus) and check if its OK. Take a look at its boot.ini file. Should be something like: [boot loader] timeout=30 default=multi(0)disk(0)rdisk(0)partition(1)\WINDOWS [operating systems] multi(0)disk(0)rdisk(0)partition(1)\WINDOWS="Microsoft Windows XP Professional" /noexecute=optin /fastdetect /usepmtimer Disconnect the Ubuntu HD. Leave only the XP one. Set BIOS to boot it. Try to see if XP works (it prolly wont yet, but who knows?) Using any Windows bootable CD / USB / Floppy, use windows (NOT linux!) fdisk /mbr to wipe grub of it. Do not fear, grub is only needed in /dev/sda, your 1st hard drive, and since this will be back to /dev/sdb when this is over, grub is not needed on that HD. Try now. It should work. Nope? Then use a XP boot CD to repair that install. If that is your only connected HD and XP is the sole OS, partition marked as boot, with a cleaned-up MBR and repaired install, it must boot, or else later grub wont be able to help you much... It works? Cool! Connect the other (Ubuntu) HD back, set it up as before (as boot HD in BIOS), launch Ubuntu and run grub-install /dev/sda again. OS prober should detect XP now, and with 2 OSes in its list, menu will show up at boot. Wow, that was a long answer. You have quite a lot of homework to do . I hope it all works. Good luck!
327	Me too had the problem, i am from India. So by default india servers selected. I changed it simply by going to "System" menu and on submenu "Administration" selected "Software sources". Their changing india server to "main" server not helped me. So clicked the "other" option in "Download from" and then clicked on "select best server" button, which inturn tested 350 servers and selected the best reachable servers. After that no errors, all my update went so nicely and speedy too. try the same.
328	See the output of pgrep -fl X, it should be similar to 1284 /usr/bin/Xorg :0 -br -verbose -audit 0 -novtswitch -auth /var/run/gdm3/auth-for-Debian-gdm-aoiVzl/database -nolisten tcp vt7 You see :0 is my DISPLAY, you should have two lines, the second with :1, so try DISPLAY=:1 or DISPLAY=:1.0
329	With some help of a guy on ubuntuforums.org I fixed this issue. I had to reinstall the network manager. sudo apt-get install --reinstall network-manager However due to the fact I had no internet on my OS I started up with ubuntu from USB where internet still worked and then downloaded the package from. http://packages.ubuntu.com/precise/net/network-manager The whole topic can be found at: http://ubuntuforums.org/showthread.php?t=2054615
330	Link to the thread that fixed this problem Ubuntu Forums: I dragged and dropped this version skype-wrapper from this location /usr/share/application/ onto the Launcher.
331	I made a little research and now I can come with the answer that is not so simple as it seems at first sight. I searched a lot on Google, and almost everything is pointing to the ~/.cache/chromium/Default folder. It’s the folder where you should find google chrome’s cache files. But there are no big flash video files (like YouTube has), just small ones. In the end, to answer the question, I came to these conclusions: First, you have to open an YouTube video and let it stream from internet. In a Terminal (Ctrl+Alt+T), you should get PID of Chromium that use Flash Player plugin. You can use various commands, but ps will do just fine: ps ax | grep flash. Once you have this PID you can find out the name of video file that just was streamed on Youtube: ls -l /proc/[*PID*]/fd | grep Flash. You will see as result something like this: lrwx------ 1 [*user*] [*user*] 64 mai 2 09:48 [*video file name - is a number*] -> /tmp/FlashXX4PeKRY (deleted)` And here is the answer of the question: the last video file streamed on YouTube and cached on the system is: /proc/[*PID*]/fd/[*video file name - is a number*] Now, if you want, you should copy them anywhere on the system: cp /proc/[*PID*]/fd/[*video file name - is a number*] ~/Videos/[*new video file name*].flv And now you have the last video watched on Youtube in your personal Videos collection.
332	I wrote a small bash script that automates the excellent solution from Radu: #!/bin/bash pidNum=$(ps ax | grep flash | grep chromium | grep -v "grep" | sed -e 's/^ *//g' -e 's/ *$//g' | tr -s " " | cut -d " " -f 1) procNum=$(ls -l /proc/${pidNum}/fd | grep Flash | tr -s " " | cut -d " " -f 9) filename=$1 if [[ "$filename" == "" ]]; then filename=$procNum fi echo "Copying /proc/${pidNum}/fd/${procNum} to '${filename}.flv'" cp /proc/${pidNum}/fd/${procNum} "${filename}.flv" ls -lah "${filename}.flv"
333	You must to use the X Logical Font Description (XLFD) full name for the font provided by xfontsel. For example, you can use something like this : -bitstream-*-*-*-*-*-12-*-*-*-*-*-*-*: dmenu_run -b -fn -bitstream-*-*-*-*-*-12-*-*-*-*-*-*-* xfontsell tool allows you to preview the different settings. If you want to use a syntax like: dmenu_run -b -fn <family>-<size>:<name>=<value> which is closer to what you asked, you can use Xft support patch. See here the instructions about how to use a patch for dmenu.
334	I do it manually like this: define this alias in /etc/bash.bashrc alias findflash='find /proc/ -maxdepth 1 -type d -exec lsfd.sh {} \;' and create this script in /usr/local/bin/lsfd.sh #!/bin/bash ls -l $1/fd/ 2>/dev/null 3>/dev/null| grep -i 'flash' 1>/dev/null 2>/dev/null 3>/dev/null; if [ $? -eq "0" ]; then echo $1/fd/; ls -l $1/fd/ | grep -i 'flash'; fi result: root@juanmf-V570:/tmp# findflash /proc/31591/fd/ lrwx------ 1 root root 64 Aug 19 23:59 37 -> /home/juanmf/.config/google-chrome/Default/Pepper Data/Shockwave Flash/.com.google.Chrome.9Oc0fE (deleted) lrwx------ 1 root root 64 Aug 19 23:59 38 -> /home/juanmf/.config/google-chrome/Default/Pepper Data/Shockwave Flash/.com.google.Chrome.hcEvxv (deleted) then I know where the files are and use mplayer to see wich one I want. then manually copy.
335	Try the following, as I believe it is related to issues with Intel iGPU drivers which ship with Ubuntu by default, as a number of other Intel users are having this same problem. sudo add-apt-repository -y ppa:oibaf/graphics-drivers; sudo apt-get update; sudo apt-get upgrade -y; sudo apt-get dist-upgrade -y This will add the oibaf PPA, switch the obaif PPA to Raring as it currently doesn't support Saucy yet, then upgrade all of your open source graphics drivers to the latest 'Updated and Optimized' open source graphics drivers.
336	The IPC hardening feature of grsecurity breaks semaphores for lvm... that was the culprit. Deactivating it fixes this problem.
337	There is no need to manage, monitor or clear the Linux cache manually during normal operations, and no performance benefit in doing so. The purpose of the cache is to store recently-accessed data from disk so that subsequent attempts to read it complete more quickly. This is why loading a large document is typically much faster the second time around. However, the memory is still considered "free" by Linux and can be re-used instantaneously if there is a need for more memory (e.g. you load a new program or document), so clearing the cache does not achieve anything. The drop_caches control is there to help developers with benchmarking and testing, not for ordinary users. It is not possible to say what is causing your slow program loading without more information, but it almost certainly has nothing to do with the cache. Poor disk performance or the presence of other disk or CPU-intensive processes are possible culprits.
338	A lot of sound files are found in /usr/share/sounds . Therefore one can use it to change default system sounds(email notification sounds in this case). One has to remember that sound files in the folder are in .ogg format and therefore the sound files that one is going to set up instead of the default system sounds must also be in .ogg format.
339	The URL link below shows you the options you can choose. https://help.ubuntu.com/community/WindowsDualBoot
340	One nice little app I've used to create Launchers for my desktop is Arronax. http://www.florian-diesch.de/software/arronax/ But a quick google search for "teamspeak" and "ubuntu" gave multiple hits about how to install. The following link also brings up a good question is "either" your ubuntu -or- the teamspeak you downloaded 32Bit instead of 64Bit? If your ubuntu is 64 bit but the app is only 32 bit then you need to install the 32-bit compatibility libraries, you should be able to run 32 bit programs normally by adding: sudo apt-get install ia32-libs The folloiwing post also had good info for teamspeak setup: How to install Teamspeak 3 client on ubuntu 12.04 lts 32 bit? it states: 1) cd ~/Downloads (assuming saved in Downloads folder, otherwise where you saved it) 2) chmod u+x ./TeamSpeak3-Client-linux_x86-3.0.12.run OR if 64bit version: chmod u+x ./TeamSpeak3-Client-linux_amd64-3.0.13.1.run ./TeamSpeak3-Client-linux_x86-3.0.12.run OR if 64bit version: ./TeamSpeak3-Client-linux_amd64-3.0.13.1.run 3) Press enter to view the user agreement 4) Press Q to leave the user agreement 5) Type Yes to create the folder (named TeamSpeak3-Client-linux_xxxxxx) 6) Open the folder, Run program called ts3client_linux_x86 or ts3client_linux_amd64
341	I'd use a simple grep to look for user90: $ echo "randomcollege-nt\user90" | grep -o user90 user90 If user90 is not constant, prefer this command: $ echo "randomcollege-nt\user90" | grep -oP '(?<=randomcollege-nt\\)\w+' user90 Finally using sed to edit the file in place: $ sed -ri 's/randomcollege-nt\\(user[0-9]+)/\1/' my_file Or to match all possible user accounts: $ sed -ri 's/randomcollege-nt\\(\w+)/\1/' my_file
342	You can use perlbrew: sudo apt-get install perlbrew Then: perlbrew init perlbrew install perl-5.20.1
343	The Development and Programming section of Ubuntu Forums has a subforum named "Ubuntu Application Development". You could also consider the ubuntu-app-devel mailing list and the #ubuntu-app-devel IRC channel on Freenode (can't post IRC links, so: irc://irc.freenode.net/ubuntu-app-devel). Lastly, if it is development, you can always ask here, or on Stack Overflow.
344	You could use apt-check from update-notifier-common: $ /usr/lib/update-notifier/apt-check --human-readable 0 packages can be updated. 0 updates are security updates. This is the same tool that updates the motd message.
345	MATE DE (Desktop Environment) is a piece of software separate from Ubuntu, originally a fork of the older GNOME 2.x DE. Ubuntu MATE, on the other hand, is (from the official page) "A community developed Ubuntu based operating system that beautifully integrates the MATE desktop." Basically, MATE is the DE - it provides the GUI functionality. Ubuntu MATE, on the other hand, is a derivative of Ubuntu, a sort of "child OS" based off Ubuntu, but with changes to the default software and design, most notably the use of the MATE DE instead of the default Ubuntu DE, Unity. Source: What is Ubuntu MATE? | Ubuntu MATE
346	What is MATE DE? quoting from the MATE Wikipedia article MATE is a desktop environment forked from the now-unmaintained code base of GNOME 2. It is named after the South American plant Yerba mate and tea made from the herb, mate. The use of a new name, instead of GNOME, avoids conflicts with GNOME 3 components. But what is a Desktop Environment? quoting from the Desktop Environment Wikipedia article In computing, a desktop environment (DE) is an implementation of the desktop metaphor made of a bundle of programs running on top of a computer operating system, which share a common graphical user interface (GUI). A desktop environment typically consists of icons, windows, toolbars, folders, wallpapers and desktop widgets. In Linux there are many different DEs. The most well-known are: Unity, GNOME 3, KDE, Cinnamon, XFCE, and LXDE. So what is Ubuntu MATE? quoting from the official Ubuntu MATE site A community developed Ubuntu based operating system that beautifully integrates the MATE desktop. Ubuntu MATE is a stable, easy-to-use operating system with a configurable desktop environment. Ideal for those who want the most out of their desktops, laptops and netbooks and prefer a traditional desktop metaphor. With modest hardware requirements it is suitable for modern workstations and older hardware alike. So what is the difference between Gnome and MATE? MATE is a fork of Gnome 2 and retains features from Gnome 2 such as the file manager, appearance preferences, panel and indicator function(re-branded) and is not interchangeable with GNOME Classic. The forked programs have been renamed, with most names in Spanish. Caja (box) – File manager (from Nautilus) Pluma (quill) – Text editor (from Gedit) Eye of MATE – Image viewer (from Eye of GNOME) Atril (lectern) – Document viewer (from Evince) Engrampa (staple) – Archive manager (from File Roller) MATE Terminal – Terminal emulator (from GNOME Terminal) Marco (frame) – Window manager (from Metacity) Mozo (waiter) – Menu item editor (from Alacarte)
347	In python, entries like: a=(1,2,3,4,5) b=(2,4) are iterables and known as tuples. Your task can be easily done in python: #!/usr/bin/env python2 a = (1, 2, 3, 4, 5) b = (2, 4) c = tuple(i for i in a if i not in b) print c Output : (1, 3, 5) Here we have found the values of the tuple a, that do not exist in tuple b and put them in another tuple c. Also note that this operation will be fast and memory efficient for larger data sets as we have used python generator expression.
348	The OP managed to fix the problem themselves, as posted in the original question: Go to Nvidia X server settings; OpenGL Settings; and uncheck Sync to VBlank. Reboot, this fixed my mouse problem in Draftsight. -tfsron
349	Being brief (a small book could be written on the topic), maybe it is useful to think like this: cp is for duplicating stuff and by default only ensures files have unique full path names rsync is for synchronising stuff and uses the size and timestamp of files to decide if they should be replaced. It has many more options and capabilities than cp Using their various options, you can use either of them for many tasks, for example cp -u can replace only files that are newer, as rsync is used to do. But there are some tasks where one has advantages over the other You might as well use cp when you want to make a local duplicate file or directory. For example, you want to edit an important file, so you make a backup first: cp .bashrc bashrc-bak Making rsync do this would require three more keystrokes, so why bother? If you want to duplicate a directory cp -r ~/Desktop/cakes ~/Recipes/cakes serves you well. Why bother typing rsync -a? Well you might, since its -v verbose option gives more interesting and useful output. However, let's say you're updating a backup of some directory on your system on a flash drive. The directory already exists on the flash drive, and you just want to sync the files so it has the latest version of your stuff. rsync is much faster than cp for this, because it will check file sizes and timestamps to see which ones need to be updated, and you can add more refinements. You can even make it do a checksum instead of the default 'quick check', although this will take longer. You can also use rsync to copy or sync files to a remote machine, or make is run as a daemon. Humble cp can't do such fancy things. To learn the options and syntax ("structure"?) (which is very similar) read man and info pages and practise!
350	Note that sudo isn't necessary. snap find and snap install will work just fine without it. snap find only shows promoted and public snaps in the stable channel. By curating snaps in this way, users can expect a degree of quality when using snap find for app discovery. If you'd like to know all the snaps that exist, try uappexplorer: $ snap install uappexplorer-cli $ uappexplorer-cli --type snap ┌────────────────────┬───────────────────────────┬───────────────┬──────┬──────┐ │ App │ Description │ Type │ ❤ │ ★ │ ├────────────────────┼───────────────────────────┼───────────────┼──────┼──────┤ │ test-snapd-cups-c… │ A basic snap declaring a… │ Snap │ 0 │ 0 │ ├────────────────────┼───────────────────────────┼───────────────┼──────┼──────┤ │ test-snapd-fuse-c… │ A basic snap declaring a… │ Snap │ 0 │ 0 │ ├────────────────────┼───────────────────────────┼───────────────┼──────┼──────┤ │ lcavassa-iperf │ A TCP, UDP, and SCTP net… │ Snap │ 0 │ 0 │ ├────────────────────┼───────────────────────────┼───────────────┼──────┼──────┤ │ deadbeef-vs │ The Ultimate Music Playe… │ Snap │ 0 │ 0 │ ├────────────────────┼───────────────────────────┼───────────────┼──────┼──────┤
351	The WSL RootFs filesystem (that under AppData/Local/lxss that appears as / in WSL) uses extended attributes which Windows doesn't understand to store Linux filesystem data, and so can't process. So if you edit or create files there (say in your 'shared' folder), those files will be invisible to WSL. You need to create your 'shared' folder somewhere under /mnt/c, which uses the WSL DriveFs filesystem and doesn't suffer from this limitation.
352	The easiest option would be to install the default version that available on Ubuntu package list, you can choose either to install Java Dev Kit (JDK) or Java Runtime Environment (JRE): First, update the package index sudo apt-get update To install Java Dev Kit (JDK), run following command: sudo apt-get install default-jdk Above command will install JDK, but if you instead want to install JRE sudo apt-get install default-jre Source: https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-get-on-ubuntu-16-04
353	APT APT only installs softwares using .deb packages, and By default the apt command does not cache the deb files: apt command does not cache the .deb files? Where are packages stored installed with APT in Ubuntu 16.04? It download and install the package and after installation was done it will remove the deb packages. Apt is only used to do package management using dpkg and deb packages, it's a high level tools which make installation of packages easier. To get download link of "eclipse" package: $ apt download eclipse --print-uris |& grep -Po "http.*?deb" http://archive.ubuntu.com/ubuntu/pool/universe/e/eclipse/eclipse_3.8.1-8_all.deb or to download it in current directoey: $ apt download eclipse Tar To install "eclipse" using tar files just extract the archive somewhere and run its executable file. The other situation is when you download a tar archive containing the software source code which depend on the software you should follow some instruction to compile and install it
354	xkill is a utility used for force-quitting GUI apps. It is handy when some app isn't responding or is causing your system to work abnormally. NAME xkill - kill a client by its X resource DESCRIPTION Xkill is a utility for forcing the X server to close connections to clients. This program is very dangerous, but is useful for aborting programs that have displayed undesired windows on a user's screen. If no resource identifier is given with -id, xkill will display a special cursor as a prompt for the user to select a window to be killed. If a pointer button is pressed over a non-root window, the server will close its connection to the client that created the window. To use it quickly you can use Alt+F2 and enter xkill and hit Enter. Alternatively, you can also type the same in Terminal. You can also define a keyboard shortcut in Settings → Devices → Keyboard to use xkill. Your cursor will turn into cross sign and forcefully terminate (finishes the game (what I think) of) the app.
355	I solved this problem by reinstalling openssh-server as follows: sudo apt-get purge openssh-server sudo apt-get install openssh-server
356	You can use tcpdump tool to achieve this. Script: #!/usr/bin/env bash echo "$(date +%x_%H:%M:%S:%N)" > /var/log/info.txt echo " " >> /var/log/koko.txt tcpdump -c 10 -w /tmp/info.pcap -i eno1 tcp && \ tcpdump -r /tmp/info.pcap >> /var/log/info.txt Make script executable with chmod +x sniffer.sh Then add the job to cron: Open cron editor as root: sudo crontab -e Add the line 0 */2 * * * /path/to/sniffer.sh Explanation: echo "$(date +%x_%H:%M:%S:%N)" > /var/log/koko.txt: echo the date into the output file echo " " >> /var/log/koko.txt: separate the date from other conten with a line tcpdump -c 10 -w /tmp/info.pcap -i eno1 tcp &&: Capture 10 packets from interface eno1 (can be lefet out, in which case it will capture from all interfaces) and write to a file and if successful do the next command, tcpdump -r /tmp/info.pcap >> /var/log/koko.txt: read from that file and write to a the info.txt file.
357	You've used UFW to allow the port to listen, but you haven't initiated listening on the port, install netcat if you don't already have it, and try: nc -l 11963
358	I don't know complicated the permissions per user you require but does something like this work for you : https://ubuntuforums.org/showthread.php?t=2453008 In that situation the user created a share of one folder ( /FolderRoot ) with many subfolders with the intent that only some users would have access to each subfolder. He wanted the parent folder and the whole tree to be read/writeable to only one user ( User1 ) for which I suggested this: [FolderRoot] path = /FolderRoot read only = no valid users = User1 force user = UserMaster Then he wanted a subfoler that only User1 and User3 could access. I suggested just creating a different share of that subfolder like this: [Folder2] path = /FolderRoot/Folder2 read only = no valid users = User1, User3 force user = UserMaster You might want to look at the original posters question to see how applicable his use case is to yours.
359	If your file is HTML or XML then you should consider using a tool that is designed for markup languages. However if you must use awk, then AFAIK you can't use variables inside a regexp constant /.../. However you can use what the GNU awk user guide refers to as a dynamic regexp or a computed regexp - basically a string expression that you can use on the RHS of a ~ comparison. So: $ TPNum='"P16"' $ awk -v TPNum="$TPNum" ' $0 ~ "\\<style:style style:name="TPNum{p=1} p{print} /style:style>/{p=0} ' file <style:style style:name="P16" style:family="paragraph" style:parent-style-name="Table_20_Contents"> <style:paragraph-properties fo:text-align="center" style:justify-single-word="false"/> <style:text-properties fo:color="#000000" style:font-name="open sansregular2" fo:font-size="18pt" officeooo:rsid="00050000" officeooo:paragraph-rsid="000040000" style:font-size-asian="18pt" style:font-size-complex="18pt"/> </style:style> The backslash needs to be escaped in the dynamic regex because the string is scanned twice: What difference does it make if the string is scanned twice? The answer has to do with escape sequences, and particularly with backslashes. To get a backslash into a regular expression inside a string, you have to type two backslashes.
360	You can download it from here. It is a "deb" file, which can be installed locally with the "gdebi package manager" Please note that this way is not encouraged, since it is inherently insecure. You do not know what code you are downloading and what is does to your system. Also accept that it might not work, if dependencies are not met. But if you really have to download code like this, look for .deb files, not for .rpm
361	http://www.wikimatrix.org is a great place to start when you are looking for the right wiki. Just reading the list of features available will help you along. You may want to look into foswiki.org. It works fine with Apacheauth (no worrying about the wiki logon being safe), and happily accepts LDAP Auth through Apache. It saves the posts in plain text files and is easily expanded by plugins. The learning curve is nice and flat, although it is a rather powerful software if you wish to delve deeply.
362	The same thing happened to me and I found the cause to be my FTP Client. I use FlashFXP. A spyware on my local machine took the site data from my FlashFXP. It then connected to my website and inserted the code in the default page. Next time when site is opened this malicious tihng is downloaded and also google discards this into black-list. We solved the problem by moving our FTP client to another clean machine and the problem was solved.
363	A Quad Core is a CPU with 4 cores. A Core2Quad is an Intel marketing name for their Core 2 series CPUs with 4 cores.
364	You really need to know the model numbers for the two processors, then you will be able to learn more. There is a good comparison of Intel processors on wikipedia
365	Another thing that I haven't seen mentioned yet is that systems advertised as servers are designed to run 24/7 and tend to have more cooling on the whole system rather than just the main components, leading to better reliability.
366	Xorlev's answer will certainly work. Accepting your client's private key, though, violates everything that PKI is about. You should be sending your public key to the client, who will then place that on the EC2 instance, granting you access. Private keys are meant to be kept, well, private.
367	As long as DNSSEC isn't widely used, the best way to protect against DNS spoofing is to use "source port randomization". This is especially important since the "Kaminsky DNS bug". You need to make sure that both the version of DIG that you use as well as the recursive DNS server that you query have implemented "source port randomization". Theoretically it is still possible to spoof even "source port randomization", but it would take a LONG time and a LOT of network traffic.
368	I would first make sure they they are resolving the IP correctly. If that works, you will want a couple traceroutes from the clients (Or at least their public IPs). You can then give that information to your ISP and they should be able to find out what is wrong. It does sound like it is probably not your server. Maybe just-traceroute will be able to show you where the packet loss is happening or places where there are big jumps in latency.
369	If the VPN is already running on the host, then the NAT VM will also have the same access.
370	Yes it's possible. In fact, they are not related at all. FTP uses TCP port 21, SFTP is actually part of SSH and uses TCP 22.
371	Traditionally there has been very few and expensive boards with more than two sockets for Intel chips, because the FSB architecture didn't support it directly. The only exceptions were very expensive boards with specialized chipsets. AMD-based boards, OTOH, have been not-so-hard to find with 4 or even 8 sockets, because the hypertransport architecture makes it so (comparatively) easy. Current Intel processors have a AMD-like architecture; but still have limited number of inter-processor ports, so you have to be sure what exact chip model you have (and corresponding price points). Add to that the lots of cores you get on each socket, and it's understandable why there are so few many-socket boards there. In fact, it's increasingly rare to find AMD boards with 4 sockets.
372	It's all about the privileges that a Service User Account has. The Local System account is a predefined local account that can start a service and provide the security context for that service. It is a powerful account that has full access to the computer, including the directory service when used for services running on domain controllers. The Local Service account is a special built-in account that has reduced privileges similar to an authenticated local user account. This limited access helps safeguard the computer if an attacker compromises individual services or processes. A service that runs as the Local Service account accesses network resources as a null session; that is, it uses anonymous credentials. The actual name of the account is NT AUTHORITY\LocalService, and it does not have a password that an administrator needs to manage. The Network Service account is a special built-in account that has reduced privileges similar to an authenticated user account. This limited access helps safeguard the computer if an attacker compromises individual services or processes. A service that runs as the Network Service account accesses network resources using the credentials of the computer account in the same manner as a Local System service does. The actual name of the account is NT AUTHORITY\NetworkService, and it does not have a password that an administrator needs to manage. For example, ASP.NET Service runs under NT AUTHORITY\NetworkService user that has not access to File System. Reference
373	System has extensive privileges on your local machine (access registry, etc...), where Network Service has limited privileges on your local machine. However both of them can be used for network account. In your case I think you should use System account. More information about difference you can find Difference between local service account and network service account in windows server with respect to SQL Server 2005 For more detailed difference check: NetworkService and LocalSystem
374	This should do the trick. (Updated for version 7.2.0 A01 released 1/11/2013.)
375	I would say you need to check your firewall rules. Just because port 135 is open does not mean it is open to "Public" subnets. Windows Firewall with Advanced Security allows differentiation between Public, Private, and "Domain" address space rules. I would imagine the defaults are set for only inside your domain subnets and not on "public" network (meaning outside the boundaries of the domain). So if you open up wf.msc you should look all the way at the last column to see it is set for what you need. The definitions are, according to Microsoft: There are three network location types in Windows Firewall with Advanced Security: Domain. Windows automatically identifies networks on which it can authenticate access to the domain controller for the domain to which the computer is joined in this category. No other networks can be placed in this category. Public. Other than domain networks, all networks are initially categorized as public. Networks that represent direct connections to the Internet or are in public places, such as airports and coffee shops should be left public. Private. A network will only be categorized as private if a user or application identifies the network as private. Only networks located behind a NAT device (preferably a hardware firewall) should be identified as private networks. Users will likely want to identify home or small business networks as private. Also, to get a more specific idea regarding WMI firewall exceptions, get familiar with this Microsoft MSDN article. Happy hunting.
376	May be, if there is no open user session, Windows doesn't assign drive letter to usb device? Create a cmd file like this: cd z:\ 2> c:\test.log echo %errorlevel% >> c:\test.log Schedule a task to run this task at time, when there is no open user session. Check c:\test.log
377	Solved! It was a weird one to solve this issue. It turned out that I needed to reset my PRAM. It must have stored some details that needed to change with the upgrade. Apple has a article on how to reset the PRAM. You reboot and hold cmd+opt+p+r until you hear the a 2nd time.
378	I dont know if its just a typo.. but shouldnt it be ..../script.rb >> /home/web/logfile.log for it to propertly append? Your code seems to have a space between the double angle bracket I tried it just now on bash in mac, it prompted an error, perhaps some shells may just ignore the second angle arrow in this case
379	Actually I just experienced twice an instance where when the server goes down the mail was not held and delivered. The situation is using exchange 2003, the internet went down, the router used between the exchange server and the internet was UPNP, the wizard was used to set it up. After the internet was brought back online, less than 12 hrs from the time it went down, the exchange server still could not reach the internet, the user had to run the IECW over again on the server to get things working, none of the emails during the downtime ever reappeared. This seemed to be an isolated incident until it happened again a month later. Same scenario, same server, same router. Not sure if the router is at fault or the server, but have since manually configured the router to hopefully prevent this from happening in the futures. So a backup solution might not be such a bad thing after all.
380	I've never used them because they're a single point of failure, at best. Every server I deploy into a real datacenter has each PSU plugged into a different PDU in the rack, each of which are attached to a different independent UPS, on different circuits, ideally even fed from different power feeds. If the UPS, PDU or circuit your Y-cable's attached to goes down, the redundant PSUs are going to be useless, so it seems like a waste at best, and a false sense of redundancy at worst. EDIT: I'll just mention that I'm talking about lower capacity 1U or 2U UPSes mounted inside the server rack, rather than the much larger, much more expensive UPS units that take a up rack all to themselves. Those are definitely built to be highly redundant in and of themselves, without the need for a secondary unit.
381	The only people allowed to access the folder are: user A: He is the owner members of B: They can read/browse the folder And that's it. The 0 in 750 means that other users won't be allowed to do anything with this folder. What you did was to add user A to the group C, but it doesn't affect the folder at all.
382	Just to send email you do not have to establish MX records for your own domain.
383	No, MX records are not used when sending outbound mail. However, some mail servers may require that the domain of the from address have the necessary DNS records to support incoming mail, in which case you need either an MX or A record on that domain.
384	You are not required to have MX records just to send email. However: you must use a valid, existing and working email domain as sender address in all outgoing traffic (sending mail from something@nonexistentdomain.com is not allowed) any domain used in email traffic can work without MX records if it has a valid A record, but this kind of setup is not much used on the 'net nor really encouraged. If a domain must be able to receive mail, set up valid MX records. any domain used in email traffic (such as the sender address of the previous items) must have a valid and working postmaster@ account, that means the domain must be able to receive mail, that means the domain should have MX records Short story: you don't have to have/manage MX records, but be sure to use a working email address as sender and be sure it is on a working domain with valid MX records.
385	I know this is old, but I think for this one, I would recommened trying out: web.server.protocol=https in the portal-ext.properties.
386	Yes, cron job B will run at 8:05. You can also run more than one long-running job at 8:00 etc. However, the job will not resume after a reboot. If you need something like that rewrite your job with a wrapper that gets scheduled often and that checks if it has something new to do or something else to continue. This will depend on the task you want to do, obviously.
387	Each and Every cron on your system is isolated from each other, but the cron job execution time will solely depends upon the System Resources Allocation and the work for which Cron has been schedule.
388	They are run in parallel. Cron Job B will run at 8:05 am.
389	When you write Host BitBucket, you also have to ssh BitBucket, not the real hostname (but you could put that into the Host line...)
390	We don't have an authenticating proxy but I had a similar problem with update-help. It seems our gateway may be set up not to allow requests from powershell, but does allow requests from IE. In our case running fiddler allowed the request from powershell to get through the gateway\proxy. Not sure how, maybe fiddler changes the user-agent string or something, but might be worth a pop if your network is set up similarly. BTW if anyone from Microsoft is monitoring, please can you at least make the update-help -verbose option report the URLs it is trying to request as this made troubleshooting impossible. I was using fiddler to try to work out what URLs powershell was trying to request.
391	mitmproxy seems to be the right tool to do what you are asking. mitmproxy is an interactive, SSL-capable man-in-the-middle proxy for HTTP with a console interface. mitmdump is the command-line version of mitmproxy. Think tcpdump for HTTP. Features Intercept HTTP requests and responses and modify them on the fly. Save complete HTTP conversations for later replay and analysis. Replay the client-side of an HTTP conversations. Replay HTTP responses of a previously recorded server. Reverse proxy mode to forward traffic to a specified server. Transparent proxy mode on OSX and Linux. Make scripted changes to HTTP traffic using Python. SSL certificates for interception are generated on the fly. The reverse proxy mode would let you capture the request and response just like Fiddler does.
392	There are specific SFTP protocol extensions to calculate file hashes, and such extensions are supported by most clients and servers (it's very common). See this link for full documentation of such extensions: https://tools.ietf.org/html/draft-ietf-secsh-filexfer-extensions-00#section-3 Anyway, given the above, I would recommend to use a SFTP client that supports such extensions and calculate the hash code of your file both on the client and the server (after transfer) and check if they're the same. That's the safest way to accomplish your goal.
393	"Basic scaling" means that an instance is created when a request arrives; billing ends "fifteen minutes after a basic instance has finished processing its last request". The "instance-hours" shown on the bill, dashboards, etc, refer to the B1 instance class, the smallest one; other instance classes are scaled proportionately. For example, if an instance of class B2 (the default) spends 5 minutes starting up and processing a request, then goes idle, those 20 minutes of B2 will show up as 40 minutes (0.66 "instance hours"). Thus, there is nothing impossible in 2 hours of elapsed (wall-clock) time of a basic-scaling module consuming 6 "instance hours" on a single instance -- all it takes is for that instance to have a sufficiently high instance class. There are no instance classes counting as 3 times a B1; but for example instance class B4 counts as 4 times a B1, so it would consume 6 instance hours in 1.5 hours of elapsed-time activity, counting the 15 minutes after it goes idle each time. 6 requests in 2 hours, equally spaced, each processed "instantly" (thus counting only the 15 minutes after it goes idle) by a B4 instance, for example, would show up as "6 instance hours" (6 * 0.25 * 4), i.e, 75% of the 8-hours "free quota" for backend "instance hours". If you show the .yaml file configuring the module, and the pattern of activity (which you can evince from the timestamps in the logs), it is possible to check these hypotheses. Without such extra information, hypotheses are all we can propose!-)
394	You can find somewhat newer syslog-ng packages (that includes the systemd-journal driver) for Debian Jessie in the repository of a syslog-ng developer at https://build.opensuse.org/project/show/home:laszlo_budai:syslog-ng I'm not sure that this will make the field available in syslog-ng (unless it is translated somewhere to _COMM or SYSLOG-IDENTIFIER, see http://support.oneidentity.com/technical-documents/syslog-ng-open-source-edition/administration-guide/source-read-receive-and-collect-log-messages/systemd-journal-collecting-messages-from-the-systemd-journal-system-log-storage ), but if you do need it, open a Gitub issue at https://github.com/balabit/syslog-ng Regards, Robert
395	Update: Look at the download link. It is not official Microsoft website but a website registered to someone in China. The download may even be virus infected and/or cracked Office. STAY AWAY FROM IT!! If you look on ebay, there are too many people selling MS product keys. Most of them will work sometime and give you the impression of having a legit product, but that is not the case. Easiest is to contact Microsoft over chat and ask them about the product key that you received. They will tell you that it is part of some license deal (e.g. educational license with 500 max installation). Once the maximum number of installation is reached, Microsoft will block the key and you will not be able to reinstall your office again. According to EU law, you are responsible to ensure that you are buying a legitimate product. If the software is used, then you need from all former owner a statement that they removed any old installation and are not keeping copies of the software. If the product is licensed for many users, like Office Professional Plus, you need copy of original license agreement and description of which part of the license agreement you are buying. E.g. if a company has a 10-user license and sells you the 10th user license, since they only need 9 user license, that is legal and fine. But it has to be made clear to you, what you are buying (e.g. the 10th user of a legitimate 10-user license with proof of purchase). If you are not in the EU other laws will apply to you. TL;DR So you can use it, it will work for some time, even updates will work but most likely after some time you will not be able to reinstall your office, hence it is most likely a stolen license key.
396	Simple answer: No. You don't need to match Brand or Model, 10GbE is usually not as picky as FC.
397	Each device will need a transceiver that it's happy with, but they don't need to match at opposite ends of the link. (several manufacturers, and Cisco is one, read out the data in the module's EEPROM and refuse to use it if it isn't "approved". This only applies to the module that's physically plugged into the SFP+ cage on the device, though. There is no way for a device to determine who made the SFP+ module on the other end of the link.)
398	Go to Azure Active Directory >> App Registrations >> Select All Apps from the dropdown menu >> find your app and click on it. The service principal will be the application Id and the secret will be the key under settings.
399	As Bruno Faria said, you can find the service principal in Azure Active Directory, Azure Active Directory -> App registrations -> All apps like this: Also you can use az aks list --resource-group <your-resouece-group> to find your service principal: Hope this helps.
400	The output from "az aks list" should contain your service principal clientId.
401	In a production deployment, you would ideally have a management network separate from the network that your virtual machines use. This text refers to setting up such a management network. You can operate Hyper-V without a separate management network, but that traffic will contend with VM traffic.
402	Just want to point out that even though the server header is removed from response, the name of the server (nginx or openresty e.g.) is still clearly visible in the html error response that the server sends in case of an error. Anyone can very easily get this response by e.g. sending a header that is too long. Nginx will return a 400 Bad Request, that does not contain a server header (if fixed), but the html itself will show it: P.S. I don't know how to get rid of this one as well, really the html itself will give it away, so there should be a way perhaps to not generate these at all?
403	The local port is the port number on the local computer, in this case your Windows 2016 server. The remote port is the port number on the remote computer, in this case the client that is connecting to your SQL server. In most protocols (including SQL Server) the client uses a randomly chosen port number, so the remote port setting in the firewall rule needs to be configured to the default setting of "All Ports". The local port number in the firewall rule needs to be whatever port number your SQL Server is listening on, in this case port 1433. (Typically, you would only specify a particular remote port when creating an outbound rule; for example, you would specify remote port 80 if you wanted to create a rule blocking outbound HTTP traffic.)
404	Try with this az aks list --resource-group core-project --query="[0].servicePrincipalProfile.clientId"
405	Facebook does not officially support changing the font on your profile. Some people manage to make it look like this by putting in script characters (Hindi, etc.) that look vaguely similar to English letters, or by combining Unicode characters. But this does have some downsides: A lot of people find it annoying. People searching for your name won't see it, because your name in Facebook's database won't actually be the characters of your name that people would be searching for. I would suggest that you not do this, but if you really want to, you'll have to look for special characters that look like letters.
406	As this Google Analytics Google Groups states "IP Addresses are not tracked by Google Analytics" at all for some reasons mentioned in the post, like "it's not reliable", "it's not scalable" and "it's Evil".
407	Tagging is available only if you upload the video directly to Facebook—if you share the link, the video is fetched from YouTube, not Facebook so you can't tag them. Might I suggest dropping a comment and doing an @Mention?
408	Click "Share" under the video on YouTube then click on the Facebook icon—a little window should come up. In that window, there is a small box that says "Whats on your mind"; in it type @friends name. For example @candice ramkissoon.
409	The accepted answer mentions colours that are not mentioned in the question and only looks back. Also "Date is before" "in the past week" does not highlight dates within seven days of today. I suggest a Conditional formatting Custom formula is of the type: =and(A1>today()-7,A1<today()+7) where six days before today, today and six days after today should all be highlighted.
410	Unfortunately there is no read receipt feature, although it is on their dev backlog according to this Tweet thread. There isn't much you can do outside of asking if they saw it. Some other possibilities: Look at their screen to see if their Slack app is showing the unread message notification. This isn't perfect though. You'll know they read it if the notification isn't there, but they may have also seen it even with the notification showing, due to other unread messages. If they are offline when you message them, wait around to see if they appear online shortly after you send the message. That is a likely indication that they read it. Having said that, it might be possible that a user's account is "sleeping" and the act of receiving the message sets them as online. You can test this with someone that has the Slack app on their phone. Have them login and leave the app alone for some time. Once they no longer appear online, send them a message and see of they come online without having to reopen the app.
411	According to @SlackHQ (the official Slack twitter account), "owners can only see the private channels that they are a member of".
412	From Facebook Help Center: When you delete a friend request, the person who sent you the request won't be notified and can't send you another request for one year. So, she has to wait for one year to send you a friend request. But you can send her friend request. If you are not seeing option to send her friend request then probably she has set the privacy. Ask her to change her privacy settings for adding friends. Instructions are given here: How do I change who can add me as a friend on Facebook? Other than privacy settings, there could be some other reasons also which is mentioned in this Facebook FAQ: Why can't I add someone as a friend on Facebook? If everything looks fine and still you are not able to send her friend request then this block is temporarily and you have to wait for few days or weeks. Facebook sometimes does this kind of blocking for security purpose.
413	=ARRAYFORMULA(TRANSPOSE(SPLIT(TEXTJOIN("♪", 1, QUERY(TRANSPOSE(IF(B2:Z<>"", B2:Z&",", )), "select *", ROWS(B2:B))), "♪", 0)))
414	As of May 2019 Slack's privacy FAQ states that on a free plan, owners can request an export of all data, including private messages and channels. However, they must "provide (a) valid legal process, (b) consent of members, or (c) a requirement or right under applicable laws."
415	There is workaround though. If you have a Slack app that collects tokens from all you users, that app is able to access all private channels. Also see this post: https://stackoverflow.com/questions/37690761/get-a-list-of-all-private-channels-with-slack-api/53142640#53142640
416	The most likely explanation is too much sun too quickly - the chlorophyll content in the leaves is greatest on the upper surface, and its the chlorophyll that absorbs sunlight. Your plant, being exposed to sun suddenly, flipped its leaves to absorb less of it - this is not an unusual event on pepper plants and it shouldn't affect its fruiting. Next time you want to put it outside, introduce it to sun gradually by standing in a dappled shade spot for a day or three, gradually moving it into full sun as it grows.
417	Do not worry about mycelium on and in the soil. If your almond seed was moldy then they just won't germinate. Soil is always full of fungal spores. When the soil gets disturbed, water added, some of those spores will grow. No big deal. If your seeds were moldy they just won't germinate. Nothing more insidious. Germination of almond seeds DO NOT add anything right now! No vinegar, baking soda, my goodness. One actually lowers pH possibly making your soil uninhabitable by any plant and the latter raises the pH. pH is a big deal. One never adds anything to the soil unless they have a soil test and knows soils, chemistry and plants! More than likely the mold, if any on the almonds, is NOT the fungus/mycelium you are seeing in the soil. You can't believe the amount and diversity of fungal spores in garden soil!
418	Well, now I'm going to have to do a slightly different answer to the one you've already got. Yes, there are two types of outdoor composting processes - hot and aerobic, or cold and anaerobic. Hot and aerobic is achieved by regular and frequent turning of the contents, cold and anaerobic is what most people do, you just build the heap and leave it to get on with it. If you have a lot of material regularly that needs composting, it's worth having two heaps, one you've built and another one you're building, adding materials all the time. Hot and aerobic is faster, but more work, obviously. Whichever method you decide on, it's quicker if you chop everything up as small as possible, especially woodier materials. Weeds should not be added to cold anaerobic heaps, although if you strip off the flowerheads or seed heads, you can add the stems and leaves, provided they're not pernicious weeds like bindweed. The heat generated in an aerobic heap kills off most weed seeds, so you can take the risk with that type of heap. An anaerobic heap should not smell - it only smells if you haven't got the C:N ratio right. That means carbon to nitrogen, or, in common parlance, browns to greens, and there's good guidance on that subject here http://www.gardenmyths.com/how-to-compost-browns-greens/ I agree you never add meat, fish, cheese or whole eggs - but you can add eggshells if you like. Cooked kitchen scraps aren't a great addition to a heap, but vegetable peelings and fruit skins are fine.
419	So far as I'm aware, Tithonia varieties are no more sensitive to being transplanted than, say, Aquilegia or other plants that produce a tap root over time. You've got a choice; you either sow them in seed trays, then prick them out and grow them on in small pots, planting out when they're big enough and all risk of frost is past, or, you sow them direct, thinly, and thin them out by removing excess seedlings. You could try transplanting these excess seedlings, but this will likely be less successful than pricking them out into pots from a seed tray. https://www.westcoastseeds.com/how-to-grow-guides/grow-tithonia/
420	I thought they turned the leaves of a night time if it got cold
421	I believe that's an Amaranth - Amaranthus tricolor. Native to Southeastern Asia into Africa, it's a perennial in zones 9b+ and is usually treated as an annual elsewhere. Propagation is via seed. Amanaranths like full sun to part shade and a moderately moist soil. In the garden, Tricolor can grow to 2-4 feet tall and 1-2 feet wide. Leaves and seeds are edible. Here are some photos: http://mlb-s2-p.mlstatic.com/amaranthus-tricolor-sementes-flor-pra-mudas-8174-MLB20000697548_112013-F.jpg https://assets.listia.com/photos/8c30e6f2197d0c4386b8/original.png?s=800x600g&sig=7b320ca9b9525b4f&ts=1454606499
422	Okay, I know this isn't a fun situation at all for you. First, before anything else, have you been to the doctor? I think that you should make sure that there are no developmental issues. If this has been going on for awhile, it is worth considering. The reason I say that is because some children with Autism have this reaction when they become overwhelmed or bored.
423	Absolutely. An Elmer's-style wood glue (polyvinyl acetate (PVA), generically known as carpenter's interior wood glue) is an inexpensive glue which is quite effective for holding balsa wood together. It does not take a lot of wood glue to make a good bond. In fact, too much glue will create a weak joint, so use it sparingly (how to use). If you already have it on hand, wood glue is a perfectly suitable choice. But to be more thorough, when balsa wood is used in applications like model building, joint strength and minimizing weight might become more of an issue. In those cases, cyanoacrylates ("super glues") are often a better choice. Glue accelerators are usually mixed with these products to speed cure time in a product that would otherwise be ill-suited to fill spaces (loosely fitted porous materials). There are also polyurethane glues ("gorilla glues") and epoxies that have different properties based on the project's needs and application. There are actually a lot of glues which work well with balsa wood, so here is a list of adhesives showing their properties, pros and cons, and their recommended application: Polyvinyl acetate (PVA or White School Glue) Aliphatic (Carpenters Glue, Wood Glue) Cyanoacrylate (CA Glue, Super Glue, Krazy Glue, etc.) Epoxy adhesive Polyurethane Adhesives (Gorilla Glue) Contact Cement Model Airplane Cement (Testors) This list provided courtesy of Diary of a Balsa Goddess
424	Wood glues are fine for balsa. While there are stronger glues, the added strength is usually unnecessary and strong enough should be sufficient. It is hard to generalize but "white" glues, like Elmers, are just PVA glues that are advertised as craft or general glues. There are also yellow PVA glues, which Elmers also makes (and the one I generally use for my indoor projects), that are geared more towards wood. However there is many similarities between them and in some cases the yellow is just colour added (FYI white vs. yellow is a large debate.). A common adage among wood workers is that the glue joint is stronger than the wood itself and that is true. Also true is that balsa is one of the weakest hardwoods but it is ideal for a great deal of applications. Go ahead and use either white/yellow glue for this. Some people would even use cyanoacrylate or CA glues, like Super/Crazy glue (as well as some other glues), for their balsa models. What is more important is how you apply the glue. You said that you had a clean break which is great. Whether or not this is the case for you I would recommend not removing splinters from the break. You want to glue joint to be as free of gaps as possible. Remove splinters from the break can introduce weak points where the glue might not get the best adhesion. Make sure when you put the staircase back together that you apply glue on both sides of the break enough to cover the entire surface area. If possible you want to clamp the work, or apply pressure in some way as clamps might be excessive for balsa, to force some of the excess glue out from the joint (you don't need a lot in the joint). Clean the extra that does come out. Let it sit for as long as the glue states on the product label.
425	Well, there's always "the" book on counterpoint. There may be a translation online somewhere; that said, this one is pretty inexpensive, just not online.
426	It really depends on the style of music. If you're playing military or orchestral music, with lots of rolls, you'll probably find a wooden stick rebounds better from the snare drum, making it easier to play. On the other hand, because wood has a grain, wooden tips give you a slightly different sound depending on the rotation of the stick around its long axis. If you're playing rock or jazz music with a lot of cymbal work (whether it's loud or quiet), you'll find it easier to get a consistent sound with nylon tips. Nylon tips last longer if you're playing heavily, especially on cymbals, cowbells, or other hard objects you might use to get special sounds. One more possible consideration is that nylon tips were only invented in the 1950's. If you're playing music that's older than that, you might want to use a wooden stick for authenticity, especially if your audience is close up or you're being videoed.
427	Nylon tips are good sounding on cymbals, therefore you'll want to use it if you do a lot of cymbal sounds. It is also more consistent than of the wooden tips, since wooden tips will sounds bad when it is depreciated. Wooden tips on the other hand sounds better on the toms, that's why many rock and pop drummers prefer it than the nylon tips.
428	I've been a vocalist since my HS freshmen year which was 7 years ago, now in college and still with it. If you want to growl low, like really low, learn a false chord technique. If you want more of a scream or airy sounding growl learn vocal fry. False chord will still deepen your voice and if pushed to hard to often can cause development of the dreaded nodes on your vocal chords or false chords (located just above the vocal chords). It's nigh impossible to safely learn false chord technique without first learning vocal fry. This is because you have to feel where the sound is coming from. If you are properly engaging false chords you will feel and potentially hear a faint electronicy buzz above your vocal chords. It took me three years to get my fry to a place where it wasn't incredibly difficult to perform consistently. This is not a quick process and it will be quiet when you start out. Your goal is to find the fry register. This sound is made by vibrating your vocal chords in combination with intense diaphramatic pressure. First make the "grudge sound" an easy way to achieve this is to make a note and hold it, then slowly use less and less air until you hear that creaky sound you made to annoy people as a kid. Tighten that and push with your diaphragm. Half Lower your larynx and raise your soft pallet high... As high as you can. That's all I can really describe in text look at some vids on the tube, but ignore any vocal feud that sound not like crazy high pitched shrieks because the sound isn't coming from the soft pallet they are using their throats.
429	If your tailpiece is loose my advice is: go to a luthier. Because in this case is important to check if the sound-pole is in its place, as it can move away or fall and endanger the violin. Since you have to do that ask there for a cleaning product. Violins have a special polish that is most often made/produced by the luthier himself. On your own I would only recommend a dry cloth or at most a cloth damp with just water. You could also buy a cleaner, made for string instruments like this one. But I would still advise a visit to a luthier. Good luck.
430	A jumbo fret is made with a thicker gauge wire, and consequently the top of the fret is further away from the fretboard. The claimed playing advantages are: you can get your fretting-hand fingers further down in the gap to the side of the string, allowing you to put sideward pressure on the string more easily. In other words : string-bending is easier! (In my experience this is a definite advantage) you can push the string down further before your fingertip starts to touch the fretboard (which then starts to put upward pressure on your finger), so it requires less pressure overall to get the strings down. (In my experience this is not so noticeable) Another advantage is that you can dress the frets one or more times more than with standard frets before having to have them replaced. A possible disadvantage of jumbo frets is that you can unintentionally push the string further out of tune than with standard frets as it can travel further down to the fretboard. The solution is to just not press so hard (see playing advantage no. 2!) In summary : jumbo frets are supposed to be, if anything, easier to play - but you may not notice much difference depending on your technique.
431	Here are my thoughts for your situation. You mentioned that you are a beginner and mostly play chords. That leads me to believe that you are not going to be playing much lead or doing full step plus bends. Jumbo frets are popular on many electric guitars and basses. They are rarely seen on acoustic guitar. The main advantage of jumbo frets, is that when playing lead guitar runs, riffs and licks and solos, it is easier to bend the note by pushing the string towards the edge of the neck while fretting. Most frets classified as "jumbo" are both taller and wider than standard frets. This presents two disadvantages for your style playing. First, the taller frets will make it easy to press down on the string far enough to make the notes you are trying to play - significantly sharp. Whenever I try to play a guitar with jumbo frets, it sounds out of tune because I have not developed the lighter touch needed to play chords and keep from pressing them out of tune. This can happen with standard frets as well - but to a much lesser and barely noticeable degree. The other disadvantage, is that the additional width of the jumbo frets, could eventually lead to less precise intonation. When the frets are new, or re-crowned, they have a "crown" which in simple terms means they come to a narrower point on top. Ideally, the crown is at the exact distance from the saddle to cause the string fretted at that point to play the intended note. Over time if played often, some of your frets will lose their crown and be flat on top as the friction of steel strings wears out the softer fret wire. With the wider jumbo frets, the flat top is wider and can potentially alter the intonation to a greater degree than narrower standard frets would if similarly worn. This can be corrected by an experienced luthier who takes the time to properly crown the frets with a special file. It's a minimal effect but can mean less accurate intonation. This would not matter so much if you are playing mostly lead and bending the strings because the act of bending alters the note way more than any variance in the intonation caused by worn frets would ever do. For these reasons, if the deciding factor is standard frets verses jumbo frets - and you will be using the guitar to play mostly chords and rhythm as opposed to note bending lead, I would go with the standard frets. Later when you decide to learn to solo and want a guitar that will be easier to bend notes on, add one with jumbo frets to your collection.
432	I have a student whose guitar has lighter gauge strings and it always sounds out of tune...I suggested he switch to mediums at least to see if that helped, so if you are having similar problems, I'd recommend changing your strings!
433	The sound is all personal preference, for me personally after a few years of bouncing back and forth between wood and nylon tip I got to where I didn't care for the nylon tips even on cymbals. Nylon tips are brighter and "pingier" (for lack of a better word) on cymbals and eventually I settled on the darker sound from wood tips. Wood tips are also nice because playing the tip and shoulder of the stick on cymbals is more consistent in tone. But it's all about the sound you like. In terms of durability, both can have issues at the tip. Nylon tips can fall off (but can be glued back on) while the wood eventually chip away over time. If you're trying to decide on which way to go, then get a set of both and see which one you like best...and to eliminate any other factors from affecting your comparison, try to get the same brand and same model of stick just with a different tip.
434	More often than not, they're synonyms. When counting the rhythm of a piece, they are the points at which you may tap your foot, or click you finger. Be aware, though, that people's perception of where a pulse is may vary. Some may clap on 1, 2, 3 and 4. others on 1 and 3, yet others on 2 and 4. It's all pretty straightforward till we come to complex time, such as 6/8, where often two different feels or counts (call them pulses or beats if you like) are present in the same piece. 1 2 3 4 5 6 is one manifestation; 1 - - 2 - - is another. And the difference between 2/4/and 4/4 is sometimes not easy to discern, making the pulse or beat a little muddy. Some refer to a crotchet (quarter note) as a one beat note - I tend to - as it is the basic diet for a lot of rhythms. So in a 4/4 piece - way the most common - it could be said that there are 4 beats to the bar, or the pulse is 1 2 3 4.
435	A pulse is the heartbeat of the rhythm/music that you hear - and feel - when listening to music and this is what people usually tap along to when listening. The beat is the repeated note value of the time signature. They can often (and are usually) the same thing, or at least they cross over. However I shall give some examples: In a piece with time sig 4/4, the beat is 4 crotchet beats every bar. The pulse is most likely also going to be this however if some notes are more pronounced you may tap your foot 2 beats/bar. In a piece with time sig 6/8, the beat is 6 quaver beats/bar whereas the pulse is usually 2 beats/notes at intervals of dotted crotchets. It will be felt as: 1-and-a-2-and-a, 1-and-a-2-and-a, etc. where '1' is where you tap your foot, the pulse.
436	A good way of thinking about it is as a clockwork watch or clockwork mechanism or machine. You could have two watches keeping the same time but with different time signatures. Think of the second hand as the pulse with its tick, tock, tick, tock and the beat as the mechanism driving the second hand as 123, 123, 123, 123. Each tick or tock is supported by three beats. A beat behind the second hand pulse of 1234, 1234, 1234, 1234 would be a 16/4 time signature. A beat that is the same as the pulse 1234, 1234, e.t.c. would be in common time. An old mantelpiece clock could be imagined in cut time 2/2. That's why trying to determine the time signature of a tune by counting foot taps as beats only works in 4/4 or if you double or half your tap interval to an 8/4 or 2/4, e.t.c. Complex time signatures can't be determined that way. For example, if you tap out a 6/8 jig, you'd fool yourself into thinking it's in 2/8 time, i.e. two beats to every bar whereas you are actually tapping out groups of three beats, 123, 123. A common question in traditional music that might help is the difference between a jig and a reel. To real (forgive the pun) traditional musicians, who have learned by ear and never seen a musical score, the reply will be something using words; if you can say 'jiggery, jiggery,' to the music, it's a jig and if you can say 'this is how a reel goes, this is how a reel goes,' it's a reel. The jiggery is Ji Ge Ry, 123, beat on the capital letter, and this is how a reel goes is Thisis Howa Reel Goes, 1234. Therefore, a jig is in 6/8 time (usually) 123, 123, i.e. 6 X 8th notes (beats) per bar and a reel is in 4/4 time 4 X 4 notes (beats) per bar. To understand the 123 grouping think of a waltz which is often (usually in 3/4 time, i.e. three quarter notes per bar. You'll find yourself saying 123, 123, 123, 123 while tapping out the pulse as one tap on the 1 of each 123 grouping.
437	The meaning of 'pulse' is fairly set (unless we're going to get silly and bring vegetables into it). It's the 'click track' behind the music. The heartbeat. Well - the 'pulse'. 'Beat' has a variety of musical meanings. It can mean the physical gesture made by the conductor. In some modern 'techno' music it can mean a sampled fragment endlessly repeated. It can be used to approve the rhythmic drive of a piece - you'll hear 'That song has a great beat!' rather than 'That song has a great pulse!' Not a term used much about 'classical' music, though some of it has an excellent 'beat'!
438	Yes, all octaves will harmonize since the wave forms are all complimentary. Human range o pitch perception is 20hz to 20,000hz, which gives about 10 octaves. Below 20hz you’re more likely to just hear them as rhythms. If you include those frequencies you can get about 4 more for a total of 14 octaves.
439	"How many octaves are there in the human range of hearing?" From http://www.penguinproducer.com/Blog/2011/09/did-you-know-octave-frequency-facts/: The human ear can hear a maximum of 10 octaves: 20-40Hz, 40-80 Hz, 80-160 Hz, 160-320 Hz, 320-640 Hz, 640 Hz to 1.28 KHz, 1.28-2.56 KHz, 2.56-5.12 KHz, 5.12-10.24 KHz, and 10.24 KHz up to the upper edge of the human ability to hear. The next octave would start at 20.48 KHz, which is barely above the high threshold of human hearing. "Will the same note through all the octaves harmonize?" To an extent, but you have to be careful. The ear doesn't respond in the same way through the whole range, and typically, neither do instruments. For example, the notes at the bottom of the piano can sound very muddy when playing chords, due to note inharmonicity and the weak fundamentals of the instrument.
440	Given that, basically, a pitch will sound an octave higher when its frequency is doubled, and so on, each C note for instance, will sound like any other C note in a different octave, and won't clash. 'Harmonise' may not be an apposite word. The range of human voices is approximately 80Hz-255Hz with speech, and up to >2kHz singing, bearing in mind sibilants, harmonics etc. Human hearing, as already noted, is approx. 20Hz - 20kHz, but that varies between individuals. Youngsters range goes a fair bit higher. The four questions posed here are different. 1 (header). As many as you want. 2. Approx 10 octaves. 3.Basically, yes. 4. There is no definitive answer.
441	Don't try to relate E♭ major to C major in a functional way. Just accept that a sudden shift of tonal centre to just about ANYWHERE is an acceptable and common device in today's music. And don't try to explain the return to C from Eb as a dominant-tonic. It's just a return to where we started. That naturally will be 'satisfing'. There is a world of harmony where everything can be analysed as a tonic, dominant or subdominant. We aren't in that world here. This particular shift of a minor 3rd is so frequently used that it gets a label - "Chromatic Mediant Relationship". In fact there are four 'chromatic mediants. If we start in C major they're E major, A major, E♭ major, and A♭ major. They're all good to jump into, and from a diatonic C major section one is as good as another. Of course, if you intended to jump into (e.g.) E♭ major you COULD 'pave the way' by introducing the odd Fm chord. Some would see this as desirable preperation, some would feel it spoils the surprise! It works particularly well when the shift is from a major tonality to another major tonality (or from minor to minor). And when there's a common note between the two 'tonic' chords - C major and E♭ major share the note G. C minor and E♭ minor share the note E♭. But, really, you can jump anywhere. You can also get to absolutely any tonality, with or without shared notes or any other obvious connection, by simply jumping into a ii - V - I in the new key. Jazz tunes do this all the time. What this really comes down to is that in modern tonal writing it's OK to just jump just about anywhere. And, if you insist, I'll find a 'theory' excuse for the place you choose, or even pin a label on it. But please don't try to make me force it into 'circle of 5ths' thinking.
442	The human ear can normally hear 10 octaves of C : from Co to C10. If a musical instrument could be exactly tuned to Scientific Pitch where Co=16 Hz up to C10= 16384 Hz then you could probably perfect octave harmony.
443	Whatever the key signature, the first one is two G♯ notes. The second is a G♮ and a G♯.
444	Do you have the manual for the thing? I've done a little poking around (I even found a bunch of parts diagrams at Sears website), and I'm getting the impression that it's got a spark ignition system, not a pilot. Is the range plugged in? Is there any chance that the circuit it's on has tripped it's breaker? I've got a cooktop with a spark ignition system, and it has a special 'light' setting on the gas control - you turn it to 'light', which turns on the gas and starts the sparker. Once it ignites you turn it further to whatever setting you want. Does yours have anything similar? Does it make a 'clicking' noise when you start the gas? Also, has it ever worked? If so, when did it stop working? Did you make any changes to the kitchen at that time?
445	Courtesy of a Google image search, I found the wiring diagram for your stove (see below). It shows that your stove-top burners are lit by spark ignitors and that your oven is also run by an electric ignition system. It's most likely that the oven is done with a hot coil resistor. If you look under the oven, you'll see it glowing while you've got a rolling flame next to it. Just in case somebody does have one that has a pilot light, the complicated part is that pilot light systems come with safety valves. If the flame is out then the gas valve will close because the thermocouple / thermopile won't be generating any electricity to hold it open. You need to find the system that allows you to let gas flow without the flame and hold it open for a few seconds after the flame has started. .
446	The SDS chuck system was the original developed by Bosch. SDS Plus is an improvement on the original SDS system, but remains compatible with SDS bits, and is now the most commonly seen on the market. SDS Max is designed for the heaviest masonry work, and is incompatible with SDS/SDS+ bits. (source: wikimedia.org) https://en.wikipedia.org/wiki/Drill_bit_shank#SDS_shank It sounds like for your application, SDS Plus would be the way to go, given that they are generally less expensive, and you don't have really tough masonry work to do.
447	You can get toilet bolt covers in a variety of styles. The ones pictured by gregmac are a common type that use a plastic washer to which the cap snaps onto. I recently purchased another style that has a cap with an internal threaded part that screws onto the toilet bolt end. The cap kit comes with several sizes of the threaded inserts to adapt to different sizes of toilet bolts. As you can see in the picture below the inserts thread into the inside of the cap and then onto the toilet bolt. In your case it may be necessary to file the sharp ends of the toilet bolt so that cap can thread onto the end of the bolt. I found this type of cap to work very well. I previously had the snap on type caps that always came unsnapped when bumped accidentally. Purchase them at any good hardware store in the replacement plumbing parts section.
448	For easier identification: SDS and SDS plus are 10 mm diameter - and interchangeable. SDS Max is 18 mm diameter SDS Max is for heavier work, with 4 times the cross section shank.
449	This little picture shows how you have to get the pins installed so that the key will allow the lock cylinder to rotate properly.
450	Open the drawer under the oven. Inside towards the back near the center along the top there is a metal prong sticking out - like a mini-sprinkler pipe. At the end of the pipe is something that looks like a sprinkler head. This is where the pilot light is located and where it must be lit. Set the oven's temperature to "Off", remove the stove's oven control knob, and push in on the metal control rod there while holding a lighter under that sprinkler head— this should cause the pilot to light. Hold the control rod in for a few seconds to allow the pilot to warm up the oven's thermocouple, then release it. If the pilot stays lit, you are all set! If not, try again and hold the control rod down longer. All the other answers on here are wrong: lots of stoves in modern apartments still have pilot lights. They are no big deal and are very common and safe except in certain very rare situations. It is true that a lot of new stoves have spark systems but pilot light set-ups are still very common.
451	This is hard to tell and may largely be determined by your refrigerators. Energy Star came into existence around 1992 I believe, so if your fridges are older than that they are probably energy leeches regardless of leaving them plugged in or not. This article claims a fridge left unplugged overnight would not net significant energy savings. This comes to 1/3 time unplugged over the course of a week. Your situation, with 5/7 time unplugged over a week, is just over double the 1/3 time unplugged per week. This may save some energy, but with much older fridges, they will strain to cool down again and you could put a lot of stress on the compressor and use a ton of energy to recool the unit. Maybe it will save some energy, but maybe it will blow out your fridge. Perhaps a month long experiment is in order. Try your fridge unplugged hypothesis for a month with all other energy usage remaining the same. At the end of the month, compare energy costs with the last month and see if the savings are significant and use this as a guide for the future. Also, check out the energy saving tips on this page to help cut down on waste. For example, leaving it on the highest temperature settings while not in use can help cut down on energy consumption.
452	It's probably a false economy to turn it off and you run the risk of having them develop a smell unless you take these precautions. If you do turn them off you need to open the door and wipe it out with some chlorine bleach to prevent any mold developing. Opening the door allows it to dry out again helping to prevent mold. If you have a holiday home that lies vacant for several months, yes turn off the fridge assuming it's empty and there are no frozen items in the freezer section that you want to keep. In your case, I'd leave it. Running a fridge for 5 days when the door is never opened will not cost you that much at all. However, having a fridge develop a smell you can't eliminate will cost you a new fridge.
453	I think unplugging the refrigerators will both save electricity and reduce wear on the compressors, although I agree with others that if possible you should measure the usage, in part to decide whether any (possibly small) savings is worth the effort. Energy Savings Empty refrigerators are less efficient, since the compressor needs to cycle on and off more frequently due to relatively low thermal mass. If you unplugged the fridge when you weren't using it, I suspect when you plugged it back in it would only take a few hours to cool down. Under normal usage a fridge will have its compressor running about 1/3 of the time, so this will be a meaningful savings. (The fridge uses the vast majority of its electricity running the compressor, so how long it's running for is a good proxy for electricity consumption.) Wear on Refrigerator Cycling of the fridge compressor on and off is a primary cause of wear, so unplugging the fridge should be a benefit in that respect. Plus there will be total fewer runtime hours. I don't see how unplugging the fridge for days at a time could possibly damage it. (If you were unplugging it twice a day and forcing it to warm up to room temperature and the cool down, that would be another story.) Other Considerations When the fridges are off you will need to make sure they don't get moldy or develop smells. The easiest thing would be to leave the doors open so any moisture can evaporate. Leaving a dry hand towel over the door can help ensure the door doesn't close accidentally. If you have the means to measure the electricity savings, I would do so. You may find that the savings are small and not worth the effort. Water jugs will not help you if you are unplugging the fridge, in fact they will make it worse. The purpose of the water is to retain cold and stabilize the temperature. If you let the water warm up to room temperature with the rest of the fridge you will just be creating more work for the compressor when you plug it back in. On the other hand, if you decide to keep the keep the fridge plugged in all the time, leaving jugs might help a bit (but only if you leave them in all the time... do not remove them). Do you really need two fridges at all? Maybe a cooler and some cold packs could supplement any overflow those 2 days/week? Old fridges can be big power hogs. I'm sure you could save a lot of electricity with a new model (maybe a single bigger one). Whether a new fridge could pay for itself in a reasonable amount of time depends on a number of factors, but it might be something to consider.
454	If the lever you are referring to is on the side of your pressure switch: Then I unfortunately have not very good news for you. As the name implies, this cuts off the switch entirely when the pressure drops to about 10psi below the cut-in point (eg, most well pumps are set up to turn on at 40 and off at 60psi, so the low-pressure point is about 30psi). It's there to prevent the pump from running dry. Potential cause: low-yield well Without any other information, my best guess would be your well is not producing enough water to keep up with demand. This seems to be consistent with your statement that it only happens after 30-45 minutes: there is enough reserve capacity in the well itself to supply you for a while, but ultimately, the rate of water entering the well is lower than the rate you're using water. The ultimate fix for this is to install a cistern or holding tank that the well pump supplies, and have a second pump in that that actually supplies the house. The cistern is controlled via float (instead of pressure switch) and the well pump is protected by a load-monitoring device (eg: Pumptec by Franklin-Electric) that turns off the pump electronically if it senses no-load. The size of the tank largely depends on how much capacity you want, what the actual yield of the well is, and logically where the tank will go and how big you can fit. Commonly, the cistern is a large cylindrical PVC tank installed in the basement. Potential cause: undersized pump The other main cause would be an undersized or under-performing pump that is unable to keep up with demand. The symptom of this would be that the pump runs constantly during use, rather than cycling on and off, and that you generally have a consistently low pressure for that time prior to the low-pressure switch cutting out. Replacing the pump in this case may help, but if you have a low-yield well then it's a waste of money. Considering it's been happening for 14 years, it seems unlikely this would be something mechanically wrong (I'd expect the condition to worsen over time, or for the pump to have failed by now) and more likely that the pump was undersized, IF you also have the symptoms I described. What next? If you can determine the pump is undersized, then replacing it with a larger pump would be one way to remedy the problem (assuming there is no yield problem also). The next best course of action would probably be be to test the yield of the well. You may be able to do this yourself, but a professional will bring in a much larger pump and test the flow right at the well, bypassing all the pressure controls and inside piping that would interfere with the results. Of course, seeing as you're selling the house, you'll have to make your on judgement call on what you do or disclose -- advice on that is beyond the scope of this site.
455	There is no problem with doing this. Housewrap is "breathable" by design so you won't trap moisture anywhere. You could build a wall with ten layers of housewrap and it would be more durable, not less. Regardless of how many layers you have, it's critically important to make sure your windows and doors are properly flashed to the outermost layer slash the one with the most integrity. When the installers complete this work, don't let them get away without re-flashing all your windows and doors to the new layer of housewrap.
456	Really I would suggest using SDS Max on the larger projects where you are doing some Demo. SDS Plus is however a lot lighter and easier to move around with, as long as you dont need to go super heavy duty. You can get adaptors to convert between systems like SDS Max, Plus and Spline. SDS Max Shank Carbide Bit: SDS Plus: You can find some good photos of the various bit types at www.BuildersDepot.com. Link: https://www.buildersdepot.com/carbide-drill-bits.html
457	In short, sds + is for light duty applications (drilling for ledger boards and light demo), sds max is for people who work with and demolish concrete professionally. I build decks and fences. For me sds + does everything I could ask. Good for breaking up old peirs, drilling multiple large (up to 1") holes in brick or concrete.
458	I have seen this solution done many times, and it is taught in carpentry and building courses. Please note homeowners must not attempt to design or carry out this work themselves. Your whole roof may collapse in on you. Your roof framing may be one of two standard types - truss framed roof or "old school" non truss (officially called traditional and or conventional roof framing)(those words are not describing the shape of your roof BTW). Depending which roof frame type your house has been built with, you will need to apply a different solution to this particular situation. Sometimes to save on the cost of one large beam fitting into the ceiling several smaller beam can span across and become hangers for this larger beam which you want to remove the support post from. Approx cost guide 2018 - $500 engineer, $200 council approval application and a few weeks waiting for it, $500 new beam and brackets, $500 replace ceiling (gyprock and plasterer), $1000 a day for between 1-3 days work for carpenter gang of 2 or 3 once all materials on site and ready to go. $1000 contingency for shifting electrical cables currently in ceiling, more if you have gas or air con pipes in ceiling, and more again if you need to take roof covering off and hire scaffolding to get new beam into the ceiling space. This solution is virtually impossible if this is a two storey house. hope this helps all you readers out, and doesnt put you off. Apologies for the scratchy sketch, just knocked it up quickly to make the points clearer.
459	Typically a main stack vent that is rubbing against a structural stud, sill plate, or drywall. I have fixed this ticking/clicking noise in two houses by cutting out the offending piece of 3/4" drywall and replacing with 1/2" on top of furring strips to give the pipe some room to expand.
460	This particular model provides a reach for the mounted television of a maximum of 29", which is astonishing (opinion) and according to the ad copy, allows a 90° turn for up to a 55" television set. This would appear to meet and exceed your requirements of about 45°. It's pricey, but not compared to the prices of large televisions that get knocked about. As Tyson suggests, a Google search for "long reach wide television arm mount" would give you a wide selection. The one pictured above can be found here.
461	It is probably a shaded pole motor or perhaps a variable speed motor. If It doesn’t have wires for a capacitor it doesn’t need a capacitor. Capacitors are only for split phase motors. Granted split phase motors are most common for blowers but by no means the only motors for blowers.
462	Sealing vents off can damage the duct work and shorten blower life. I have had to open walls where the owner closed a couple of bedroom vents this caused the main duct to split inside a wall I would not totally seal it off it may not sound like much but the main duct has a large area and the flex lines can break loose or metal trunk lines can split I have seen both.
463	From the NEC: 352.46 Bushings. Where a conduit enters a box, fitting, or other enclosure, a bushing or adapter shall be provided to protect the wire from abrasion unless the box, fitting, or enclosure design provides equivalent protection. The important part is bolded above - you need a bushing unless your fitting provides equivalent protection - that is, equivalent to the protection a bushing provides. You'll probably terminate your conduit in your panel with either a PVC male terminal adapter: or a PVC box adapter: I think anyone would agree the box adapter provides protection equivalent to a bushing. I believe it's generally accepted that a PVC male adapter does provide equivalent protection, but you might find someone that disagrees, and some of them are pretty sharp. I usually ream them with lineman's pliers to take the edge off and do without the bushing. The box adapters make a great connection but since they are cemented on, they are a pain if you have to remove and replace them.
464	A bushing is typically NOT required when using PVC conduit. However, for the sake of completeness I always use a bushing...
465	Don't ship an air conditioning unit overseas, for Pete's sake. Your cash stake in that unit is "what it will cost to buy a comparable one on Craigslist at your destination" minus "what you can sell this one for here". That number may even be zero or less than zero. The only way the shipping costs won't absolutely blow away your cash stake by a factor of ten, is if you ship your goods by seagoing container. Even more, the Philippines have a weird dialect of 240V power where neutral basically does not exist. Taking an older A/C unit, you may find the unit has suffered some insulation failure between neutral and ground; harmless enough in Qatar/Europe but in the Philippines' strange power it spins your electric meter or shocks people who touch it. To say nothing of the 50/60Hz incompatibility, which is a deal killer all by itself.
466	Transformers are always going to produce some heat. It's a part of the step-down process. It should only be warm to the touch, however. If it burns you, there's something seriously wrong. Some noise is not unusual either. Go stand near a power company transformer and you should hear some noise as well. If the transformer is cheap, it might make more noise than a more expensive model (my experience only, yours may differ), but they generally aren't silent. #1 would worry me more than this
467	On the heat check the specs on the ring doorbell and make sure 20VA is enough to cover what the required VA needed. It should tell you either the wattage or the VA it uses. VA is volt-amps or volts times amps or wattage. (12 volts x 1.6 amps equals 19.2VA, 24 volts x .83 amps equals 20VA). You shouldn't go over 80% of the rating of your transformer or in your case 16VA. Transformers that are magnetic are going to create heat. Just don't overload.
468	the transformer is pretty warm to the touch....Not crazy hot but deff warm. Is this normal for a transformer? A loaded transformer should be about as warm as your laptop charger. On the conceptual level, they do essentially same thing. (the transformer is less efficient, but the laptop charger puts much more power so the waste heat should be similar) Or do I have to much power being distributed to it? The only way of giving it too much power would be wiring a 110V transformer (yours) to a 220V circuit. Or wiring it backwards, but that would have blown up already. the transformer makes a decent amount of noise. That's bit concerning. A transformer should emit mains hum, but it should be very faint, impossible to hear from a distance. On a busy day, you should have to put your ear to it in order to notice the sound, easier to feel by hand. Unless something is acting as sound amplifier (like a guitar body), eg. being fixed to a drywall or lying on a desk. I guess my overall concern is I understand the very (and I mean very) basics of a transformer and resistor. But are the above items normal? Should a transformer be silent and cool? Based on my set up is there any red flags? The phenomena you're describing are fundamentally normal, but it's impossible to tell from your description if the intensity is normal as well. Cheaply made, loose transformer will make much more noise than a decent unit. Generally, when dealing with a new circuit, the best course is to assemble and run it on a bench first. In stages. You should observe the transformer running at idle (without any load), with almost-idle load (videobell fully charged), with small load (the videobell charging through the resistor) and at full load (with the bell button depressed / the resistor hooked up directly). The sound and heat of the transformer change with load. The heat load of your resistor also change, depending if the button is pressed. You could try using the 8, 16 or 24V taps to see which one works best. Contra-intuitively, using higher voltage sometimes resuls in smaller losses when charging an electronic device. You could try to use 2 resistors in series (you've linked a 2-pack), especially with 16 or 24V. Even a cheapest multimeter would help greatly to ensure you get expected voltages. (Within a healthy margin, certainly. A doorbell transformer is not meant to be precise.) The most important question would be: is the videobell charging? All of your issues could be easily explained if some of the output terminals are shorted, overloading the transformer. The unused terminal should be left unconnected. Ring uses 30VA transformer on their examples, yours has only 10VA on 8 and 16V circuits and 20VA on 24V - but that's definitely not a problem here. With 25ohm resistor, the power always stays within the limits. On 8V it's merely 2 watts (you can assume that 1VA = 1W in this case).
469	There are three possible ways to fix this. Drying, sanding, bleaching, re-staining to match the existing stain, apply clear coat. This option requires that you are able to match the new stain to the color of the rest of the floor. There are videos and how-to articles available to explain the details. Replace damaged boards with good boards. If the existing floor is worn/old even an exact match of new original flooring will be an obvious repair. There is online information for this process. Replace the whole floor. I don't think you will be able to do option 1 and get a match that will please your landlord. There are people who specialize in repairing this type of floor damage. It won't hurt to get an estimate. Google "repair wood floor water damage" and you'll get a list of businesses. Someone with experience might be able to match the existing floor. If the repairing the floor won't please your landlord you might be able to persuade him/her that the floor is old and nearing the end of it's life and you should only have to pay some percentage of the whole cost of a new floor. I'm sorry I don't have easier options.
470	If you follow the (3) wires from gas valve, two end up on the control board and one goes to a limit switch on the blower. This limit switch was burnt out on my furnace. It's a relatively inexpensive part to replace. Good luck.
471	I would sister 2 pieces 3/4" marine grade Plywood Braces (since it's under a toilet) on one side of the damaged joist as shown below. Use Epoxy or Urthane glue and SS deck screws to tie them to the Damaged Joist. After both Sister Braces are set and in place, add a plug (not shown) in the gap of the Brace A's (purple) opening since it'll be under compression. Then trace the joist's opening and make a rough cut plug. Glue this in and fill in the gaps between the plug and the joist with a "filler type" resin. Finally add 2 more Sister Braces (not shown) like on the first side.
472	Good to be proactive and catch this before the tile goes up. Obvious problems I see are that the drywall is poorly cut (can take it out and trace it to re-cut a matching piece without gaps or overcut at almost no cost so easily fixed). Any of a drywall cutout tool, a Dremel, a keyhole saw, a hacksaw blade or a drill with a side cut bit can cut the piece without so many obvious flaws. Sloppy cuts like that are no issue on properly backed board, but a repair justifies greater diligence. If he's being dodgy about fixing such an obvious problem, he may just need an idea of how to do the fix at a reasonable cost. The rigidity problem won't be fully solved by the above, but it is still very easy to solve. You have a very significant size workable hole there, so it shouldn't be a problem to add backing wood verticals to support the drywall. You probably don't want to remove more tile and trying to screw to the studs inside the wall would be exceeingly awkward, but you can get some 1"x1" pieces of wood, figure out what the longest one you can get through the hole is, cut it and hold it up inside the wall to see if it's long enough to bridge the taller gap with enough overlap to glue to the inside of the drywall above and below. If it's not long enough, you can put two pieces in the wall and then screw them together with a 4" overlap to make one long piece. Make sure you drop all the pieces you need in the wall before you start screwing together or gluing in pieces that might block the opening. Finally, you can cut blocks to fill the space between the backing boards and the back wall and glue, screw and/or wedge those in place. Consider overkill using heavy duty adhesive like PL400. By the time you're done the result should be as permanent and rigid as the rest of the wall. Cost will be quite low compared to cost of re-doing tile an infinite number of times. Especially if you use high strength adhesive like PL products, prep everything first, clean the inside of the drywall of dust and read the instructions, as some of these products set quite fast. As far as the depth problem, that should not be a significant issue for an experienced tilesetter or mason unless it is quite significantly proud, but to me it looks inset and since the drywall needs to be re-set anyway it would be easy to shim it flush. Bashing out more tile, even just enough to install a horizontal backing board would also work, and the 16" tall piece of drywall you're asking about would function too, but it will still have some flex unless you add backing. You would have to take out 9 tiles including a special cut and really all you want is a normal strength wall and it probably won't break your heart if it has a few extra boards hidden in it.
473	Go buy yourself a repair kit for about £5-6 pounds. These would include the following: 1) Tyre levers - something to remove the tyre !! 2) Repair patches 3) Emery cloth - To roughen up the tube surface. 4) Tube of glue. If you haven't got quick release wheels, make sure you take something to undue the wheels nuts. I learnt this the hard way when I first started riding my fixed wheel.
474	Cycling gloves come in different varieties (like full-fingered or half-fingered). Typically: Cycling gloves have extra padding at the palms, which for me makes a difference when riding for hours at a time. They protect your palms in case you attempt to use them to break a fall. Like regular gloves, they can keep your hands warm in cold weather, especially since your hands aren't moving as much as your legs. My particular pair of cycling gloves have a "towel" built in at the base of the thumb "finger" so I can actually wipe off water/sweat by running my fist over it.
475	Cycling gloves dampen the vibrations coming into your hands from your handlebars. I find that if I cycle for more than one or two hours without gloves I slowly loose feeling in the tips of my fingers and I get a tingling feeling in the pinky side of my palms near my wrist. This slowly spreads to essentially make both my hands feel numb. It goes away quickly when I get off the bike at first, but during cycling holidays where riding a bike is a daily activity I ended up with numb hands essentially all the time. Simple cycling gloves have solved this for me. Note that front suspension would probably address at least part of the same problem.
476	Padding and warmth are covered in other answers, but in the winter I have a third use. In the warmer weather my fingers swell slightly, which doesn't happen so much in the winter, so my wedding ring has a tendency to be looser in colder weather. Long fingered gloves stop me from worrying so much about it slipping off when on bumpier rides.
477	To answer the second question. Gloves like that are great for working on cars... The padded palm keeps you from tearing up your hands on old rusty parts. The top of the hand is covered for when you slip and bang into sharp rusty parts. The fingers are exposed so you can still easily grip small parts. I find they work much better than traditional "full finger" mechanics gloves...
478	Cycling gloves do a few basic things: reduce friction between your hands and handlebars, which could otherwise cause blisters dampen vibrations which might cause hand/finger numbness reduce pressure on your ulnar nerve, which also causes numbness Of course, if none of these are problems for you, it's fine to ride without them. Other types of gloves should offer similar benefits too (wool gloves with "grippy" palms are nice in cold, wet weather). I try to ride without cycling gloves for rides up to an hour to toughen my palms and reduce the bizarre tan lines the gloves create. But for longer rides (especially randonneuring, which is 200km+) I can't ride without them. What else can you use them for? Basically anything where a padded palm would help. They make great workout gloves, and I've occasionally used a pair for paddling, doing yard work or helping someone move.
479	Gloves do help with hand numbness/discomfort, but the primary benefit to me is safety. If you fall and take a handlebar spill, your hands won't be torn up if you instinctively put your hands out to protect you.
480	aside from the warmth and padding, I also wear them to protect my hands in case of wipeout. grinding gravel into my palms doesn't sound like a fun thing to do.
481	When you fall off a bike your natural reactions will lead to putting your hands out to stop your fall. Your hands are quite likely to hit the ground first so gloves provide some protection against that. Comfort is another factor - damping vibration and providing protection from the elements. Depending upon your climate you may want different gloves for different seasons. I wear motorcycle gloves on my bicycle in the winter.
482	For bmx, the greatest benefit is grip. If your hands are sweaty, you'll have to apply a lot of extra force to prevent throttle grip. Gloves eliminate all that. Also, the padded palms work nice to prevent meat paw, terry cloth thumb is good for wiping sweat away, and there is usually some tacky material on the fingers for good brake lever grip.
483	One thing that I use my gloves for on nearly every ride is putting my palm down on the tops of my tires after going through a section of stone dust or cinders. In fact, just today I was forced to ride through a section where some fresh blacktop spillage stuck to my tires. A quick drag on each wheel and the tires were completely clean again.
484	One other purpose for gloves is that if you have rubber grips, for example grip shifters on a hybrid or mountain bike, gloves will protect them from deterioration due to sweaty palms. I ride two bikes with rubber grips, one always with gloves and one without. After a few years, the grip shifters on my hybrid are ruined and the rubber can't be replaced without replacing the whole shifter. The other bike's grips still look great after 8 years.
485	They should be of a compatible width but its unlikely that they'll be the same length though. Most road hubs have different widths to MTB's. Fortunately for you, most road hubs are narrower and as long as there's enough thread on your skewer you'll probably be fine and should be able to just cut a bit off the end.
486	Generally speaking, the answer is no. Not all skewers are compatible with all quick release wheels. There are different diameters and widths of skewers. Notably, many downhill bikes have beefier skewers that are built with a much larger diameter to be more durable. Bikes with wider and narrower axles will have less standard skewers too. In your case, it is likely that the skewers will be compatible. Even if the skewer isn't quite long enough to have threads protruding from the nut, it will still be okay if the difference is less than 2mm. See this forum post for more info: True, the standard nowadays is 100mm up front and 130mm in the rear, BUT When you start talking about different types of bikes, you get into different width hubs. Tandems have a standard rear spacing of 140 or 145mm, some downhill/freeride bikes have a whopping 150mm rear spacing and 110mm front hub spacing and monstrous 20mm through bolt skewers, older bikes with French or Italian standards can have wacky sizes from 91mm 96mm, the list goes on. But you are correct in saying the "standard" size for skewers is 100mm up front and 130mm in the rear.
487	Don't overthink it. For casual weekend riding a 40-year-old Huffy will be quite serviceable. It's important, if you possibly can, to actually ride the bike you're thinking of buying, to check it for fit and comfort and to get an up-close feel for "fit and finish".
488	I think loudness is not a good indication of efficiency, since loudness (and pitch as well) can be affected by many more factors at same or similar total energy consumption.
489	Most of the noise comes from pawls on the freewheel hitting against the splines on the engagment surfaces which makes up the racheting unit. Some reasons for the noise between freewheels? Tension on pawls could be higher causing more noise as they glide over the engagment surfaces High end freewheels have more pawls and engagement points than lower end freewheels, so there are more ridges in the engagement surface and more pawls hitting the splines on the engagement surface. The reason this is desirable is that more pawls and engagement points means faster engagement when you start pedaling. Different grease (or less grease) could also be used inside higher end freewheels that is less viscous and provides less resistance, allowing the spring action of the pawls to cause more noise as they float over the the splines on the engagement surface since they are less restricted by the grease. Of course there are exceptions to these. Some hubs don't use your standard racheting mechanism and use a 'roller clutch' instead. The roller clutches tend to be very quiet, but are more prone to failure.Here's a good description of how those work. http://pardo.net/bike/pic/mobi/d.winners-hub/index.html
490	So I guess there are two parts, cause and how to fix it, so first causes: No rim tape - sometimes new bikes won't have rim tape, and the tube can get slightly cut on spoke holes, if you don't have rim tape, put some in, it will save you in the long run Rim has something sharp on it - rarely you might find that a rim has a little bit of metal sticking out that causes a puncture, generally this isn't a problem if you use rim tape. Tube incorrectly installed - make sure that when you put the tube in that you pump it up a tiny bit, and move the tyre left and right and go round the whole rim like that(making sure that you can't see the tube), it will stop you getting the tube squished in between the tyre and the rim. If your tube isn't distributed evenly around the tyre you can also get a similar problem. Tyre has something poking through or a cut - When you change the tyre run your fingers around the inside of the tyre, often there is something poking through, also inspect the inside and outside of the tyre, often there is a small cut, even a tiny cut will cause a road bike tube to fail. Incorrect pressure - If your pressure is too low you are likely to get pinch flats, and if it is too high you are likely to get random failures. Make sure you check the recommended pressure on the side of the tyre. Pinch flats can in their worst case cut through the tyre as well, so if your tyres are low pump them up! Cheap tyres - I have had quite a few tyres of different qualities, and it always seems that the cheap ones get some kind of cut in them quite quickly, but the mid range ones don't tend to get this. This mainly is appropriate to road bikes. Tube Installation damage - You hear about people that damage the tube when installing them sometimes, just make sure that when you are installing the tyre the tube isn't between your tyre and the rim! You didn't mention if you had a road bike or a mountain bike, but road bikes tend to cause a lot more problems with punctures, purely because the higher pressure will show up any installation problems and they will get flat quicker (or atleast flat enough to get a pinch flat). How to fix it: These days I don't bother repairing tubes, it quickly becomes a frustrating exercise, and in the end you don't want to be 30kms away from home with a leaky tube. If I got 1 flat I would replace the tube, and if I get another flat after that I would replace the tyre and tube. It seems really over the top, but it is very easy to put in 3 tubes into a tyre that has some kind of almost invisible nick in it, and it is cheaper to have just bought a new tyre and tube. I guess for me it is more valuable to have a bike that will just work when I get out there. Once you have read all that, you might want to have a read of Sheldon Brown's guide to flats.
491	I noticed this as well. In my experience, on higher end road bikes, the cassette that you put on the freehub body makes the most audible difference, versus the actual inner-workings of the freehub itself in most cases, i.e. normal, ratchet style freehub body. Example: I went from a Sram PG-1130 cassette to a PG-1170 recently. The lower end cassette (1130) construction is different, specifically the dome and spacers (which are plastic). On the higher end cassette (1170) the dome is lighter and stiffer, and the spacers are steel and attached to the cogs. The cassette acts like an amplifier for the sounds coming from the freehub. Thus, a cassette like the aforementioned 1170, with a very resonant dome and body, casts way more sound than the 1130, which is expected as it has plastic construction with deadens the sound considerably and a thicker dome, which also hinders resonance. I noticed immediately after the switch that the sound coming from my bike went from: click, click, click... to: ting!, ting!, ting!... Personally, I like the 'ping/ting' sound better and associate it with higher quality.
492	Steel requires rust proofing. Just like on you car, there is a thin layer of primer under the top color. When scratched to the base metal, sanding and painting the affected area is necessary. Sand until the exposed metal is shiny. Depending on the spot, you can use a high grit paper, or wet sand paper with water. You might want to start with 200-300 grit and then maybe 400 or 600. You're working with a small area so you don't want to press hard when sanding. A good technique to make sanding with paper easier is to fold it a few times to get into tight areas. Folding gives you a stiffer sheet edge and you can work it in crevices. Also wrap an inch or two of paper around a woodend dowel, or even a pencil. A round shape will help you sand the long vertical scratch on the fork without having to sand the whole width of the fork surface. The round shape will only touch the suface in a long thin area instead of a wide area. Wet sand paper is usually less than a dollar at most hardware stores when bought by the sheet instead of the pack. You shouldn't need more than a sheet or two of each grit. Wet paper last a lot longer than dry. It can also be cleaned/washed. Use a high percentage alcohol to degrease and remove dust after sanding. Dry thoroughly if wet sanding before using the alcohol. Then prime, even if it's just dab priming. Allow the primer to dry thouroughly and lightly sand the primer back to where the original paint just shows around the wound. You can also use a high number wet sand paper with water to lightly sand. Look for a paint match at an auto parts store. Dab the paint on primed areas and let dry. Wet sand with high grit paper to match the original finish. Treat the paint like a regular car. Small amounts of paint polish will give you a good shiny finish with little work. Apply wax and enjoy. Paint like yours should last a long time. 1) Rough sand with shaped paper to get the rust off down to the metal. 2) Wet sand for a finer surface finish. 3) Dry, then degrease with alcohol. 4) Paint with primer. 5) Sand the primer and lightly dust with lint free cloth(cotton ball or pad) and alcohol. 6) Apply matched paint. 7) Wet sand with fine paper. 8) Wash, then polish and wax to shine. 9) Enjoy for years to come.
493	Trying not to mention what has already been said but: Gloves that wick well will also help to keep you cooler (and cut offs are not a significant disadvantage in this sense, due to surface area to volume ratios and blood flow.) The main reasons for choosing cut off gloves as opposed to more protective full finger gloves (given that both can keep you more or less equally cool if made out of the right materials) is partially personal preference, but often relates to better feel when dealing with zips, packed food/energy, gear adjustment and not having to take them off when working on the bike, some also claim a superior feel for the brakes. What other activities are they useful for: potentially anything where you grip anything but don't need your finger tips covered or are willing to take the risk of finger tip injury, also for typing in the cold. I use gym gloves for cycling, better value, fit AND durability (in my case) than cycling equivalents at twice the price. I only use actual cycling gloves when it comes to full-finger + extra protection, or waterproof + breathable (since those are expensive in any sport, so I may as well have something with more attention to cycling relevant details).
494	So why, for the bicycles, smooth tires would be better on wet floor ? Is this from the thickness of the tire ? Yes, that and the relatively high pressure combine to displace water around the tyre. You don't need special features to move the water if it can easily part around the tyre, and the contact patch pressure is high enough that the water really wants to part. This is the commonly-cited explanation of why aquaplaning/hydroplaning isn't a risk for bicycles. For example, it gives a threshold speed of 66mph at 40 psi. If (for the moment) we take it as gospel, I guess we might just about be able to get a fatbike with huge low-pressure slicks to aquaplane after a fast descent. So, the moral is, if you're doing 50mph plus at the bottom of a mountain on your fatbike and see some standing water ahead, you might lose control. I'm honestly not sure this would come as a surprise in those circumstances. Now, we could spend an arbitrary amount of time discussing which treads are useful which circumstances - slimy, muddy, gritty or whatever. For simple standing water though, there is no advantage.
495	Recently I replaced my 6800 groupset with a Chorus one. I am using a Mavic Ksyrium SLS wheel; that means I had to change my freehub body to a Campagnolo compatible one. Surprisingly, the new freehub has a different sound when coasting, and the noise is so much more reduced. I supposed the difference in the two freehub bodies is to accommodate different brands of cassettes. I had never like my Mavic wheels, but now they are so much more lovely. Not my knowledge to explain why, but it proves that the noise is not a matter of high- or low-end hubs.
496	Louder means more force has been used to make the noise. A change in tone means that different materials have been used to make the noise. More contact points does not automatically result in more noise - if the sound was generated at the same time it would not increase the volume. If a noise gets louder then it is likely that an amplifier in the system - depending on the design, the space in the axel might act as an amplifier. The gear rings could act as an amplifier - this is not likely as the tension generated by the chain would act as a damper. Going back to the first point: if more force has been used that has resulted in a louder sound I would point to an increase in force being applied at the contact points - one obvious reason for a stronger force would be stronger springs in the freehub.
497	I don't thin there will be any problems being able to shift an 11 speed derailleur with a friction shifter. You need to run a 9 speed chain on a 9 speed cassette. There might be a problem with the wider 9 speed chain fitting in the R7000 derailleur cage. The only anther problem I see is that you'd be wasting money if you buy an R7000 derailleur specifically for this purpose.
498	At least Toyota has a special hybrid battery test that only the dealership can do. If you service your car regularly at the dealership, the test is performed annually and in Finland, this extends the warranty 1 year at a time to 10 years (with 350 000 km max). I suspect the actual test is performed continuously on the car computer and the dealership just reads the test results stored in the car computer's memory. Unfortunately, I don't know if Lincoln has a similar design than Toyota. However, typically traditional (non-plug-in) hybrid vehicle batteries are oversized for the job they do. All they need to do is to help accelerate the car to max speed. For example, my 2016 RAV4 hybrid has a 1.6kWh battery pack. This is 5.8 MJ. In comparison, accelerating the 1700kg car to 120 km/h (the max speed allowed in Finland) takes about 1 MJ, and about only half of the acceleration energy comes from the battery, so 0.5 MJ required. So, the battery is over 11x bigger than it needs to be! Of course, the battery is shallow-cycled with only 40% of its capacity being used, but even then it is oversized by a huge margin. Not only that, but also the NiMH batteries last surprisingly long amounts of time due to shallow-cycling. Additionally, since the batteries typically last for the lifetime of the car, you can almost certainly find a cheap junkyard battery instead of having to purchase a new battery. So, I wouldn't worry about the battery. I would worry about buying outdated technology when purchasing a used hybrid, as a newer car very well can have better fuel efficiency.
499	I spoke to two Ford dealerships and they both said the hybrid system itself performs diagnostics, and if there is no error lit up on the dash, the hybrid system is working fine. The two mechanics I spoke with at the two different dealerships said they each had only replaced one hybrid battery in the 10+ years they had been working there, and it was on the earliest hybrid models. One said the car had more than 300,000 miles on it. As a side note, one of the mechanics told me cars with Nickel Metal Hydride (NiMH) batteries actually have a special battery reconditioning process once the batteries do wear out, but it apparently is a time-consuming process and requires special equipment.
500	There is a blue house on Oxford street
501	Paris is the capital of France
502	fastRAG had its first commit in 2022